"""
format_for_training.py
å°†æ¸…æ´—åçš„æ•°æ®è¿›ä¸€æ­¥æ ¼å¼åŒ–ä¸ºé€‚åˆæ¨¡å‹è®­ç»ƒçš„æ ¼å¼
"""

import json
import os
from typing import List, Dict, Any

def load_jsonl(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½JSONLæ–‡ä»¶"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                data.append(json.loads(line))
    return data

def save_jsonl(data: List[Dict[str, Any]], file_path: str):
    """ä¿å­˜æ•°æ®åˆ°JSONLæ–‡ä»¶"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

def format_for_multiple_choice(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¼å¼åŒ–ä¸ºå¤šé€‰é¢˜è®­ç»ƒæ ¼å¼
    
    æ ¼å¼ï¼š
    {
        "instruction": "Choose the best answer for the following question.",
        "input": "Question: {question}\nOptions:\nA. {option1}\nB. {option2}\n...",
        "output": "A" / "B" / "C" / "D" / "æ— ç­”æ¡ˆ"
    }
    """
    
    question = item['input']
    options = item['options']
    target_idx = item['target_idx']
    
    # æ„å»ºé€‰é¡¹æ–‡æœ¬
    option_labels = ['A', 'B', 'C', 'D', 'E', 'F']  # æ”¯æŒæœ€å¤š6ä¸ªé€‰é¡¹
    options_text = []
    for i, option in enumerate(options[:6]):  # æœ€å¤š6ä¸ªé€‰é¡¹
        if i < len(option_labels):
            options_text.append(f"{option_labels[i]}. {option}")
    
    options_str = '\n'.join(options_text)
    
    # æ„å»ºè¾“å…¥æ–‡æœ¬
    input_text = f"Question: {question}\nOptions:\n{options_str}"
    
    # ç¡®å®šç­”æ¡ˆ
    if target_idx >= 0 and target_idx < len(option_labels) and target_idx < len(options):
        answer = option_labels[target_idx]
    else:
        answer = "æ— ç­”æ¡ˆ"
    
    return {
        "instruction": "Choose the best answer for the following question.",
        "input": input_text,
        "output": answer,
        "dataset": item['dataset'],
        "task_type": item['task_type'],
        "id": item['id']
    }

def format_for_yes_no(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¼å¼åŒ–ä¸ºæ˜¯éé¢˜è®­ç»ƒæ ¼å¼
    """
    
    input_text = item['input']
    target_idx = item['target_idx']
    
    # å¯¹äºBoolQï¼Œç­”æ¡ˆæ˜¯True/False
    if target_idx == 1:
        answer = "True"
    elif target_idx == 0:
        answer = "False"
    else:
        answer = "Unknown"
    
    return {
        "instruction": "Answer the following yes/no question with True or False.",
        "input": input_text,
        "output": answer,
        "dataset": item['dataset'],
        "task_type": item['task_type'],
        "id": item['id']
    }

def format_for_completion(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¼å¼åŒ–ä¸ºå¥å­è¡¥å…¨ä»»åŠ¡
    """
    
    context = item['input']
    options = item['options']
    target_idx = item['target_idx']
    
    # æ„å»ºé€‰é¡¹æ–‡æœ¬
    option_labels = ['A', 'B', 'C', 'D', 'E', 'F']
    options_text = []
    for i, option in enumerate(options[:6]):
        if i < len(option_labels):
            options_text.append(f"{option_labels[i]}. {option}")
    
    options_str = '\n'.join(options_text)
    
    input_text = f"Context: {context}\nChoose the best continuation:\n{options_str}"
    
    # ç¡®å®šç­”æ¡ˆ
    if target_idx >= 0 and target_idx < len(option_labels) and target_idx < len(options):
        answer = option_labels[target_idx]
    else:
        answer = "æ— ç­”æ¡ˆ"
    
    return {
        "instruction": "Choose the best continuation for the given context.",
        "input": input_text,
        "output": answer,
        "dataset": item['dataset'],
        "task_type": item['task_type'],
        "id": item['id']
    }

def format_item_for_training(item: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¹æ®ä»»åŠ¡ç±»å‹æ ¼å¼åŒ–å•ä¸ªæ•°æ®é¡¹"""
    
    task_type = item['task_type']
    
    if task_type == 'yes_no_question':
        return format_for_yes_no(item)
    elif task_type in ['sentence_completion']:
        return format_for_completion(item)
    else:
        # å…¶ä»–ä»»åŠ¡ç±»å‹éƒ½ä½¿ç”¨å¤šé€‰é¢˜æ ¼å¼
        return format_for_multiple_choice(item)

def create_training_format(
    input_file: str,
    output_file: str,
    max_samples: int = None
) -> Dict[str, Any]:
    """
    å°†æ¸…æ´—åçš„æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶ï¼ˆæ¸…æ´—åçš„æ•°æ®ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºåˆ›å»ºå­é›†ï¼‰
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯
    """
    
    print(f"ğŸ”„ å¼€å§‹æ ¼å¼åŒ–è®­ç»ƒæ•°æ®: {input_file}")
    
    # åŠ è½½æ¸…æ´—åçš„æ•°æ®
    cleaned_data = load_jsonl(input_file)
    print(f"ğŸ“¥ åŠ è½½äº† {len(cleaned_data)} ä¸ªæ¸…æ´—æ ·æœ¬")
    
    # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if max_samples and len(cleaned_data) > max_samples:
        import random
        random.seed(42)
        cleaned_data = random.sample(cleaned_data, max_samples)
        print(f"ğŸ¯ éšæœºé‡‡æ · {max_samples} ä¸ªæ ·æœ¬")
    
    # æ ¼å¼åŒ–æ•°æ®
    training_data = []
    failed_count = 0
    
    for i, item in enumerate(cleaned_data):
        try:
            formatted_item = format_item_for_training(item)
            training_data.append(formatted_item)
        except Exception as e:
            failed_count += 1
            print(f"âš ï¸  æ ·æœ¬ {i} æ ¼å¼åŒ–å¤±è´¥: {str(e)[:100]}...")
    
    print(f"âœ… æ ¼å¼åŒ–å®Œæˆ: {len(training_data)} ä¸ªè®­ç»ƒæ ·æœ¬, {failed_count} ä¸ªå¤±è´¥")
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    save_jsonl(training_data, output_file)
    print(f"ğŸ’¾ è®­ç»ƒæ•°æ®ä¿å­˜åˆ°: {output_file}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_samples': len(training_data),
        'failed_samples': failed_count,
        'dataset_distribution': {},
        'task_type_distribution': {},
        'instruction_types': {}
    }
    
    # ç»Ÿè®¡åˆ†å¸ƒ
    for item in training_data:
        dataset = item['dataset']
        task_type = item['task_type']
        instruction = item['instruction']
        
        stats['dataset_distribution'][dataset] = stats['dataset_distribution'].get(dataset, 0) + 1
        stats['task_type_distribution'][task_type] = stats['task_type_distribution'].get(task_type, 0) + 1
        stats['instruction_types'][instruction] = stats['instruction_types'].get(instruction, 0) + 1
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š è®­ç»ƒæ•°æ®ç»Ÿè®¡:")
    print("=" * 60)
    print("æŒ‰æ•°æ®é›†åˆ†å¸ƒ:")
    for dataset, count in sorted(stats['dataset_distribution'].items()):
        percentage = (count / len(training_data) * 100) if len(training_data) > 0 else 0
        print(f"  {dataset:15}: {count:6,} æ ·æœ¬ ({percentage:5.1f}%)")
    
    print("\næŒ‰ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, count in sorted(stats['task_type_distribution'].items()):
        percentage = (count / len(training_data) * 100) if len(training_data) > 0 else 0
        print(f"  {task_type:20}: {count:6,} æ ·æœ¬ ({percentage:5.1f}%)")
    
    print("\næŒ‰æŒ‡ä»¤ç±»å‹åˆ†å¸ƒ:")
    for instruction, count in sorted(stats['instruction_types'].items()):
        percentage = (count / len(training_data) * 100) if len(training_data) > 0 else 0
        print(f"  {count:6,} æ ·æœ¬ ({percentage:5.1f}%): {instruction[:50]}...")
    
    return stats

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ ¼å¼åŒ–æ•°æ®ä¸ºè®­ç»ƒæ ¼å¼")
    parser.add_argument("--input_file", type=str, default="raw_datasets/commonsense/cs_all_cleaned.jsonl",
                       help="è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ¸…æ´—åçš„æ•°æ®ï¼‰")
    parser.add_argument("--output_file", type=str, default="raw_datasets/commonsense/cs_all_training.jsonl",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max_samples", type=int, default=None,
                       help="æœ€å¤§æ ·æœ¬æ•°")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒæ ¼å¼
    stats = create_training_format(
        input_file=args.input_file,
        output_file=args.output_file,
        max_samples=args.max_samples
    )
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = args.output_file.replace('.jsonl', '_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")

if __name__ == "__main__":
    main()
