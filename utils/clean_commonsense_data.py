"""
clean_commonsense_data.py
æ¸…æ´—å’Œç»Ÿä¸€commonsenseæ•°æ®é›†æ ¼å¼ï¼Œä½¿å…¶é€‚åˆè®­ç»ƒä½¿ç”¨
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Any, Optional

def load_jsonl(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½JSONLæ–‡ä»¶"""
    data = []
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    data.append(json.loads(line))
    return data

def save_jsonl(data: List[Dict[str, Any]], file_path: str):
    """ä¿å­˜æ•°æ®åˆ°JSONLæ–‡ä»¶"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦"""
    if not text:
        return ""
    
    # å»é™¤å¤šä½™çš„ç©ºæ ¼
    text = ' '.join(text.split())
    
    # å»é™¤ä¸€äº›ç‰¹æ®Šçš„æ ‡è®°ï¼ˆå¦‚HellaSwagä¸­çš„[header]ç­‰ï¼‰
    # ä½†ä¿ç•™æœ‰æ„ä¹‰çš„å†…å®¹
    text = text.replace('\n', ' ').replace('\t', ' ')
    
    return text.strip()

def extract_clean_format(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä»åŸå§‹æ•°æ®ä¸­æå–å¹¶æ¸…æ´—ä¸ºç»Ÿä¸€æ ¼å¼
    
    ç»Ÿä¸€æ ¼å¼åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
    - id: æ ·æœ¬IDï¼ˆå¦‚æœæœ‰ï¼‰
    - dataset: æ•°æ®é›†åç§°
    - task_type: ä»»åŠ¡ç±»å‹
    - input: è¾“å…¥æ–‡æœ¬ï¼ˆé—®é¢˜ + ä¸Šä¸‹æ–‡ï¼‰
    - options: é€‰é¡¹åˆ—è¡¨
    - target: æ­£ç¡®ç­”æ¡ˆ
    - target_idx: æ­£ç¡®ç­”æ¡ˆç´¢å¼•
    """
    
    dataset_source = item.get('dataset_source', 'unknown')
    original_data = item.get('original_data', {})
    
    # åŸºç¡€ä¿¡æ¯
    cleaned_item = {
        'id': original_data.get('id', original_data.get('ind', f"{dataset_source}_{hash(str(original_data)) % 10000}")),
        'dataset': dataset_source,
        'task_type': get_task_type(dataset_source),
    }
    
    if dataset_source in ['arc-challenge', 'arc-easy']:
        # ARC æ ¼å¼å¤„ç†
        question = clean_text(item.get('question', ''))
        choices = [clean_text(choice) for choice in item.get('choices', [])]
        answer = item.get('answer', '')
        answer_idx = item.get('answer_index', -1)
        
        cleaned_item.update({
            'input': question,
            'options': choices,
            'target': answer,
            'target_idx': answer_idx
        })
        
    elif dataset_source == 'boolq':
        # BoolQ æ ¼å¼å¤„ç†
        question = clean_text(item.get('question', ''))
        passage = clean_text(item.get('passage', ''))
        answer = item.get('answer', '')
        answer_idx = item.get('answer_index', -1)
        
        # ç»„åˆé—®é¢˜å’Œä¸Šä¸‹æ–‡
        input_text = f"{passage} Question: {question}" if passage else question
        
        cleaned_item.update({
            'input': input_text,
            'options': ['False', 'True'],
            'target': answer,
            'target_idx': answer_idx
        })
        
    elif dataset_source == 'hellaswag':
        # HellaSwag æ ¼å¼å¤„ç†
        context = clean_text(item.get('question', ''))  # åœ¨æˆ‘ä»¬çš„æ ¼å¼ä¸­ï¼Œquestionå­—æ®µå­˜å‚¨çš„æ˜¯ctx
        choices = [clean_text(choice) for choice in item.get('choices', [])]
        answer = clean_text(item.get('answer', ''))
        answer_idx = item.get('answer_index', -1)
        
        cleaned_item.update({
            'input': context,
            'options': choices,
            'target': answer,
            'target_idx': answer_idx
        })
        
    elif dataset_source == 'openbookqa':
        # OpenBookQA æ ¼å¼å¤„ç†
        question = clean_text(item.get('question', ''))
        choices = [clean_text(choice) for choice in item.get('choices', [])]
        answer = item.get('answer', '')
        answer_idx = item.get('answer_index', -1)
        
        cleaned_item.update({
            'input': question,
            'options': choices,
            'target': answer,
            'target_idx': answer_idx
        })
        
    elif dataset_source == 'piqa':
        # PIQA æ ¼å¼å¤„ç†
        goal = clean_text(item.get('question', ''))  # åœ¨æˆ‘ä»¬çš„æ ¼å¼ä¸­ï¼Œquestionå­—æ®µå­˜å‚¨çš„æ˜¯goal
        choices = [clean_text(choice) for choice in item.get('choices', [])]
        
        # PIQAæ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸º-1æˆ–è€…åŸºäºæŸç§å¯å‘å¼æ–¹æ³•
        answer_idx = item.get('answer_index', -1)
        answer = choices[answer_idx] if answer_idx >= 0 and answer_idx < len(choices) else ""
        
        cleaned_item.update({
            'input': goal,
            'options': choices,
            'target': answer,
            'target_idx': answer_idx
        })
        
    elif dataset_source == 'winogrande':
        # WinoGrande æ ¼å¼å¤„ç†
        sentence = clean_text(item.get('question', ''))  # åœ¨æˆ‘ä»¬çš„æ ¼å¼ä¸­ï¼Œquestionå­—æ®µå­˜å‚¨çš„æ˜¯sentence
        choices = [clean_text(choice) for choice in item.get('choices', [])]
        answer = item.get('answer', '')
        
        # å¤„ç†ç­”æ¡ˆç´¢å¼•
        if answer == '1':
            answer_idx = 0
        elif answer == '2':
            answer_idx = 1
        else:
            answer_idx = item.get('answer_index', -1)
        
        target_answer = choices[answer_idx] if answer_idx >= 0 and answer_idx < len(choices) else ""
        
        cleaned_item.update({
            'input': sentence,
            'options': choices,
            'target': target_answer,
            'target_idx': answer_idx
        })
    
    else:
        # æœªçŸ¥æ ¼å¼ï¼Œå°½é‡ä¿æŒåŸæœ‰ä¿¡æ¯
        cleaned_item.update({
            'input': clean_text(str(item.get('question', ''))),
            'options': item.get('choices', []),
            'target': str(item.get('answer', '')),
            'target_idx': item.get('answer_index', -1)
        })
    
    return cleaned_item

def get_task_type(dataset_source: str) -> str:
    """æ ¹æ®æ•°æ®é›†åç§°è¿”å›ä»»åŠ¡ç±»å‹"""
    task_types = {
        'arc-challenge': 'multiple_choice_science',
        'arc-easy': 'multiple_choice_science',
        'boolq': 'yes_no_question',
        'hellaswag': 'sentence_completion',
        'openbookqa': 'multiple_choice_science',
        'piqa': 'physical_reasoning',
        'winogrande': 'pronoun_resolution'
    }
    return task_types.get(dataset_source, 'unknown')

def validate_cleaned_item(item: Dict[str, Any]) -> bool:
    """éªŒè¯æ¸…æ´—åçš„æ•°æ®é¡¹æ˜¯å¦æœ‰æ•ˆ"""
    required_fields = ['id', 'dataset', 'task_type', 'input', 'options', 'target', 'target_idx']
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    for field in required_fields:
        if field not in item:
            return False
    
    # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
    if not item['input'].strip():
        return False
    
    # æ£€æŸ¥é€‰é¡¹æ˜¯å¦ä¸ºåˆ—è¡¨ä¸”ä¸ä¸ºç©º
    if not isinstance(item['options'], list) or len(item['options']) == 0:
        return False
    
    # æ£€æŸ¥ç­”æ¡ˆç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆ-1è¡¨ç¤ºæ— ç­”æ¡ˆä¹Ÿæ˜¯æœ‰æ•ˆçš„ï¼‰
    target_idx = item['target_idx']
    if target_idx != -1 and (target_idx < 0 or target_idx >= len(item['options'])):
        return False
    
    return True

def clean_commonsense_dataset(
    input_file: str,
    output_file: str,
    validation_split: float = 0.0
) -> Dict[str, Any]:
    """
    æ¸…æ´—commonsenseæ•°æ®é›†
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        validation_split: éªŒè¯é›†æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    
    print(f"ğŸ”„ å¼€å§‹æ¸…æ´—æ•°æ®é›†: {input_file}")
    
    # åŠ è½½åŸå§‹æ•°æ®
    raw_data = load_jsonl(input_file)
    print(f"ğŸ“¥ åŠ è½½äº† {len(raw_data)} ä¸ªåŸå§‹æ ·æœ¬")
    
    # æ¸…æ´—æ•°æ®
    cleaned_data = []
    invalid_count = 0
    dataset_stats = {}
    
    for i, item in enumerate(raw_data):
        try:
            cleaned_item = extract_clean_format(item)
            
            # éªŒè¯æ¸…æ´—åçš„æ•°æ®
            if validate_cleaned_item(cleaned_item):
                cleaned_data.append(cleaned_item)
                
                # ç»Ÿè®¡å„æ•°æ®é›†çš„æ•°é‡
                dataset = cleaned_item['dataset']
                dataset_stats[dataset] = dataset_stats.get(dataset, 0) + 1
            else:
                invalid_count += 1
                print(f"âš ï¸  æ ·æœ¬ {i} éªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                
        except Exception as e:
            invalid_count += 1
            print(f"âš ï¸  æ ·æœ¬ {i} å¤„ç†å¤±è´¥: {str(e)[:100]}...")
    
    print(f"âœ… æ¸…æ´—å®Œæˆ: {len(cleaned_data)} ä¸ªæœ‰æ•ˆæ ·æœ¬, {invalid_count} ä¸ªæ— æ•ˆæ ·æœ¬")
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    if validation_split > 0.0:
        import random
        random.shuffle(cleaned_data)
        split_idx = int(len(cleaned_data) * (1 - validation_split))
        
        train_data = cleaned_data[:split_idx]
        val_data = cleaned_data[split_idx:]
        
        # ä¿å­˜è®­ç»ƒé›†
        train_file = output_file.replace('.jsonl', '_train.jsonl')
        save_jsonl(train_data, train_file)
        print(f"ğŸ’¾ è®­ç»ƒé›†ä¿å­˜åˆ°: {train_file} ({len(train_data)} æ ·æœ¬)")
        
        # ä¿å­˜éªŒè¯é›†
        val_file = output_file.replace('.jsonl', '_val.jsonl')
        save_jsonl(val_data, val_file)
        print(f"ğŸ’¾ éªŒè¯é›†ä¿å­˜åˆ°: {val_file} ({len(val_data)} æ ·æœ¬)")
        
        final_data = train_data
    else:
        # ä¿å­˜å…¨éƒ¨æ•°æ®
        save_jsonl(cleaned_data, output_file)
        print(f"ğŸ’¾ æ¸…æ´—åæ•°æ®ä¿å­˜åˆ°: {output_file}")
        final_data = cleaned_data
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_samples': len(final_data),
        'invalid_samples': invalid_count,
        'dataset_distribution': dataset_stats,
        'task_type_distribution': {},
        'validation_split': validation_split
    }
    
    # ç»Ÿè®¡ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
    for item in final_data:
        task_type = item['task_type']
        stats['task_type_distribution'][task_type] = stats['task_type_distribution'].get(task_type, 0) + 1
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ¸…æ´—åæ•°æ®ç»Ÿè®¡:")
    print("=" * 50)
    print("æŒ‰æ•°æ®é›†åˆ†å¸ƒ:")
    for dataset, count in sorted(dataset_stats.items()):
        percentage = (count / len(final_data) * 100) if len(final_data) > 0 else 0
        print(f"  {dataset:15}: {count:6,} æ ·æœ¬ ({percentage:5.1f}%)")
    
    print("\næŒ‰ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, count in sorted(stats['task_type_distribution'].items()):
        percentage = (count / len(final_data) * 100) if len(final_data) > 0 else 0
        print(f"  {task_type:20}: {count:6,} æ ·æœ¬ ({percentage:5.1f}%)")
    
    return stats

def create_sample_file(input_file: str, output_file: str, sample_size: int = 100):
    """åˆ›å»ºæ ·æœ¬æ–‡ä»¶ç”¨äºæ£€æŸ¥æ¸…æ´—æ•ˆæœ"""
    data = load_jsonl(input_file)
    if data:
        sample_data = data[:sample_size]
        save_jsonl(sample_data, output_file)
        print(f"ğŸ“‹ å·²åˆ›å»ºæ ·æœ¬æ–‡ä»¶: {output_file} ({len(sample_data)} æ ·æœ¬)")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¸…æ´—commonsenseæ•°æ®é›†")
    parser.add_argument("--input_file", type=str, default="raw_datasets/commonsense/cs_all.jsonl",
                       help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_file", type=str, default="raw_datasets/commonsense/cs_all_cleaned.jsonl",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--validation_split", type=float, default=0.0,
                       help="éªŒè¯é›†æ¯”ä¾‹ (0.0-1.0)")
    parser.add_argument("--create_sample", action="store_true",
                       help="åˆ›å»ºæ ·æœ¬æ–‡ä»¶")
    parser.add_argument("--sample_size", type=int, default=100,
                       help="æ ·æœ¬æ–‡ä»¶å¤§å°")
    
    args = parser.parse_args()
    
    # æ¸…æ´—æ•°æ®é›†
    stats = clean_commonsense_dataset(
        input_file=args.input_file,
        output_file=args.output_file,
        validation_split=args.validation_split
    )
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = args.output_file.replace('.jsonl', '_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
    
    # åˆ›å»ºæ ·æœ¬æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.create_sample:
        sample_file = args.output_file.replace('.jsonl', '_sample.jsonl')
        create_sample_file(args.output_file, sample_file, args.sample_size)

if __name__ == "__main__":
    main()
