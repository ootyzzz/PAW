#!/usr/bin/env python3
"""
train_cs_lora_lightning.py
PyTorch Lightning + SwanLab ç‰ˆæœ¬çš„ LoRA è®­ç»ƒè„šæœ¬
ç°ä»£åŒ–è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå®æ—¶ç›‘æ§å’Œå®éªŒç®¡ç†

======================================================================
ğŸš€ ä½¿ç”¨æ–¹æ³• (ä¸åŸç‰ˆå…¼å®¹çš„å‘½ä»¤è¡Œæ¥å£):
======================================================================

# åŸºæœ¬è®­ç»ƒå‘½ä»¤
python train_cs_lora_lightning.py --dataset arc-challenge
python train_cs_lora_lightning.py --dataset arc-easy
python train_cs_lora_lightning.py --dataset boolq
python train_cs_lora_lightning.py --dataset hellaswag
python train_cs_lora_lightning.py --dataset openbookqa
python train_cs_lora_lightning.py --dataset piqa
python train_cs_lora_lightning.py --dataset winogrande

# è‡ªå®šä¹‰å‚æ•°
python train_cs_lora_lightning.py --dataset arc-challenge --batch_size 16
python train_cs_lora_lightning.py --dataset arc-challenge --dry_run

# SwanLab å›¢é˜Ÿåä½œé…ç½®
python train_cs_lora_lightning.py --dataset arc-challenge --swanlab_project "team-lora-experiments"
python train_cs_lora_lightning.py --dataset arc-challenge --swanlab_project "team-lora-experiments" --swanlab_workspace "your-team-name"

# æ‰¹é‡æ‰§è¡Œ (PowerShell)
foreach ($dataset in @("arc-challenge", "arc-easy", "boolq", "hellaswag", "openbookqa", "piqa", "winogrande")) {
    Write-Host "ğŸš€ å¼€å§‹è®­ç»ƒ $dataset..."
    python train_cs_lora_lightning.py --dataset $dataset --swanlab_project "team-lora-experiments"
    Write-Host "âœ… $dataset è®­ç»ƒå®Œæˆ"
}

======================================================================

ä¸»è¦ç‰¹æ€§:
âœ… PyTorch Lightning: ç°ä»£åŒ–è®­ç»ƒæ¡†æ¶ï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡ã€åˆ†å¸ƒå¼ç­‰
âœ… SwanLab é›†æˆ: å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼Œå®éªŒç®¡ç†å’Œå¯¹æ¯”  
âœ… ä¸»æµä¿å­˜æ–¹å¼: éµå¾ª HuggingFace/Lightning æœ€ä½³å®è·µ
âœ… å…¼å®¹ç°æœ‰æ¥å£: å‘½ä»¤è¡Œå‚æ•°ä¸åŸç‰ˆå®Œå…¨å…¼å®¹
âœ… ç®€åŒ–æ¶æ„: ç§»é™¤å¤æ‚çš„ batch è¿½è¸ªï¼Œä¸“æ³¨æ ¸å¿ƒè®­ç»ƒ
âœ… è‡ªåŠ¨æ··åˆç²¾åº¦: æå‡è®­ç»ƒæ•ˆç‡
âœ… çµæ´»çš„å›è°ƒç³»ç»Ÿ: æ˜“äºæ‰©å±•å’Œè‡ªå®šä¹‰

ç›®å½•ç»“æ„ (Lightning + SwanLab é£æ ¼):
./runs/                          # ä¸»å®éªŒç›®å½•
â”œâ”€â”€ {experiment_name}/           # å•ä¸ªå®éªŒ
â”‚   â”œâ”€â”€ checkpoints/             # Lightning checkpoints (.ckpt)
â”‚   â”œâ”€â”€ tensorboard_logs/        # TensorBoard æ—¥å¿— 
â”‚   â”œâ”€â”€ swanlab_logs/           # SwanLab æ—¥å¿—
â”‚   â”œâ”€â”€ final_model/            # æœ€ç»ˆ HuggingFace æ ¼å¼æ¨¡å‹
â”‚   â””â”€â”€ config.yaml             # å®éªŒé…ç½®
â””â”€â”€ swanlab_workspace/          # SwanLab å·¥ä½œåŒº

å¯¹æ¯”ä¼ ç»Ÿ experiments/ ç›®å½•çš„ä¼˜åŠ¿:
- æ›´è§„èŒƒçš„å®éªŒç®¡ç†
- æ”¯æŒå¤šç§æ—¥å¿—æ ¼å¼
- ä¾¿äºç‰ˆæœ¬æ§åˆ¶å’Œåˆ†äº«
- ç¬¦åˆç¤¾åŒºæœ€ä½³å®è·µ
"""

import os
import sys
import json
import yaml
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional, Union, Tuple

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import pytorch_lightning as pl
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
import swanlab

from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup
from peft import LoraConfig, get_peft_model, TaskType

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

def custom_collate_fn(batch):
    """è‡ªå®šä¹‰collateå‡½æ•°ï¼Œä¿æŒå­—å…¸ç»“æ„"""
    return batch


def get_test_file_path(dataset_name: str) -> Tuple[str, bool]:
    """
    æ™ºèƒ½é€‰æ‹©æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼Œä¼˜å…ˆtestï¼Œä¸å­˜åœ¨åˆ™ä½¿ç”¨validation
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        
    Returns:
        tuple: (æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä½¿ç”¨validation)
    """
    data_dir = f"data_to_lora/cs/{dataset_name}"
    test_file = f"{data_dir}/{dataset_name}_test_formatted.jsonl"
    validation_file = f"{data_dir}/{dataset_name}_validation_formatted.jsonl"
    
    if os.path.exists(test_file):
        return test_file, False
    elif os.path.exists(validation_file):
        print(f"ğŸ“Š æ³¨æ„: {dataset_name} æ²¡æœ‰testæ–‡ä»¶ï¼Œå°†ä½¿ç”¨validationæ–‡ä»¶ä½œä¸ºæµ‹è¯•é›†")
        return validation_file, True
    else:
        # è¿”å›é»˜è®¤testè·¯å¾„ï¼Œè®©åç»­å¤„ç†æŠ¥é”™
        return test_file, False


class SequentialDataset(Dataset):
    """å®Œæ•´çš„æ•°æ®é›†ç±»ï¼Œæ”¯æŒtrain/validation/test"""
    
    def __init__(self, data_file: str, dataset_name: str, split: str = "train"):
        self.data_file = data_file
        self.dataset_name = dataset_name
        self.split = split
        self.data = self._load_data()
        self.total_samples = len(self.data)
        
    def _load_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ•°æ®ï¼Œä¿æŒåŸå§‹é¡ºåº"""
        data = []
        if not os.path.exists(self.data_file):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_file}")
            
        with open(self.data_file, 'r', encoding='utf-8') as f:
            for line_idx, line in enumerate(f):
                line = line.strip()
                if line:
                    try:
                        item = json.loads(line)
                        data.append(item)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆè¡Œ {line_idx}: {e}")
                        
        print(f"ğŸ“Š åŠ è½½{self.split}æ•°æ®é›† {self.dataset_name}: {len(data)} æ ·æœ¬")
        return data
    
    def __len__(self):
        return self.total_samples
    
    def __getitem__(self, idx):
        # æ”¯æŒè¶…è¿‡æ•°æ®é›†é•¿åº¦çš„å¾ªç¯è®¿é—®ï¼ˆä¸»è¦ç”¨äºè®­ç»ƒé›†ï¼‰
        if self.split == "train":
            actual_idx = idx % self.total_samples
        else:
            # éªŒè¯å’Œæµ‹è¯•é›†ä¸å¾ªç¯è®¿é—®
            actual_idx = idx
        return self.data[actual_idx].copy()


class TrainTestDataModule(pl.LightningDataModule):
    """Lightningæ•°æ®æ¨¡å—ï¼Œç®¡ç†train/testæ•°æ®ï¼ˆè‡ªåŠ¨é€‚é…validationä½œä¸ºtestï¼‰"""
    
    def __init__(self, dataset_name: str, batch_size: int = 4, test_mode: bool = False):
        super().__init__()
        self.dataset_name = dataset_name
        self.batch_size = batch_size
        self.test_mode = test_mode
        
        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.data_dir = f"data_to_lora/cs/{dataset_name}"
        self.train_file = f"{self.data_dir}/{dataset_name}_train_formatted.jsonl"
        
        # æ™ºèƒ½é€‰æ‹©æµ‹è¯•æ–‡ä»¶ï¼šä¼˜å…ˆtestï¼Œä¸å­˜åœ¨åˆ™ä½¿ç”¨validation
        self.test_file, self.using_validation_as_test = get_test_file_path(dataset_name)
        
    def setup(self, stage: str = None):
        """è®¾ç½®æ•°æ®é›†"""
        if stage == "fit" or stage is None:
            self.train_dataset = SequentialDataset(self.train_file, self.dataset_name, "train")
            
        if stage == "test" or stage is None:
            self.test_dataset = SequentialDataset(self.test_file, self.dataset_name, "test")
    
    def train_dataloader(self):
        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=False,  # ä¿æŒé¡ºåº
            num_workers=0 if self.test_mode else 4,
            pin_memory=not self.test_mode,
            drop_last=False,
            collate_fn=custom_collate_fn
        )
    
    def test_dataloader(self):
        return DataLoader(
            self.test_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=0 if self.test_mode else 4,
            pin_memory=not self.test_mode,
            drop_last=False,
            collate_fn=custom_collate_fn
        )


class LoRALightningModule(pl.LightningModule):
    """Lightning LoRA è®­ç»ƒæ¨¡å—"""
    
    def __init__(
        self,
        model_path: str,
        lora_config: Dict[str, Any],
        learning_rate_stage1: float = 1e-4,
        learning_rate_stage2: float = 1e-5,
        stage1_steps: int = 75,
        stage2_steps: int = 50,
        max_length: int = 512,
        **kwargs
    ):
        super().__init__()
        self.save_hyperparameters()
        
        self.model_path = model_path
        self.lora_config = lora_config
        self.learning_rate_stage1 = learning_rate_stage1
        self.learning_rate_stage2 = learning_rate_stage2
        self.stage1_steps = stage1_steps
        self.stage2_steps = stage2_steps
        self.max_length = max_length
        self.total_steps = stage1_steps + stage2_steps
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œ tokenizer
        self._init_model()
        
        # è®­ç»ƒçŠ¶æ€è·Ÿè¸ª
        self.training_step_count = 0
        
    def _init_model(self):
        """åˆå§‹åŒ–æ¨¡å‹å’Œtokenizer"""
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {self.model_path}")

        # å¹³è¡¡ç²¾åº¦å’Œæ€§èƒ½ï¼Œæ¨èå¤§å¤šæ•°åœºæ™¯
        if torch.cuda.is_available():
            torch.set_float32_matmul_precision('medium')  

        # åŠ è½½ tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path, trust_remote_code=True)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        self.base_model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map=None,  # Lightning ä¼šå¤„ç†è®¾å¤‡åˆ†é…
            trust_remote_code=True
        )
        
        # åº”ç”¨ LoRA
        lora_config = LoraConfig(**self.lora_config)
        self.model = get_peft_model(self.base_model, lora_config)
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        # è·å–å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡
        trainable_params, total_params = self.model.get_nb_trainable_parameters()
        print(f"ğŸ“Š å¯è®­ç»ƒå‚æ•°: {trainable_params:,} / {total_params:,} ({trainable_params/total_params*100:.2f}%)")
        
    def forward(self, input_ids, attention_mask, labels):
        """å‰å‘ä¼ æ’­"""
        outputs = self.model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        return outputs
    
    def training_step(self, batch, batch_idx):
        """è®­ç»ƒæ­¥éª¤"""
        loss = self._compute_loss(batch, "train")
        batch_size = len(batch) if isinstance(batch, list) else batch['input_ids'].size(0)
        
        # è®°å½•è®­ç»ƒæŒ‡æ ‡
        self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True, batch_size=batch_size)
        self.log('train/step', self.training_step_count, on_step=True, batch_size=batch_size)
        
        # è®°å½•å­¦ä¹ ç‡é˜¶æ®µä¿¡æ¯
        current_stage = 1 if self.training_step_count < self.stage1_steps else 2
        self.log('train/stage', current_stage, on_step=True, batch_size=batch_size)
        
        # è®°å½•åˆ° SwanLab
        if hasattr(self, '_swanlab_run'):
            swanlab.log({
                "train/loss": loss.item(),
                "train/step": self.training_step_count,
                "train/stage": current_stage,
                "train/epoch": self.current_epoch
            }, step=self.training_step_count)
        
        self.training_step_count += 1
        return loss
    
    def validation_step(self, batch, batch_idx):
        """éªŒè¯æ­¥éª¤ï¼ˆå·²ç§»é™¤ï¼Œå› ä¸ºè®­ç»ƒæ­¥æ•°<1 epochï¼‰"""
        pass  # ä¸å†éœ€è¦éªŒè¯æ­¥éª¤
        
    def test_step(self, batch, batch_idx):
        """æµ‹è¯•æ­¥éª¤"""
        loss = self._compute_loss(batch, "test")
        batch_size = len(batch) if isinstance(batch, list) else batch['input_ids'].size(0)
        accuracy = self._compute_accuracy(batch)
        perplexity = torch.exp(loss)
        
        # è®°å½•æµ‹è¯•æŒ‡æ ‡
        self.log('test/loss', loss, on_step=False, on_epoch=True, batch_size=batch_size)
        self.log('test/accuracy', accuracy, on_step=False, on_epoch=True, batch_size=batch_size)
        self.log('test/perplexity', perplexity, on_step=False, on_epoch=True, batch_size=batch_size)
        
        return {
            'test_loss': loss,
            'test_accuracy': accuracy,
            'test_perplexity': perplexity
        }
    
    def on_validation_epoch_end(self):
        """éªŒè¯epochç»“æŸæ—¶çš„å›è°ƒï¼ˆå·²ç§»é™¤ï¼‰"""
        pass  # ä¸å†éœ€è¦
    
    def on_test_epoch_end(self):
        """æµ‹è¯•epochç»“æŸæ—¶çš„å›è°ƒ"""
        if hasattr(self, '_swanlab_run'):
            # è®°å½•æµ‹è¯•æŒ‡æ ‡åˆ°SwanLab
            test_loss = self.trainer.callback_metrics.get('test/loss')
            test_acc = self.trainer.callback_metrics.get('test/accuracy') 
            test_ppl = self.trainer.callback_metrics.get('test/perplexity')
            
            if test_loss is not None:
                swanlab.log({
                    "test/loss": test_loss.item(),
                    "test/accuracy": test_acc.item() if test_acc is not None else 0,
                    "test/perplexity": test_ppl.item() if test_ppl is not None else 0,
                    "final_epoch": self.current_epoch
                }, step=self.training_step_count)
    
    def _compute_loss(self, batch, stage: str):
        """è®¡ç®—æŸå¤±çš„é€šç”¨æ–¹æ³•"""
        # å¤„ç†batchæ•°æ®
        if isinstance(batch, list):
            # å¦‚æœæ˜¯listï¼Œéœ€è¦tokenize
            inputs = []
            labels = []
            
            for item in batch:
                input_text = item.get('input', '')
                output_text = item.get('output', '')
                
                # ç»„åˆè¾“å…¥å’Œè¾“å‡º
                full_text = f"{input_text}{output_text}"
                
                # Tokenize
                encoding = self.tokenizer(
                    full_text,
                    truncation=True,
                    padding='max_length',
                    max_length=self.max_length,
                    return_tensors='pt'
                )
                
                inputs.append(encoding['input_ids'].squeeze())
                labels.append(encoding['input_ids'].squeeze())
            
            input_ids = torch.stack(inputs).to(self.device)
            attention_mask = torch.ones_like(input_ids).to(self.device)
            labels = torch.stack(labels).to(self.device)
            
        else:
            # å¦‚æœå·²ç»æ˜¯tensoræ ¼å¼
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask'] 
            labels = batch['labels']
        
        # å‰å‘ä¼ æ’­
        outputs = self(input_ids, attention_mask, labels)
        return outputs.loss
    
    def _compute_accuracy(self, batch):
        """è®¡ç®—å‡†ç¡®ç‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„å‡†ç¡®ç‡è®¡ç®—
        # ç›®å‰è¿”å›ä¸€ä¸ªåŸºäºlossçš„ä»£ç†æŒ‡æ ‡
        with torch.no_grad():
            loss = self._compute_loss(batch, "eval")
            # å°†lossè½¬æ¢ä¸º0-1ä¹‹é—´çš„å‡†ç¡®ç‡ä»£ç†æŒ‡æ ‡
            accuracy = torch.exp(-loss)
            return torch.clamp(accuracy, 0.0, 1.0)
    
    def configure_optimizers(self):
        """é…ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.learning_rate_stage1,  # åˆå§‹å­¦ä¹ ç‡
            betas=(0.9, 0.999),
            eps=1e-8,
            weight_decay=0.01
        )
        
        # ä¸¤é˜¶æ®µå­¦ä¹ ç‡è°ƒåº¦å™¨
        def lr_lambda(current_step):
            if current_step < self.stage1_steps:
                # Stage 1: é«˜å­¦ä¹ ç‡
                return 1.0
            else:
                # Stage 2: ä½å­¦ä¹ ç‡
                return self.learning_rate_stage2 / self.learning_rate_stage1
        
        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
        
        return {
            "optimizer": optimizer,
            "lr_scheduler": {
                "scheduler": scheduler,
                "interval": "step",
            },
        }


class SwanLabLogger:
    """SwanLab Logger for Lightning"""
    
    def __init__(self, project_name: str, experiment_name: str, config: Dict[str, Any]):
        self.project_name = project_name
        self.experiment_name = experiment_name 
        self.config = config
        self._run = None
        
    def initialize_run(self):
        """åˆå§‹åŒ– SwanLab run"""
        if self._run is None:
            self._run = swanlab.init(
                project=self.project_name,
                experiment_name=self.experiment_name,
                config=self.config
            )
        return self._run


def get_optimal_batch_size(dataset_name: str, target_steps: int = 125) -> int:
    """æ ¹æ®æ•°æ®é›†å¤§å°è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜batch size"""
    dataset_sizes = {
        'arc-challenge': 1119,
        'arc-easy': 2251, 
        'boolq': 9427,
        'hellaswag': 39905,
        'openbookqa': 4957,
        'piqa': 16113,
        'winogrande': 40398
    }
    
    if dataset_name not in dataset_sizes:
        print(f"âš ï¸ æœªçŸ¥æ•°æ®é›† {dataset_name}ï¼Œä½¿ç”¨é»˜è®¤batch_size=32")
        return 32
    
    dataset_size = dataset_sizes[dataset_name]
    
    # é€‰æ‹©åˆé€‚çš„batch size
    if dataset_size <= 1200:  # å°æ•°æ®é›†
        return 8
    elif dataset_size <= 2500:  # ä¸­å°æ•°æ®é›†  
        return 16
    else:  # å¤§æ•°æ®é›†
        return 32


def analyze_batch_efficiency(dataset_name: str, batch_size: int, target_steps: int = 125):
    """åˆ†æbatch sizeæ•ˆç‡"""
    dataset_sizes = {
        'arc-challenge': 1119,
        'arc-easy': 2251, 
        'boolq': 9427,
        'hellaswag': 39905,
        'openbookqa': 4957,
        'piqa': 16113,
        'winogrande': 40398
    }
    
    if dataset_name not in dataset_sizes:
        return
        
    dataset_size = dataset_sizes[dataset_name]
    total_samples_needed = batch_size * target_steps
    epochs_needed = total_samples_needed / dataset_size
    
    print(f"ğŸ“Š Batchæ•ˆç‡åˆ†æ:")
    print(f"  - æ•°æ®é›†: {dataset_name} ({dataset_size} æ ·æœ¬)")
    print(f"  - Batchå¤§å°: {batch_size}")
    print(f"  - {target_steps}æ­¥éœ€è¦: {total_samples_needed} æ ·æœ¬")
    print(f"  - éœ€è¦å¾ªç¯: {epochs_needed:.2f} epochs")
    
    if epochs_needed <= 1.1:
        print(f"  âœ… æ•ˆç‡å¾ˆå¥½ï¼šå‡ ä¹æ— æ•°æ®é‡å¤")
    elif epochs_needed <= 2.0:
        print(f"  ğŸ”„ æ•ˆç‡ä¸€èˆ¬ï¼šå°‘é‡æ•°æ®é‡å¤") 
    else:
        print(f"  âš ï¸ æ•ˆç‡è¾ƒä½ï¼šå¤§é‡æ•°æ®é‡å¤")
    
    return epochs_needed


def create_lightning_config(dataset_name: str, base_config: Dict[str, Any], batch_size: int = None, max_steps: int = 125, save_steps: int = 50, learning_rate: float = 1e-4, learning_rate_stage2: float = None) -> Dict[str, Any]:
    """åˆ›å»ºLightningè®­ç»ƒé…ç½®"""
    config = base_config.copy()
    
    # è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜batch sizeï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if batch_size is None:
        batch_size = get_optimal_batch_size(dataset_name)
        print(f"ğŸ¯ è‡ªåŠ¨é€‰æ‹©batch_size={batch_size}ç”¨äº{dataset_name}")
    
    # åˆ†æbatchæ•ˆç‡
    analyze_batch_efficiency(dataset_name, batch_size, max_steps)
    
    # æ™ºèƒ½é€‰æ‹©æµ‹è¯•æ–‡ä»¶è·¯å¾„ - æ”¯æŒvalidationä½œä¸ºfallback
    test_file_path, using_validation = get_test_file_path(dataset_name)
    
    # æ›´æ–°æ•°æ®è·¯å¾„ - æ”¯æŒtrain/testæˆ–train/validationé…ç½®
    config['data']['train_file'] = f"data_to_lora/cs/{dataset_name}/{dataset_name}_train_formatted.jsonl"
    config['data']['test_file'] = test_file_path
    config['data']['using_validation_as_test'] = using_validation
    
    # ç”Ÿæˆå®éªŒåç§° - ä½¿ç”¨æ›´è§„èŒƒçš„å‘½å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"{dataset_name}_lora_{timestamp}"
    
    # Lightning + SwanLab ä¸“ç”¨é…ç½®
    stage1_ratio = 0.6  # 60% æ­¥æ•°ä¸ºStage 1
    stage1_steps = int(max_steps * stage1_ratio)
    stage2_steps = max_steps - stage1_steps
    
    # è‡ªåŠ¨è®¡ç®—ç¬¬äºŒé˜¶æ®µå­¦ä¹ ç‡
    if learning_rate_stage2 is None:
        learning_rate_stage2 = learning_rate / 10
    
    config['training'].update({
        'batch_size': batch_size,
        'max_steps': max_steps,  # ä½¿ç”¨å‚æ•°åŒ–çš„æ­¥æ•°
        'stage1_steps': stage1_steps,
        'stage2_steps': stage2_steps,
        'save_steps': save_steps,  # ä¿å­˜æœ€åå¤šå°‘æ­¥
        'learning_rate_stage1': learning_rate,
        'learning_rate_stage2': learning_rate_stage2,
    })
    
    # ç°ä»£åŒ–çš„è¾“å‡ºç›®å½•ç»“æ„
    base_dir = Path("./runs") / experiment_name
    config['paths'] = {
        'experiment_dir': str(base_dir),
        'checkpoints_dir': str(base_dir / "checkpoints"),
        'tensorboard_dir': str(base_dir / "tensorboard_logs"),
        'swanlab_dir': str(base_dir / "swanlab_logs"),
        'final_model_dir': str(base_dir / "final_model"),
        'config_file': str(base_dir / "config.yaml")
    }
    
    # å®éªŒå…ƒæ•°æ®
    config['experiment'] = {
        'name': experiment_name,
        'dataset': dataset_name,
        'batch_size': batch_size,
        'framework': 'lightning_swanlab',
        'created_at': datetime.now().isoformat(),
        'description': f"Lightning LoRA training on {dataset_name} - {max_steps} steps",
        'tags': ["lightning", "swanlab", "lora", "qwen2.5", dataset_name, f"batch{batch_size}", f"steps{max_steps}"]
    }
    
    return config


def setup_callbacks(config: Dict[str, Any]) -> List[pl.Callback]:
    """è®¾ç½®Lightningå›è°ƒï¼ˆç§»é™¤Early Stoppingå’Œvalidationç›¸å…³ï¼‰"""
    callbacks = []
    
    max_steps = config['training']['max_steps']
    save_steps = config['training']['save_steps']
    
    # æ¡ä»¶æ£€æŸ¥ç‚¹ä¿å­˜ï¼ˆæœ€åsave_stepsæ­¥ï¼‰- è¿™æ˜¯æ‚¨éœ€è¦çš„å…³é”®åŠŸèƒ½
    class ConditionalCheckpoint(ModelCheckpoint):
        def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
            # ä»ç¬¬ (max_steps - save_steps + 1) æ­¥å¼€å§‹ä¿å­˜
            save_start_step = max_steps - save_steps + 1
            if pl_module.training_step_count >= save_start_step:
                super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)
    
    conditional_checkpoint = ConditionalCheckpoint(
        dirpath=config['paths']['checkpoints_dir'],
        filename='checkpoint-step-{step:03d}',
        every_n_train_steps=1,
        save_top_k=-1,
        monitor=None  # ä¸åŸºäºæŒ‡æ ‡ï¼Œç›´æ¥ä¿å­˜
    )
    callbacks.append(conditional_checkpoint)
    
    # æœ€ç»ˆæ¨¡å‹æ£€æŸ¥ç‚¹ - åŸºäºè®­ç»ƒlossï¼ˆå› ä¸ºæ²¡æœ‰éªŒè¯é›†ï¼‰
    final_checkpoint = ModelCheckpoint(
        dirpath=config['paths']['checkpoints_dir'],
        filename='final-model-{epoch:02d}-{train/loss:.4f}',
        monitor='train/loss',
        mode='min',
        save_top_k=1,
        save_last=True,
        verbose=True
    )
    callbacks.append(final_checkpoint)
    
    # å­¦ä¹ ç‡ç›‘æ§
    lr_monitor = LearningRateMonitor(logging_interval='step')
    callbacks.append(lr_monitor)
    
    return callbacks


def run_lightning_training(
    dataset_name: str,
    config: Dict[str, Any],
    swanlab_project: str = None,
    swanlab_workspace: str = None,
    dry_run: bool = False
) -> Dict[str, Any]:
    """è¿è¡ŒLightningè®­ç»ƒ"""
    
    print(f"\n{'=' * 70}")
    print(f"ğŸš€ Lightning LoRA è®­ç»ƒ: {dataset_name}")
    print(f"{'=' * 70}")
    
    # éªŒè¯æ•°æ®æ–‡ä»¶
    train_file = config['data']['train_file']
    test_file = config['data']['test_file']
    using_validation_as_test = config['data'].get('using_validation_as_test', False)
    
    for file_path, file_type in [(train_file, "è®­ç»ƒ"), (test_file, "æµ‹è¯•")]:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"{file_type}æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    print(f"ğŸ“ è®­ç»ƒæ–‡ä»¶: {train_file}")
    if using_validation_as_test:
        print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶: {test_file} (ä½¿ç”¨validationä½œä¸ºtest)")
        print("ğŸ’¡ æ•°æ®é›†é…ç½®: é€‚é…åªæœ‰train/validationçš„æ•°æ®é›†")
    else:
        print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶: {test_file}")
    print(f"ğŸ¯ å®éªŒç›®å½•: {config['paths']['experiment_dir']}")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®: batch_size={config['training']['batch_size']}, steps={config['training']['max_steps']} ({config['training']['stage1_steps']}+{config['training']['stage2_steps']}) - ä¿å­˜æœ€å{config['training']['save_steps']}æ­¥")
    
    if dry_run:
        print("ğŸƒ Dry Run å®Œæˆ - å·²éªŒè¯:")
        print("  âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®")
        print("  âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®")
        print("  âœ… å®éªŒç›®å½•ç»“æ„åˆ›å»º")
        print("  âœ… LoRAé…ç½®æœ‰æ•ˆ")
        print("  âœ… è®­ç»ƒå‚æ•°åˆç†")
        print("  ğŸ’¡ è¦å®é™…è®­ç»ƒè¯·ç§»é™¤ --dry_run å‚æ•°")
        return {"status": "dry_run_completed"}
    
    try:
        # åˆ›å»ºå®éªŒç›®å½•
        experiment_dir = Path(config['paths']['experiment_dir'])
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config['paths']['config_file'], 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, indent=2, allow_unicode=True)
        
        # åˆå§‹åŒ– SwanLab
        print("ğŸ“Š åˆå§‹åŒ– SwanLab...")
        
        # æ™ºèƒ½ç¡®å®šé¡¹ç›®åç§°
        if swanlab_project:
            project_name = swanlab_project
        else:
            # é»˜è®¤é¡¹ç›®åç§°ï¼Œæ”¯æŒä¸ªäººå’Œå›¢é˜Ÿä½¿ç”¨
            import getpass
            current_user = getpass.getuser()
            project_name = f"lora-training-{current_user}"
        
        # SwanLabåˆå§‹åŒ–å‚æ•°
        swanlab_params = {
            "project": project_name,
            "experiment_name": config['experiment']['name'],
            "config": config,
            "logdir": config['paths']['swanlab_dir']
        }
        
        # å¦‚æœæŒ‡å®šäº†å·¥ä½œåŒºï¼Œæ·»åŠ å·¥ä½œåŒºå‚æ•°ï¼ˆç”¨äºå›¢é˜Ÿåä½œï¼‰
        if swanlab_workspace:
            swanlab_params["workspace"] = swanlab_workspace
            print(f"ğŸ¢ ä½¿ç”¨å›¢é˜Ÿå·¥ä½œåŒº: {swanlab_workspace}")
        
        print(f"ğŸ“‚ SwanLabé¡¹ç›®: {project_name}")
        swanlab_run = swanlab.init(**swanlab_params)
        
        # åˆ›å»ºæ•°æ®æ¨¡å—
        batch_size = config['training']['batch_size']
            
        data_module = TrainTestDataModule(
            dataset_name=dataset_name,
            batch_size=batch_size,
            test_mode=False  # ç§»é™¤test_modeï¼Œå§‹ç»ˆä½¿ç”¨æ ‡å‡†æ¨¡å¼
        )
        
        print(f"ğŸ“Š æ•°æ®æ¨¡å—é…ç½®:")
        print(f"  - Trainæ–‡ä»¶: {data_module.train_file}")
        print(f"  - Testæ–‡ä»¶: {data_module.test_file}")
        print(f"  - Batchå¤§å°: {batch_size}")
        print(f"  - Shuffle: False (ä¸¥æ ¼é¡ºåº)")
        
        # åˆ›å»ºLightningæ¨¡å—
        model_path = config.get('model', {}).get('path', 'models/Qwen-Qwen2.5-0.5B')
        if not os.path.exists(model_path):
            model_path = config.get('model', {}).get('name', 'Qwen/Qwen2.5-0.5B')
        
        lora_config = {
            'r': config.get('lora', {}).get('r', 16),
            'lora_alpha': config.get('lora', {}).get('alpha', 32),
            'target_modules': config.get('lora', {}).get('target_modules', ["q_proj", "v_proj"]),
            'lora_dropout': config.get('lora', {}).get('dropout', 0.1),
            'bias': config.get('lora', {}).get('bias', "none"),
            'task_type': TaskType.CAUSAL_LM
        }
        
        lightning_module = LoRALightningModule(
            model_path=model_path,
            lora_config=lora_config,
            learning_rate_stage1=config['training']['learning_rate_stage1'],
            learning_rate_stage2=config['training']['learning_rate_stage2'],
            stage1_steps=config['training']['stage1_steps'],
            stage2_steps=config['training']['stage2_steps'],
        )
        
        # å°†SwanLab runæ·»åŠ åˆ°æ¨¡å—ä¸­
        lightning_module._swanlab_run = swanlab_run
        
        # è®¾ç½®å›è°ƒ
        callbacks = setup_callbacks(config)
        
        # è·å–æœ€ä½³checkpointå›è°ƒçš„å¼•ç”¨
        final_checkpoint = None
        for callback in callbacks:
            if isinstance(callback, ModelCheckpoint) and callback.monitor == 'train/loss':
                final_checkpoint = callback
                break
        
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        tensorboard_logger = TensorBoardLogger(
            save_dir=config['paths']['tensorboard_dir'],
            name="",
            version=""
        )
        
        # åˆ›å»ºTrainer
        trainer = Trainer(
            max_steps=config['training']['max_steps'],
            callbacks=callbacks,
            logger=tensorboard_logger,
            enable_progress_bar=True,
            log_every_n_steps=1,
            enable_checkpointing=True,  # å¯ç”¨æ£€æŸ¥ç‚¹
            precision='16-mixed' if torch.cuda.is_available() else 32,
            accelerator='auto',
            devices='auto',
            strategy='auto',
        )
        
        print(f"\nğŸƒâ€â™‚ï¸ å¼€å§‹Lightningè®­ç»ƒ...")
        print(f"ğŸ“Š è®­ç»ƒå™¨é…ç½®:")
        print(f"  - æœ€å¤§æ­¥æ•°: {config['training']['max_steps']}")
        print(f"  - ç²¾åº¦: {'16-mixed' if torch.cuda.is_available() else '32'}")
        print(f"  - åŠ é€Ÿå™¨: {trainer.accelerator}")
        print(f"  - è®¾å¤‡æ•°: {trainer.num_devices}")
        
        # å¼€å§‹è®­ç»ƒï¼ˆåŒ…å«éªŒè¯ï¼‰
        trainer.fit(lightning_module, datamodule=data_module)
        
        # åœ¨æµ‹è¯•é›†ä¸Šæœ€ç»ˆè¯„ä¼°
        print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•é›†è¯„ä¼°...")
        test_results = trainer.test(lightning_module, datamodule=data_module)
        
        print(f"ğŸ“Š æµ‹è¯•ç»“æœ:")
        for key, value in test_results[0].items():
            print(f"  - {key}: {value:.4f}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_dir = Path(config['paths']['final_model_dir'])
        final_model_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹åˆ°: {final_model_dir}")
        lightning_module.model.save_pretrained(final_model_dir)
        lightning_module.tokenizer.save_pretrained(final_model_dir)
        
        # å…³é—­SwanLab
        swanlab.finish()
        
        results = {
            "status": "training_completed",
            "experiment_dir": str(experiment_dir),
            "final_model_dir": str(final_model_dir),
            "checkpoints_dir": config['paths']['checkpoints_dir'],
            "final_model_path": final_checkpoint.best_model_path if final_checkpoint else "N/A",
            "total_steps": config['training']['max_steps'],
            "test_results": test_results[0] if test_results else {},
            "framework": "lightning_swanlab"
        }
        
        print(f"\nâœ… Lightningè®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ å®éªŒç›®å½•: {experiment_dir}")
        print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {final_model_dir}")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹: {final_checkpoint.best_model_path if final_checkpoint else 'N/A'}")
        print(f"ğŸ“ æ£€æŸ¥ç‚¹: {config['paths']['checkpoints_dir']}")
        print(f"ğŸ“Š è®­ç»ƒæ­¥æ•°: {config['training']['max_steps']}")
        print(f"ğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ: {test_results[0] if test_results else 'æœªå®Œæˆ'}")
        
        return results
        
    except Exception as e:
        print(f"âŒ Lightningè®­ç»ƒå¤±è´¥: {e}")
        if 'swanlab_run' in locals():
            swanlab.finish()
        raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Lightning + SwanLab LoRAè®­ç»ƒè„šæœ¬")
    parser.add_argument("--dataset", type=str, required=True,
                       help="è¦è®­ç»ƒçš„æ•°æ®é›†åç§° (arc-challenge, arc-easy, boolq, hellaswag, openbookqa, piqa, winogrande)")
    parser.add_argument("--config", type=str, default="configs/lightning_config.yaml",
                       help="Lightningé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dry_run", action="store_true",
                       help="å¹²è¿è¡Œæ¨¡å¼: éªŒè¯é…ç½®å’Œæ•°æ®æ–‡ä»¶ï¼Œåˆ›å»ºå®éªŒç›®å½•ï¼Œä½†ä¸å®é™…è®­ç»ƒæ¨¡å‹")
    parser.add_argument("--batch_size", type=int, default=None,
                       help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤è‡ªåŠ¨é€‰æ‹©)")
    parser.add_argument("--max_steps", type=int, default=125,
                       help="è®­ç»ƒæ€»æ­¥æ•° (é»˜è®¤125)")
    parser.add_argument("--save_steps", type=int, default=50,
                       help="ä¿å­˜æœ€åå¤šå°‘æ­¥çš„æ£€æŸ¥ç‚¹ (é»˜è®¤50)")
    parser.add_argument("--learning_rate", type=float, default=1e-4,
                       help="å­¦ä¹ ç‡ (é»˜è®¤1e-4)")
    parser.add_argument("--learning_rate_stage2", type=float, default=None,
                       help="ç¬¬äºŒé˜¶æ®µå­¦ä¹ ç‡ (é»˜è®¤ä¸ºlearning_rateçš„1/10)")
    parser.add_argument("--swanlab_project", type=str, default=None,
                       help="SwanLabé¡¹ç›®åç§° (é»˜è®¤: lora-training-{ç”¨æˆ·åæˆ–å›¢é˜Ÿå})")
    parser.add_argument("--swanlab_workspace", type=str, default=None,
                       help="SwanLabå·¥ä½œåŒºåç§° (ç”¨äºå›¢é˜Ÿåä½œ)")
    
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™ä½†å¿½ç•¥çš„å‚æ•°
    parser.add_argument("--track_batches", action="store_true",
                       help="(å…¼å®¹å‚æ•°ï¼Œå½“å‰ç‰ˆæœ¬å¿½ç•¥)")
    
    args = parser.parse_args()
    
    # éªŒè¯æ•°æ®é›†åç§°
    valid_datasets = ['arc-challenge', 'arc-easy', 'boolq', 'hellaswag', 'openbookqa', 'piqa', 'winogrande']
    if args.dataset not in valid_datasets:
        print(f"âŒ æ— æ•ˆçš„æ•°æ®é›†åç§°: {args.dataset}")
        print(f"âœ… å¯ç”¨æ•°æ®é›†: {', '.join(valid_datasets)}")
        return False
    
    # å…¼å®¹æ€§æç¤º
    if args.track_batches:
        print("ğŸ’¡ æ³¨æ„: --track_batches åŠŸèƒ½å°†åœ¨ä¸‹ä¸ªç‰ˆæœ¬ä¸­å®ç°ï¼Œå½“å‰ç‰ˆæœ¬å¿½ç•¥æ­¤å‚æ•°")
    
    print("ğŸš€ Lightning + SwanLab LoRAè®­ç»ƒè„šæœ¬")
    print("=" * 70)
    print(f"ç›®æ ‡æ•°æ®é›†: {args.dataset}")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"Batchå¤§å°: {args.batch_size if args.batch_size else 'è‡ªåŠ¨é€‰æ‹©'}")
    print(f"è®­ç»ƒæ­¥æ•°: {args.max_steps}")
    print(f"ä¿å­˜æ­¥æ•°: ä¿å­˜æœ€å{args.save_steps}ä¸ªæ£€æŸ¥ç‚¹")
    print(f"å­¦ä¹ ç‡: {args.learning_rate} -> {args.learning_rate_stage2 or args.learning_rate/10}")
    
    # SwanLabé…ç½®ä¿¡æ¯
    import getpass
    current_user = getpass.getuser()
    swanlab_project_display = args.swanlab_project or f"lora-training-{current_user}"
    print(f"SwanLabé¡¹ç›®: {swanlab_project_display}")
    if args.swanlab_workspace:
        print(f"SwanLabå·¥ä½œåŒº: {args.swanlab_workspace} (å›¢é˜Ÿæ¨¡å¼)")
    else:
        print("SwanLabå·¥ä½œåŒº: ä¸ªäººå·¥ä½œåŒº")
    
    print(f"è¿è¡Œæ¨¡å¼: {'ğŸƒ Dry Run (éªŒè¯é…ç½®å’Œæ•°æ®ï¼Œä¸è®­ç»ƒ)' if args.dry_run else 'ğŸš€ å®Œæ•´è®­ç»ƒ'}")
    print(f"æ¡†æ¶: PyTorch Lightning + SwanLab")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    try:
        # åŠ è½½åŸºç¡€é…ç½®
        with open(args.config, 'r', encoding='utf-8') as f:
            base_config = yaml.safe_load(f)
        
        # åˆ›å»ºLightningé…ç½®
        config = create_lightning_config(args.dataset, base_config, args.batch_size, args.max_steps, args.save_steps, args.learning_rate, args.learning_rate_stage2)
        
        # æ‰§è¡Œè®­ç»ƒ
        results = run_lightning_training(
            dataset_name=args.dataset,
            config=config,
            swanlab_project=args.swanlab_project,
            swanlab_workspace=args.swanlab_workspace,
            dry_run=args.dry_run
        )
        
        print(f"\nğŸ‰ å®éªŒå®Œæˆ!")
        print(f"ğŸ“Š ç»“æœ: {results.get('status', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
