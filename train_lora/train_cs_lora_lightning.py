#!/usr/bin/env python3
"""
train_cs_lora_lightning.py
PyTorch Lightning + SwanLab ç‰ˆæœ¬çš„ LoRA è®­ç»ƒè„šæœ¬
ç°ä»£åŒ–è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå®æ—¶ç›‘æ§å’Œå®éªŒç®¡ç†
======================================================================

# æ•°æ®é›†
python train_cs_lora_lightning.py --dataset arc-challenge arc-easy boolq hellaswag openbookqa piqa winogrande

# è‡ªå®šä¹‰å‚æ•°
python train_cs_lora_lightning.py --dataset arc-challenge --bs 16
python train_cs_lora_lightning.py --dataset arc-challenge --dry_run

# æ‰¹é‡æ‰§è¡Œ (PowerShell)
foreach ($dataset in @("arc-challenge", "arc-easy", "boolq", "hellaswag", "openbookqa", "piqa", "winogrande")) {
    Write-Host "ğŸš€ å¼€å§‹è®­ç»ƒ $dataset..."
    python train_cs_lora_lightning.py --dataset $dataset
    Write-Host "âœ… $dataset è®­ç»ƒå®Œæˆ"
}

======================================================================

ä¸»è¦ç‰¹æ€§:
âœ… PyTorch Lightning: ç°ä»£åŒ–è®­ç»ƒæ¡†æ¶ï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡ã€åˆ†å¸ƒå¼ç­‰
âœ… SwanLab é›†æˆ: å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼Œå®éªŒç®¡ç†å’Œå¯¹æ¯”  
âœ… ä¸»æµä¿å­˜æ–¹å¼: éµå¾ª HuggingFace/Lightning
âœ… è‡ªåŠ¨æ··åˆç²¾åº¦: æå‡è®­ç»ƒæ•ˆç‡
âœ… æ¨¡å—åŒ–æ¶æ„: ä»£ç æŒ‰åŠŸèƒ½æ‹†åˆ†ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

ç›®å½•ç»“æ„ (Lightning + SwanLab é£æ ¼ï¼ŒæŒ‰æ¨¡å‹åˆ†ç»„):
./runs/                          # ä¸»å®éªŒç›®å½•
â”œâ”€â”€ {model_name}/                # æŒ‰æ¨¡å‹åç§°åˆ†ç»„ (å¦‚ Qwen2.5-1.5B, Qwen2.5-0.5B)
â”‚   â”œâ”€â”€ {experiment_name}/       # å•ä¸ªå®éªŒ (å¦‚ arc-challenge_lora_20250723_143022)
â”‚   â”‚   â”œâ”€â”€ checkpoints/         # Lightning checkpoints (.ckpt) 
â”‚   â”‚   â”œâ”€â”€ tensorboard_logs/    # TensorBoard æ—¥å¿—
â”‚   â”‚   â”œâ”€â”€ swanlab_logs/       # SwanLab æ—¥å¿—
â”‚   â”‚   â”œâ”€â”€ final_model/        # æœ€ç»ˆ HuggingFace æ ¼å¼æ¨¡å‹
â”‚   â”‚   â””â”€â”€ config.yaml         # å®éªŒé…ç½®
â”‚   â””â”€â”€ {another_experiment}/    # åŒä¸€æ¨¡å‹çš„å…¶ä»–å®éªŒ
â””â”€â”€ {another_model}/             # å…¶ä»–æ¨¡å‹çš„å®éªŒ
    â””â”€â”€ {experiment_name}/
        â””â”€â”€ ...
"""

import os
import sys
import yaml
import argparse
import warnings
from datetime import datetime
from pathlib import Path

# å±è”½ Transformers å’Œ Lightning è­¦å‘Š
warnings.filterwarnings("ignore", message=".*cache_implementation.*")
warnings.filterwarnings("ignore", message=".*generation flags are not valid.*")
warnings.filterwarnings("ignore", message=".*sync_dist.*")
warnings.filterwarnings("ignore", message=".*recommended.*")
warnings.filterwarnings("ignore", message=".*Progress bar.*")
warnings.filterwarnings("ignore", category=UserWarning)
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'
os.environ['PYTORCH_LIGHTNING_VERBOSITY'] = 'ERROR'  # åªæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
os.environ['TQDM_DISABLE'] = '1'  # ç¦ç”¨tqdmè¿›åº¦æ¡

# å¼ºåˆ¶ä½¿ç”¨å•GPUï¼Œé¿å…å¤šè¿›ç¨‹å¯åŠ¨ï¼ˆ4å¡A800ç¯å¢ƒï¼‰
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # åªä½¿ç”¨ç¬¬ä¸€å¼ GPU
os.environ['WORLD_SIZE'] = '1'  # å¼ºåˆ¶å•èŠ‚ç‚¹
os.environ['LOCAL_RANK'] = '0'
os.environ['RANK'] = '0'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, '..'))  # æ·»åŠ ä¸Šçº§ç›®å½•

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from core import (
    setup_environment,
    create_lightning_config,
    run_lightning_training
)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Lightning + SwanLab LoRAè®­ç»ƒè„šæœ¬")
    parser.add_argument("--dataset", type=str, required=True,
                       help="è¦è®­ç»ƒçš„æ•°æ®é›†åç§° (arc-challenge, arc-easy, boolq, hellaswag, openbookqa, piqa, winogrande)")
    parser.add_argument("--config", type=str, default="./config/lightning_config.yaml",
                       help="Lightningé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dry_run", action="store_true",
                       help="å¹²è¿è¡Œæ¨¡å¼: éªŒè¯é…ç½®å’Œæ•°æ®æ–‡ä»¶ï¼Œåˆ›å»ºå®éªŒç›®å½•ï¼Œä½†ä¸å®é™…è®­ç»ƒæ¨¡å‹")
    parser.add_argument("--bs", type=int, default=None,
                       help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤è‡ªåŠ¨é€‰æ‹©)")
    parser.add_argument("--max_steps", type=int, default=125,
                       help="è®­ç»ƒæ€»æ­¥æ•° (é»˜è®¤125)")
    parser.add_argument("--save_steps", type=int, default=1,
                       help="ä¿å­˜æœ€åå¤šå°‘æ­¥çš„æ£€æŸ¥ç‚¹ (é»˜è®¤1)")
    parser.add_argument("--lr", type=float, default=1e-5,
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--lr2", type=float, default=None,
                       help="ç¬¬äºŒé˜¶æ®µå­¦ä¹ ç‡ (é»˜è®¤å’Œlearning_rateç›¸åŒ")
    parser.add_argument("--base_model", type=str, default="../autodl-tmp/models/gemma-2-2b-it",
                       help="åŸºç¡€æ¨¡å‹è·¯å¾„æˆ–huggingfaceæ¨¡å‹å (é»˜è®¤=../autodl-tmp/models/gemma-2-2b-it)")
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿ç•™ä½†å¿½ç•¥çš„å‚æ•°
    parser.add_argument("--track_batches", action="store_true",
                       help="(å…¼å®¹å‚æ•°ï¼Œå½“å‰ç‰ˆæœ¬å¿½ç•¥)")

    args = parser.parse_args()
    if args.lr2 is None:
        args.lr2 = args.lr
    
    # éªŒè¯æ•°æ®é›†åç§°
    valid_datasets = ['arc-challenge', 'arc-easy', 'boolq', 'hellaswag', 'openbookqa', 'piqa', 'winogrande']
    if args.dataset not in valid_datasets:
        print(f"âŒ æ— æ•ˆçš„æ•°æ®é›†åç§°: {args.dataset}")
        print(f"âœ… å¯ç”¨æ•°æ®é›†: {', '.join(valid_datasets)}")
        return False
    
    # å…¼å®¹æ€§æç¤º
    if args.track_batches:
        print("ğŸ’¡ æ³¨æ„: --track_batches åŠŸèƒ½å°†åœ¨ä¸‹ä¸ªç‰ˆæœ¬ä¸­å®ç°ï¼Œå½“å‰ç‰ˆæœ¬å¿½ç•¥æ­¤å‚æ•°")
    
    print("ğŸš€ Lightning + SwanLab LoRAè®­ç»ƒè„šæœ¬ (æ¨¡å—åŒ–ç‰ˆæœ¬)")
    print("=" * 70)
    print(f"ç›®æ ‡æ•°æ®é›†: {args.dataset}")
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"Batchå¤§å°: {args.bs if args.bs else 'è‡ªåŠ¨é€‰æ‹©'}")
    print(f"è®­ç»ƒæ­¥æ•°: {args.max_steps}")
    print(f"ä¿å­˜æ­¥æ•°: ä¿å­˜æœ€å{args.save_steps}ä¸ªæ£€æŸ¥ç‚¹")
    print(f"å­¦ä¹ ç‡: {args.lr} -> {args.lr2 or args.lr/10}")
    print(f"åŸºç¡€æ¨¡å‹: {args.base_model}")
    print(f"è¿è¡Œæ¨¡å¼: {'ğŸƒ Dry Run (éªŒè¯é…ç½®å’Œæ•°æ®ï¼Œä¸è®­ç»ƒ)' if args.dry_run else 'ğŸš€ å®Œæ•´è®­ç»ƒ'}")
    print(f"æ¡†æ¶: PyTorch Lightning + SwanLab")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    try:
        # è®¾ç½®ç¯å¢ƒ
        setup_environment()
        
        # åŠ è½½åŸºç¡€é…ç½®
        config_path = os.path.join(os.path.dirname(__file__), args.config)
        with open(config_path, 'r', encoding='utf-8') as f:
            base_config = yaml.safe_load(f)
        
        # åˆ›å»ºLightningé…ç½®
        config = create_lightning_config(
            dataset_name=args.dataset, 
            base_config=base_config, 
            base_model_path=args.base_model,  # ä¼ é€’base_modelè·¯å¾„
            batch_size=args.bs, 
            max_steps=args.max_steps, 
            save_steps=args.save_steps, 
            learning_rate=args.lr, 
            learning_rate_stage2=args.lr2
        )
        
        # æ³¨å…¥ base model è·¯å¾„
        if 'model' not in config:
            config['model'] = {}
        config['model']['path'] = args.base_model
        config['model']['name'] = args.base_model

        # æ‰§è¡Œè®­ç»ƒ
        results = run_lightning_training(
            dataset_name=args.dataset,
            config=config,
            dry_run=args.dry_run
        )
        
        print(f"\nğŸ‰ å®éªŒå®Œæˆ!")
        print(f"ğŸ“Š ç»“æœ: {results.get('status', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
