# LoRA Transfer Pipeline - Main Configuration
# 主要配置文件

# 路径配置
paths:
  models_dir: '../autodl-tmp/models'
  train_script: './train_lora/train_cs_lora_lightning.py'
  eval_script: './eval/lightning_eval.py'
  transfer_script: './lora_adapter/scripts/transfer_lora_x.py'
  runs_dir: './train_lora/runs'
  transferred_lora_dir: '../autodl-tmp/transferred_lora'
  results_dir: './results'

# 训练配置
training:
  default_batch_size: 2
  default_max_steps: 200
  default_lr: '1e-5'
  # 要运行的数据集列表 - 不需要的可以注释掉
  datasets:
    # - 'piqa'
    - 'arc-challenge'
    # - 'arc-easy'
    # - 'hellaswag'
    # - 'winogrande'

# 评估配置
evaluation:
  sample_ratio: 0.05
  default_batch_size: 8

# 迁移配置
transfer:
  similarity_threshold: 0.0001

# 结果配置
results:
  csv_file: 'experiment_results.csv'
  markdown_file: 'experiment_summary.md'

# 默认实验配置 - 如果不提供命令行参数则使用这些值
default_experiment:
  source_model: 'gemma-2-2b-it'
  target_model: 'Qwen_Qwen2.5-1.5B'
  dataset: 'arc-challenge'
  eval_only: false

# 通用配置
general:
  timestamp: null

# 实验管理配置
experiment_management:
  # 当发现已存在实验时的默认行为
  # 选项: 'prompt', 'continue', 'delete', 'abort'
  existing_experiment_action: 'prompt'
  
  # 删除现有输出时要清理的内容
  cleanup_targets:
    - 'training_outputs'    # 训练结果 (train_lora/runs/*)
    - 'transferred_lora'    # 迁移的LoRA (autodl-tmp/transferred_lora/*)
    - 'evaluation_results'  # 评估结果 (eval/results/*)
    - 'pipeline_results'    # Pipeline结果 (results/*)
  
  # 要保留的文件模式 (这些文件不会被删除)
  preserve_patterns:
    - '*.yaml'             # 配置文件
    - '*.py'               # Python脚本
    - 'README.*'           # 说明文档
    - '.git*'              # Git相关文件

# LoRA配置
lora:
  # LoRA基础参数
  r: 16                    # LoRA秩，控制适配器的复杂度
  lora_alpha: 32           # LoRA缩放参数，通常设为r的2倍
  lora_dropout: 0.1        # LoRA层的dropout率
  bias: "none"             # 偏置处理方式: "none", "all", "lora_only"
  
  # 目标层配置 - 决定对哪些层应用LoRA
  target_modules:
    # 保守配置 - 只对注意力机制的查询和值投影层进行LoRA
    - "q_proj"
    - "v_proj"
    
    # 标准配置 - 完整注意力层 (取消注释以启用)
    # - "k_proj"
    # - "o_proj"
    
    # 完整配置 - 包含FFN层 (取消注释以启用)
    # - "gate_proj"
    # - "up_proj" 
    # - "down_proj"
  
  # 预设配置模板 (可选择使用)
  presets:
    conservative:
      target_modules: ["q_proj", "v_proj"]
      r: 16
      lora_alpha: 32
    
    standard:
      target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
      r: 16
      lora_alpha: 32
    
    full:
      target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
      r: 32
      lora_alpha: 64
