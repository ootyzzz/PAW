#!/usr/bin/env python3
"""
results_manager.py
å®éªŒç»“æœç®¡ç†å·¥å…·

åŠŸèƒ½:
- æŸ¥çœ‹å®éªŒå†å²
- æœç´¢ç‰¹å®šå®éªŒ
- ç”Ÿæˆå®éªŒæŠ¥å‘Š
- æ¸…ç†è¿‡æœŸå®éªŒ
"""

import os
import sys
import yaml
import pandas as pd
import argparse
from datetime import datetime, timedelta
from pathlib import Path

class ResultsManager:
    def __init__(self, config_path="config/pipeline_config.yaml"):
        """åˆå§‹åŒ–ç»“æœç®¡ç†å™¨"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.results_dir = self.config['paths']['results_dir']
        self.csv_path = os.path.join(self.results_dir, self.config['results']['csv_file'])
    
    def load_results(self):
        """åŠ è½½å®éªŒç»“æœ"""
        if not os.path.exists(self.csv_path):
            print("ğŸ“Š è¿˜æ²¡æœ‰ä»»ä½•å®éªŒç»“æœ")
            return pd.DataFrame()
        
        try:
            return pd.read_csv(self.csv_path)
        except Exception as e:
            print(f"âŒ åŠ è½½ç»“æœå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def list_experiments(self, limit=10):
        """åˆ—å‡ºæœ€è¿‘çš„å®éªŒ"""
        df = self.load_results()
        if df.empty:
            return
        
        print(f"ğŸ“Š æœ€è¿‘ {min(limit, len(df))} ä¸ªå®éªŒ:")
        print("=" * 80)
        
        # æŒ‰æ—¶é—´æ’åº
        df_sorted = df.sort_values('timestamp', ascending=False).head(limit)
        
        for _, row in df_sorted.iterrows():
            print(f"ğŸ†” {row['experiment_id']}")
            print(f"   ğŸ“… æ—¶é—´: {row['timestamp']}")
            print(f"   ğŸ¯ {self._get_model_name(row['source_model'])} â†’ {self._get_model_name(row['target_model'])}")
            print(f"   ğŸ“š æ•°æ®é›†: {row['dataset']}")
            
            # æ˜¾ç¤ºå…³é”®ç»“æœ
            if pd.notna(row['transferred_acc']) and pd.notna(row['target_acc']):
                improvement = (row['transferred_acc'] - row['target_acc']) * 100
                print(f"   ğŸ“ˆ è¿ç§»æ•ˆæœ: {row['transferred_acc']:.4f} (+{improvement:.2f}%)")
            
            print()
    
    def search_experiments(self, **filters):
        """æœç´¢å®éªŒ"""
        df = self.load_results()
        if df.empty:
            return
        
        print(f"ğŸ” æœç´¢æ¡ä»¶: {filters}")
        
        # åº”ç”¨è¿‡æ»¤å™¨
        filtered_df = df.copy()
        for key, value in filters.items():
            if key in df.columns and value:
                if key in ['source_model', 'target_model']:
                    # æ¨¡å‹åæ”¯æŒéƒ¨åˆ†åŒ¹é…
                    filtered_df = filtered_df[filtered_df[key].str.contains(value, case=False, na=False)]
                else:
                    filtered_df = filtered_df[filtered_df[key] == value]
        
        if filtered_df.empty:
            print("ğŸš« æœªæ‰¾åˆ°åŒ¹é…çš„å®éªŒ")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(filtered_df)} ä¸ªåŒ¹é…å®éªŒ:")
        print("=" * 60)
        
        for _, row in filtered_df.iterrows():
            print(f"ğŸ†” {row['experiment_id']}")
            print(f"   ğŸ“… {row['timestamp']}")
            print(f"   ğŸ¯ {self._get_model_name(row['source_model'])} â†’ {self._get_model_name(row['target_model'])}")
            print(f"   ğŸ“š {row['dataset']}")
            
            if pd.notna(row['source_acc']):
                print(f"   ğŸ“Š æºæ¨¡å‹: {row['source_acc']:.4f}")
            if pd.notna(row['target_acc']):
                print(f"   ğŸ“Š ç›®æ ‡æ¨¡å‹: {row['target_acc']:.4f}")
            if pd.notna(row['transferred_acc']):
                improvement = (row['transferred_acc'] - row['target_acc']) * 100 if pd.notna(row['target_acc']) else 0
                print(f"   ğŸ“Š è¿ç§»ç»“æœ: {row['transferred_acc']:.4f} (+{improvement:.2f}%)")
            print()
    
    def generate_report(self, dataset=None):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        df = self.load_results()
        if df.empty:
            return
        
        if dataset:
            df = df[df['dataset'] == dataset]
            if df.empty:
                print(f"ğŸš« æ•°æ®é›† {dataset} æ²¡æœ‰å®éªŒè®°å½•")
                return
            print(f"ğŸ“Š æ•°æ®é›† {dataset} å®éªŒæŠ¥å‘Š")
        else:
            print("ğŸ“Š å…¨éƒ¨å®éªŒæŠ¥å‘Š")
        
        print("=" * 60)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"ğŸ“ˆ æ€»å®éªŒæ•°: {len(df)}")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['timestamp'].min()} - {df['timestamp'].max()}")
        print(f"ğŸ¯ æ¶‰åŠæ¨¡å‹: {', '.join(df['source_model'].apply(self._get_model_name).unique())}")
        print(f"ğŸ“š æ¶‰åŠæ•°æ®é›†: {', '.join(df['dataset'].unique())}")
        
        # æ€§èƒ½ç»Ÿè®¡
        if not df['transferred_acc'].isna().all() and not df['target_acc'].isna().all():
            improvements = (df['transferred_acc'] - df['target_acc']) * 100
            improvements = improvements.dropna()
            
            if not improvements.empty:
                print(f"\nğŸ“ˆ è¿ç§»æ•ˆæœç»Ÿè®¡:")
                print(f"   å¹³å‡æå‡: {improvements.mean():.2f}%")
                print(f"   æœ€å¤§æå‡: {improvements.max():.2f}%")
                print(f"   æœ€å°æå‡: {improvements.min():.2f}%")
                print(f"   æˆåŠŸç‡: {(improvements > 0).sum()}/{len(improvements)} ({(improvements > 0).mean()*100:.1f}%)")
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„ç»Ÿè®¡
        if not dataset:
            print(f"\nğŸ“š å„æ•°æ®é›†ç»Ÿè®¡:")
            for ds in df['dataset'].unique():
                ds_df = df[df['dataset'] == ds]
                print(f"   {ds}: {len(ds_df)} ä¸ªå®éªŒ")
        
        print()
    
    def cleanup_old_experiments(self, days=30, dry_run=True):
        """æ¸…ç†æ—§å®éªŒæ–‡ä»¶"""
        df = self.load_results()
        if df.empty:
            return
        
        cutoff_date = datetime.now() - timedelta(days=days)
        cutoff_str = cutoff_date.strftime("%Y%m%d")
        
        old_experiments = df[df['timestamp'] < cutoff_str]
        
        if old_experiments.empty:
            print(f"âœ… æ²¡æœ‰è¶…è¿‡ {days} å¤©çš„å®éªŒ")
            return
        
        print(f"ğŸ—‘ï¸ å‘ç° {len(old_experiments)} ä¸ªè¶…è¿‡ {days} å¤©çš„å®éªŒ:")
        
        for _, row in old_experiments.iterrows():
            print(f"   ğŸ“… {row['timestamp']} - {row['experiment_id']}")
            
            # æ£€æŸ¥ç›¸å…³æ–‡ä»¶
            paths_to_check = []
            if pd.notna(row['source_lora_path']):
                paths_to_check.append(row['source_lora_path'])
            if pd.notna(row['target_lora_path']):
                paths_to_check.append(row['target_lora_path'])
            if pd.notna(row['transferred_lora_path']):
                paths_to_check.append(row['transferred_lora_path'])
            
            for path in paths_to_check:
                if os.path.exists(path):
                    print(f"     ğŸ“ {path}")
                    if not dry_run:
                        try:
                            import shutil
                            shutil.rmtree(path)
                            print(f"     âœ… å·²åˆ é™¤")
                        except Exception as e:
                            print(f"     âŒ åˆ é™¤å¤±è´¥: {e}")
        
        if dry_run:
            print(f"\nğŸ” è¿™æ˜¯é¢„æ¼”æ¨¡å¼ï¼Œå®é™…æ–‡ä»¶æœªåˆ é™¤")
            print(f"ğŸ’¡ ä½¿ç”¨ --no-dry-run æ‰§è¡Œå®é™…åˆ é™¤")
        else:
            print(f"\nâœ… æ¸…ç†å®Œæˆ")
    
    def _get_model_name(self, model_path):
        """è·å–æ¨¡å‹ç®€ç§°"""
        return os.path.basename(model_path.strip())

def main():
    parser = argparse.ArgumentParser(description="å®éªŒç»“æœç®¡ç†å·¥å…·")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ—å‡ºå®éªŒ
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæœ€è¿‘çš„å®éªŒ')
    list_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡é™åˆ¶')
    
    # æœç´¢å®éªŒ
    search_parser = subparsers.add_parser('search', help='æœç´¢å®éªŒ')
    search_parser.add_argument('--dataset', type=str, help='æ•°æ®é›†åç§°')
    search_parser.add_argument('--source_model', type=str, help='æºæ¨¡å‹åç§°(æ”¯æŒéƒ¨åˆ†åŒ¹é…)')
    search_parser.add_argument('--target_model', type=str, help='ç›®æ ‡æ¨¡å‹åç§°(æ”¯æŒéƒ¨åˆ†åŒ¹é…)')
    
    # ç”ŸæˆæŠ¥å‘Š
    report_parser = subparsers.add_parser('report', help='ç”Ÿæˆå®éªŒæŠ¥å‘Š')
    report_parser.add_argument('--dataset', type=str, help='ç‰¹å®šæ•°æ®é›†çš„æŠ¥å‘Š')
    
    # æ¸…ç†å®éªŒ
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§å®éªŒ')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿ç•™å¤©æ•°')
    cleanup_parser.add_argument('--no-dry-run', action='store_true', help='æ‰§è¡Œå®é™…åˆ é™¤')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    manager = ResultsManager()
    
    if args.command == 'list':
        manager.list_experiments(args.limit)
    elif args.command == 'search':
        filters = {}
        if args.dataset:
            filters['dataset'] = args.dataset
        if args.source_model:
            filters['source_model'] = args.source_model
        if args.target_model:
            filters['target_model'] = args.target_model
        
        manager.search_experiments(**filters)
    elif args.command == 'report':
        manager.generate_report(args.dataset)
    elif args.command == 'cleanup':
        manager.cleanup_old_experiments(args.days, dry_run=not args.no_dry_run)

if __name__ == "__main__":
    main()
