"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
è´Ÿè´£LoRAè®­ç»ƒçš„è°ƒåº¦å’Œç®¡ç†
"""

import os
import yaml
from typing import Optional, Tuple
from .config import PipelineConfig
from .utils import ModelUtils, CommandRunner, OutputParser


class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, config: PipelineConfig, verbose: bool = True):
        self.config = config
        self.runner = CommandRunner(verbose=verbose)
        self.verbose = verbose
    
    def train_model(self, model_path: str, dataset: str) -> Tuple[Optional[str], Optional[float], str]:
        """è®­ç»ƒæ¨¡å‹+LoRA
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            dataset: æ•°æ®é›†åç§°
            
        Returns:
            Tuple[æ¨¡å‹è·¯å¾„, å‡†ç¡®ç‡, çŠ¶æ€æ¶ˆæ¯]
        """
        model_name = ModelUtils.get_model_short_name(model_path)
        
        if self.verbose:
            print(f"\nTraining {model_name} + LoRA (dataset: {dataset})")
        
        # Check for existing training results
        existing_path = self._check_existing_training(model_path, dataset)
        if existing_path:
            if self.verbose:
                print(f"çŠ¶æ€: å‘ç°å·²æœ‰è®­ç»ƒç»“æœ: {existing_path}")
            # å°è¯•ä»å·²æœ‰ç»“æœä¸­è¯»å–å‡†ç¡®ç‡
            existing_accuracy = self._read_accuracy_from_existing(existing_path)
            return existing_path, existing_accuracy, f"å‘ç°å·²æœ‰è®­ç»ƒç»“æœ: {existing_path}"
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = self._build_train_command(model_path, dataset)
        
        # æ‰§è¡Œè®­ç»ƒ
        output = self.runner.run_command(
            cmd, 
            f"è®­ç»ƒ {model_name} LoRA",
            cwd="."  # åœ¨PAWæ ¹ç›®å½•æ‰§è¡Œ
        )
        
        if output is None:
            return None, None, "è®­ç»ƒå¤±è´¥ï¼šå‘½ä»¤æ‰§è¡Œé”™è¯¯"
        
        # è§£æè¾“å‡ºè·å–å‡†ç¡®ç‡
        accuracy = OutputParser.parse_training_accuracy(output)
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„æ¨¡å‹è·¯å¾„ - ä½¿ç”¨æ¨¡å‹çš„çŸ­åç§°
        model_short_name = ModelUtils.get_model_short_name(model_path)
        final_model_path = self._find_latest_model(model_short_name, dataset)
        
        if final_model_path:
            return final_model_path, accuracy, f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {final_model_path}"
        else:
            return None, accuracy, "è®­ç»ƒæ‰§è¡Œå®Œæˆï¼Œä½†æœªæ‰¾åˆ°è¾“å‡ºæ¨¡å‹"
    
    def _check_existing_training(self, model_path: str, dataset: str) -> Optional[str]:
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒé…ç½®çš„è®­ç»ƒç»“æœ
        
        ç›®å‰åªæ¯”å¯¹batch_sizeå’Œmax_steps - å¯æ‰©å±•åˆ°æ›´å¤šå‚æ•°
        """
        model_short_name = ModelUtils.get_model_short_name(model_path)
        
        # æ£€æŸ¥æ–°æ ¼å¼è·¯å¾„: runs/{dataset}/{model_name}/
        new_format_dir = os.path.join("runs", dataset, model_short_name)
        # æ£€æŸ¥æ—§æ ¼å¼è·¯å¾„: train_lora/runs/{dataset}/{model_name}/
        old_format_dir = os.path.join(self.config.get('paths.runs_dir'), dataset, model_short_name)
        
        # è·å–å½“å‰é…ç½®
        current_batch_size = self.config.get('training.default_batch_size')
        current_max_steps = self.config.get('training.default_max_steps')
        
        # ä¼˜å…ˆæ£€æŸ¥æ–°æ ¼å¼ï¼Œç„¶åæ£€æŸ¥æ—§æ ¼å¼
        for runs_dir in [new_format_dir, old_format_dir]:
            if not os.path.exists(runs_dir):
                continue
            
            # æŸ¥æ‰¾æ‰€æœ‰è®­ç»ƒç»“æœç›®å½•
            existing_runs = [d for d in os.listdir(runs_dir) 
                            if os.path.isdir(os.path.join(runs_dir, d))]
            
            if not existing_runs:
                continue
            
            # æ£€æŸ¥æ¯ä¸ªè®­ç»ƒç»“æœï¼Œæ¯”å¯¹é…ç½®
            for run_dir in sorted(existing_runs, reverse=True):  # ä»æœ€æ–°å¼€å§‹
                run_path = os.path.join(runs_dir, run_dir)
                final_model_path = os.path.join(run_path, "final_model")
                
                # æ£€æŸ¥final_modelæ˜¯å¦å­˜åœ¨
                if not os.path.exists(final_model_path):
                    continue
                    
                # æŸ¥æ‰¾é…ç½®æ–‡ä»¶è¿›è¡Œæ¯”å¯¹
                config_files = [
                    os.path.join(run_path, "config.yaml"),       # PAWé¡¹ç›®é…ç½®æ–‡ä»¶
                    os.path.join(run_path, "hparams.yaml"),      # Lightningé»˜è®¤å‚æ•°æ–‡ä»¶
                    os.path.join(run_path, "trainer_state.json"), # Transformersè®­ç»ƒçŠ¶æ€
                    os.path.join(run_path, "training_args.json"), # è®­ç»ƒå‚æ•°
                    os.path.join(run_path, "config.json"),       # é€šç”¨é…ç½®
                ]
                
                for config_file in config_files:
                    if os.path.exists(config_file):
                        try:
                            if self._config_matches(config_file, current_batch_size, current_max_steps):
                                if self.verbose:
                                    print(f"   å‘ç°åŒ¹é…é…ç½®çš„è®­ç»ƒç»“æœ: {final_model_path}")
                                    print(f"   é…ç½®æ–‡ä»¶: {os.path.basename(config_file)}")
                                return final_model_path
                        except Exception as e:
                            if self.verbose:
                                print(f"   é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ {config_file}: {e}")
                            continue
        
        return None
    
    def _config_matches(self, config_file: str, target_batch_size: int, target_max_steps: int) -> bool:
        """æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦åŒ¹é…å½“å‰è®­ç»ƒé…ç½®
        
        ç›®å‰åªæ¯”å¯¹batch_sizeå’Œmax_steps
        """
        import json
        import yaml
        
        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£ææ–¹å¼
            if config_file.endswith('.yaml') or config_file.endswith('.yml'):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
            else:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            
            # æŸ¥æ‰¾batch_sizeçš„å„ç§å¯èƒ½é”®åå’Œè·¯å¾„
            found_batch_size = None
            batch_size_paths = [
                'batch_size', 'per_device_train_batch_size', 'train_batch_size', 'bs',
                'training.batch_size', 'experiment.batch_size'
            ]
            
            for path in batch_size_paths:
                value = self._get_nested_value(config, path)
                if value is not None:
                    found_batch_size = value
                    break
            
            # æŸ¥æ‰¾max_stepsçš„å„ç§å¯èƒ½é”®åå’Œè·¯å¾„
            found_max_steps = None
            max_steps_paths = [
                'max_steps', 'total_steps', 'training_steps',
                'training.max_steps', 'experiment.max_steps'
            ]
            
            for path in max_steps_paths:
                value = self._get_nested_value(config, path)
                if value is not None:
                    found_max_steps = value
                    break
            
            # æ¯”å¯¹é…ç½®
            batch_match = (found_batch_size is None or found_batch_size == target_batch_size)
            steps_match = (found_max_steps is None or found_max_steps == target_max_steps)
            
            if self.verbose and (found_batch_size is not None or found_max_steps is not None):
                print(f"     é…ç½®æ¯”å¯¹: batch_size {found_batch_size} vs {target_batch_size}, "
                      f"max_steps {found_max_steps} vs {target_max_steps}")
            
            return batch_match and steps_match
            
        except Exception as e:
            if self.verbose:
                print(f"     é…ç½®è§£æå¤±è´¥: {e}")
            return False
    
    def _read_accuracy_from_existing(self, model_path: str) -> Optional[float]:
        """ä»å·²æœ‰è®­ç»ƒç»“æœä¸­è¯»å–å‡†ç¡®ç‡"""
        import json
        import os
        import yaml
        
        # 1. é¦–å…ˆæŸ¥æ‰¾æ ‡å‡†çš„ç»“æœæ–‡ä»¶
        result_files = [
            os.path.join(os.path.dirname(model_path), "trainer_state.json"),
            os.path.join(os.path.dirname(model_path), "training_results.json"),
            os.path.join(os.path.dirname(model_path), "eval_results.json"),
        ]
        
        for result_file in result_files:
            if os.path.exists(result_file):
                try:
                    with open(result_file, 'r') as f:
                        data = json.load(f)
                    
                    # æŸ¥æ‰¾å‡†ç¡®ç‡çš„å„ç§å¯èƒ½é”®å
                    accuracy_keys = [
                        'test/accuracy', 'test_accuracy', 'eval_accuracy', 
                        'accuracy', 'final_accuracy', 'best_accuracy'
                    ]
                    
                    for key in accuracy_keys:
                        if key in data:
                            accuracy = data[key]
                            if isinstance(accuracy, (int, float)) and 0 <= accuracy <= 1:
                                if self.verbose:
                                    print(f"   ä»{os.path.basename(result_file)}è¯»å–å‡†ç¡®ç‡: {accuracy:.4f}")
                                return float(accuracy)
                            
                except (json.JSONDecodeError, KeyError, ValueError):
                    continue
        
        # 2. æŸ¥æ‰¾tensorboardçš„hparams.yamlæ–‡ä»¶
        hparams_file = os.path.join(os.path.dirname(model_path), "tensorboard_logs", "hparams.yaml")
        if os.path.exists(hparams_file):
            try:
                with open(hparams_file, 'r') as f:
                    data = yaml.safe_load(f)
                # hparamsé€šå¸¸ä¸åŒ…å«å‡†ç¡®ç‡ï¼Œä½†æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹
                if 'accuracy' in data:
                    accuracy = data['accuracy']
                    if isinstance(accuracy, (int, float)) and 0 <= accuracy <= 1:
                        if self.verbose:
                            print(f"   ä»hparams.yamlè¯»å–å‡†ç¡®ç‡: {accuracy:.4f}")
                        return float(accuracy)
            except Exception:
                pass
        
        # 3. å°è¯•ä»swanlabå…ƒæ•°æ®ä¸­è¯»å–ï¼ˆè™½ç„¶é€šå¸¸ä¸åŒ…å«å‡†ç¡®ç‡ï¼‰
        swanlab_dir = os.path.join(os.path.dirname(model_path), "swanlab_logs")
        if os.path.exists(swanlab_dir):
            for run_dir in os.listdir(swanlab_dir):
                metadata_file = os.path.join(swanlab_dir, run_dir, "files", "swanlab-metadata.json")
                if os.path.exists(metadata_file):
                    try:
                        with open(metadata_file, 'r') as f:
                            data = json.load(f)
                        # æ£€æŸ¥æ˜¯å¦æœ‰å‡†ç¡®ç‡ä¿¡æ¯
                        if 'accuracy' in data:
                            accuracy = data['accuracy']
                            if isinstance(accuracy, (int, float)) and 0 <= accuracy <= 1:
                                if self.verbose:
                                    print(f"   ä»swanlabå…ƒæ•°æ®è¯»å–å‡†ç¡®ç‡: {accuracy:.4f}")
                                return float(accuracy)
                    except Exception:
                        continue
        
        # 4. å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå°è¯•è¿è¡Œä¸€ä¸ªå¿«é€Ÿè¯„ä¼°æ¥è·å–å‡†ç¡®ç‡
        if self.verbose:
            print(f"   æœªæ‰¾åˆ°å·²ä¿å­˜çš„å‡†ç¡®ç‡ï¼Œå°è¯•å¿«é€Ÿè¯„ä¼°...")
        
        return self._quick_evaluate_model(model_path)
    
    def _quick_evaluate_model(self, model_path: str) -> Optional[float]:
        """å¯¹å·²æœ‰æ¨¡å‹è¿›è¡Œå¿«é€Ÿè¯„ä¼°ä»¥è·å–å‡†ç¡®ç‡"""
        try:
            # ä»æ¨¡å‹è·¯å¾„æ¨æ–­æ•°æ®é›†å’ŒåŸºç¡€æ¨¡å‹
            path_parts = model_path.split(os.sep)
            dataset = None
            model_name = None
            
            # è§£æè·¯å¾„ï¼šruns/arc-challenge/gemma-2-2b-it/211804/final_model
            for i, part in enumerate(path_parts):
                if part == "runs" and i + 2 < len(path_parts):
                    dataset = path_parts[i + 1]
                    model_name = path_parts[i + 2]
                    break
            
            if not dataset or not model_name:
                if self.verbose:
                    print(f"   æ— æ³•ä»è·¯å¾„è§£ææ•°æ®é›†å’Œæ¨¡å‹å: {model_path}")
                return None
            
            # æ„å»ºåŸºç¡€æ¨¡å‹è·¯å¾„
            base_model_path = os.path.join(self.config.get('paths.models_dir'), model_name)
            
            # æ„å»ºè¯„ä¼°å‘½ä»¤
            eval_script = self.config.get('paths.eval_script')
            sample_ratio = self.config.get('evaluation.sample_ratio', 0.05)
            
            cmd = f"python {eval_script} " \
                  f"--models_list {model_path} " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {sample_ratio} " \
                  f"--base_model {base_model_path}"
            
            if self.verbose:
                print(f"   è¿è¡Œå¿«é€Ÿè¯„ä¼°: {cmd}")
            
            # è¿è¡Œè¯„ä¼°
            output = self.runner.run_command(
                cmd,
                f"å¿«é€Ÿè¯„ä¼° {model_name}",
                cwd="."
            )
            
            if output:
                # è§£æè¯„ä¼°è¾“å‡ºè·å–å‡†ç¡®ç‡
                accuracy = OutputParser.parse_evaluation_accuracy(output)
                if accuracy is not None:
                    if self.verbose:
                        print(f"   å¿«é€Ÿè¯„ä¼°è·å¾—å‡†ç¡®ç‡: {accuracy:.4f}")
                    return accuracy
            
        except Exception as e:
            if self.verbose:
                print(f"   å¿«é€Ÿè¯„ä¼°å¤±è´¥: {e}")
        
        # å¦‚æœå¿«é€Ÿè¯„ä¼°ä¹Ÿå¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼æˆ–None
        if self.verbose:
            print(f"   æ— æ³•è·å–å‡†ç¡®ç‡ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
        return None  # æˆ–è€…è¿”å›ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼ï¼Œæ¯”å¦‚ 0.5
    
    def _build_train_command(self, model_path: str, dataset: str) -> str:
        """æ„å»ºè®­ç»ƒå‘½ä»¤"""
        train_script = self.config.get('paths.train_script')
        
        # åŸºç¡€å‘½ä»¤
        cmd = f"TQDM_DISABLE=1 python {train_script} " \
              f"--dataset {dataset} " \
              f"--base_model {model_path} " \
              f"--bs {self.config.get('training.default_batch_size')} " \
              f"--max_steps {self.config.get('training.default_max_steps')}"
        
        # å¦‚æœé…ç½®ä¸­æœ‰LoRAè®¾ç½®ï¼Œæ·»åŠ é…ç½®æ–‡ä»¶å‚æ•°
        if self.config.has_lora_config():
            config_file = self.config.get_config_file_path()
            if config_file and os.path.exists(config_file):
                cmd += f" --config {config_file}"
                if self.verbose:
                    print(f"ğŸ“ ä½¿ç”¨LoRAé…ç½®æ–‡ä»¶: {config_file}")
                    lora_config = self.config.get('lora', {})
                    print(f"   - ç›®æ ‡å±‚: {lora_config.get('target_modules', ['q_proj', 'v_proj'])}")
                    print(f"   - ç§© (r): {lora_config.get('r', 16)}")
                    print(f"   - Alpha: {lora_config.get('lora_alpha', 32)}")
        else:
            # å¦‚æœæ²¡æœ‰LoRAé…ç½®ï¼Œä½¿ç”¨é»˜è®¤çš„lightningé…ç½®æ–‡ä»¶
            default_config = "./train_lora/config/lightning_config.yaml"
            if os.path.exists(default_config):
                cmd += f" --config {default_config}"
                if self.verbose:
                    print(f"ğŸ“ ä½¿ç”¨é»˜è®¤LoRAé…ç½®æ–‡ä»¶: {default_config}")
        
        return cmd
    
    def _find_latest_model(self, model_name: str, dataset: str) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°ç”Ÿæˆçš„æ¨¡å‹è·¯å¾„"""
        # æ£€æŸ¥æ–°æ ¼å¼è·¯å¾„: runs/{dataset}/{model_name}/
        new_format_dir = os.path.join("runs", dataset, model_name)
        # æ£€æŸ¥æ—§æ ¼å¼è·¯å¾„: train_lora/runs/{dataset}/{model_name}/
        old_format_dir = os.path.join(self.config.get('paths.runs_dir'), dataset, model_name)
        
        # ä¼˜å…ˆæ£€æŸ¥æ–°æ ¼å¼
        for runs_dir in [new_format_dir, old_format_dir]:
            if not os.path.exists(runs_dir):
                continue
            
            runs = [d for d in os.listdir(runs_dir) 
                   if os.path.isdir(os.path.join(runs_dir, d))]
            
            if not runs:
                continue
            
            # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼Œç¡®ä¿è·å–æœ€æ–°çš„è®­ç»ƒç»“æœ
            def get_mtime(run_name):
                run_path = os.path.join(runs_dir, run_name)
                try:
                    return os.path.getmtime(run_path)
                except:
                    # å¦‚æœè·å–ä¿®æ”¹æ—¶é—´å¤±è´¥ï¼Œå°è¯•è§£ææ—¶é—´æˆ³
                    if len(run_name) == 6 and run_name.isdigit():
                        # 6ä½æ•°å­—æ ¼å¼ï¼šHHMMSS
                        return float(run_name)
                    elif len(run_name) >= 15 and '_' in run_name:
                        # å®Œæ•´æ ¼å¼ï¼šYYYYMMDD_HHMMSS
                        timestamp_part = run_name.split('_')[-1]
                        if timestamp_part.isdigit():
                            return float(timestamp_part)
                    return 0
            
            latest_run = sorted(runs, key=get_mtime)[-1]
            final_model_path = os.path.join(runs_dir, latest_run, "final_model")
            
            if os.path.exists(final_model_path):
                return final_model_path
        
        return None
    
    def check_step_completed(self, model_path: str, dataset: str) -> Tuple[bool, Optional[str]]:
        """æ£€æŸ¥è®­ç»ƒæ­¥éª¤æ˜¯å¦å·²å®Œæˆ
        
        Returns:
            Tuple[æ˜¯å¦å®Œæˆ, æ¨¡å‹è·¯å¾„]
        """
        model_name = ModelUtils.get_model_short_name(model_path)
        existing_path = self._check_existing_training(model_name, dataset)
        
        if existing_path:
            return True, existing_path
        
        return False, None
    
    def _get_nested_value(self, config: dict, path: str):
        """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼ï¼Œæ”¯æŒç‚¹åˆ†éš”çš„è·¯å¾„"""
        keys = path.split('.')
        current = config
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        
        return current
