"""
LoRAè®­ç»ƒå’Œè¿ç§»ä¸»ç®¡é“
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„ç®¡é“æ¥å£
"""

import os
from typing import Dict, Any, Optional
from tqdm import tqdm

from .config import PipelineConfig, QuickTestConfig
from .trainer import ModelTrainer
from .evaluator import ModelEvaluator
from .transfer import LoRATransfer
from .results import ResultsManager
from .utils import ModelUtils, get_timestamp


class TransferPipeline:
    """LoRAè¿ç§»ç®¡é“ä¸»ç±»"""
    
    def __init__(self, config_path: str = None, quick_test: bool = False):
        """åˆå§‹åŒ–ç®¡é“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            quick_test: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæµ‹è¯•é…ç½®
        """
        if quick_test:
            self.config = QuickTestConfig()
        else:
            self.config = PipelineConfig(config_path)
        
        self.timestamp = get_timestamp()
        self.experiment_id = None
        
        # åˆå§‹åŒ–æ¨¡å—
        self.trainer = ModelTrainer(self.config)
        self.evaluator = ModelEvaluator(self.config)
        self.transfer = LoRATransfer(self.config)
        self.results = ResultsManager(self.config)
    
    def run_pipeline(self, source_model: str, target_model: str, dataset: str, 
                    eval_only: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´ç®¡é“ - æ–°æµç¨‹ï¼šè®­ç»ƒæºLoRA â†’ è¿ç§» â†’ è¯„ä¼°ç›®æ ‡åŸºç¡€ â†’ è¯„ä¼°è¿ç§»LoRA â†’ è®­ç»ƒç›®æ ‡LoRA â†’ è¯„ä¼°æºåŸºç¡€
        
        Args:
            source_model: æºæ¨¡å‹è·¯å¾„
            target_model: ç›®æ ‡æ¨¡å‹è·¯å¾„
            dataset: æ•°æ®é›†åç§°
            eval_only: ä»…è¿è¡Œè¯„ä¼°ï¼Œè·³è¿‡è®­ç»ƒå’Œè¿ç§»
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # éªŒè¯è¾“å…¥
        if not self._validate_inputs(source_model, target_model, dataset):
            return False
        
        # åˆ›å»ºå®éªŒID
        self.experiment_id = ModelUtils.create_experiment_id(
            source_model, target_model, dataset, self.timestamp
        )
        
        print(f"\nğŸ¯ å¼€å§‹LoRAè¿ç§»å®éªŒ")
        print(f"ğŸ“‹ å®éªŒID: {self.experiment_id}")
        print(f"ğŸ² æºæ¨¡å‹: {source_model}")
        print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {target_model}")
        print(f"ğŸ“š æ•°æ®é›†: {dataset}")
        print("=" * 80)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å†å²è®°å½•
        if not eval_only:
            existing = self.results.check_existing_experiment(source_model, target_model, dataset)
            if existing is not None:
                print(f"âš ï¸ å‘ç°ç›¸åŒå®éªŒè®°å½• (æ—¶é—´: {existing['timestamp']})")
                response = input("æ˜¯å¦ç»§ç»­? (y/N): ").strip().lower()
                if response not in ['y', 'yes']:
                    print("ğŸš« å®éªŒå–æ¶ˆ")
                    return False
        
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        results = self._init_results_dict(source_model, target_model, dataset)
        
        # æ‰§è¡Œç®¡é“æ­¥éª¤
        return self._execute_pipeline_steps(results, source_model, target_model, dataset, eval_only)
    
    def _validate_inputs(self, source_model: str, target_model: str, dataset: str) -> bool:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        # å¤„ç†æ¨¡å‹è·¯å¾„
        if not source_model.startswith('/'):
            source_model = self.config.get_model_path(source_model)
        if not target_model.startswith('/'):
            target_model = self.config.get_model_path(target_model)
        
        # éªŒè¯æ¨¡å‹å­˜åœ¨
        if not ModelUtils.check_model_exists(source_model):
            print(f"âŒ æºæ¨¡å‹ä¸å­˜åœ¨: {source_model}")
            return False
        if not ModelUtils.check_model_exists(target_model):
            print(f"âŒ ç›®æ ‡æ¨¡å‹ä¸å­˜åœ¨: {target_model}")
            return False
        
        # éªŒè¯æ•°æ®é›†
        supported_datasets = self.config.get('training.datasets', [])
        if dataset not in supported_datasets:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset}")
            print(f"âœ… æ”¯æŒçš„æ•°æ®é›†: {', '.join(supported_datasets)}")
            return False
        
        return True
    
    def _init_results_dict(self, source_model: str, target_model: str, dataset: str) -> Dict[str, Any]:
        """åˆå§‹åŒ–ç»“æœå­—å…¸"""
        return {
            'experiment_id': self.experiment_id,
            'source_model': source_model,
            'target_model': target_model,
            'dataset': dataset,
            'timestamp': self.timestamp,
            'training_config': f"batch_size={self.config.get('training.default_batch_size')}, "
                              f"max_steps={self.config.get('training.default_max_steps')}, "
                              f"lr={self.config.get('training.default_lr')}",
            'notes': 'è‡ªåŠ¨åŒ–ç®¡é“ç”Ÿæˆ'
        }
    
    def _execute_pipeline_steps(self, results: Dict[str, Any], source_model: str, 
                               target_model: str, dataset: str, eval_only: bool) -> bool:
        """æ‰§è¡Œç®¡é“æ­¥éª¤"""
        # è®¾ç½®è¿›åº¦æ¡
        total_steps = 6 if not eval_only else 4
        progress_bar = tqdm(total=total_steps, desc="ğŸš€ LoRAè¿ç§»ç®¡é“", position=0, leave=True)
        
        try:
            if not eval_only:
                # æ­¥éª¤1: è®­ç»ƒæºLoRA
                if not self._step_train_source_lora(results, source_model, dataset, progress_bar):
                    raise Exception("æºæ¨¡å‹è®­ç»ƒå¤±è´¥")
                
                # æ­¥éª¤2: è¿ç§»LoRA
                if not self._step_transfer_lora(results, source_model, target_model, dataset, progress_bar):
                    raise Exception("LoRAè¿ç§»å¤±è´¥")
            
            # æ­¥éª¤3: è¯„ä¼°ç›®æ ‡åŸºç¡€æ¨¡å‹
            if not self._step_eval_target_base(results, target_model, dataset, progress_bar):
                print("âš ï¸ ç›®æ ‡åŸºç¡€æ¨¡å‹è¯„ä¼°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            if not eval_only:
                # æ­¥éª¤4: è¯„ä¼°è¿ç§»LoRA
                if not self._step_eval_transferred_lora(results, target_model, dataset, progress_bar):
                    print("âš ï¸ è¿ç§»LoRAè¯„ä¼°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
                
                # æ­¥éª¤5: è®­ç»ƒç›®æ ‡LoRA
                if not self._step_train_target_lora(results, target_model, dataset, progress_bar):
                    print("âš ï¸ ç›®æ ‡æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # æ­¥éª¤6: è¯„ä¼°æºåŸºç¡€æ¨¡å‹
            if not self._step_eval_source_base(results, source_model, dataset, progress_bar):
                print("âš ï¸ æºåŸºç¡€æ¨¡å‹è¯„ä¼°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # æœ€ç»ˆä¿å­˜å®Œæ•´ç»“æœ
            progress_bar.set_description("ğŸ’¾ ä¿å­˜æœ€ç»ˆç»“æœ")
            self.results.save_results(results)
            progress_bar.close()
            
            # æ‰“å°æ€»ç»“
            self._print_summary(results)
            
            # æç¤ºå¯é€‰å‘½ä»¤
            if not eval_only:
                self._print_optional_commands(source_model, target_model, dataset)
            
            print("\nğŸ‰ ç®¡é“æ‰§è¡ŒæˆåŠŸ!")
            return True
            
        except Exception as e:
            progress_bar.close()
            print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            # ä¿å­˜éƒ¨åˆ†ç»“æœ
            self.results.save_partial_results(results, f"å¤±è´¥: {e}")
            return False
    
    def _step_train_source_lora(self, results: Dict[str, Any], source_model: str, 
                               dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤1: è®­ç»ƒæºLoRA"""
        progress_bar.set_description("ğŸ¯ æ­¥éª¤1: è®­ç»ƒæºLoRA")
        
        source_lora_path, source_lora_acc = self.trainer.train_model(source_model, dataset)
        if source_lora_path is None:
            return False
        
        results.update({
            'source_lora_path': source_lora_path,
            'source_lora_acc': source_lora_acc,
        })
        self.results.save_partial_results(results, "æºLoRAè®­ç»ƒå®Œæˆ")
        progress_bar.update(1)
        return True
    
    def _step_transfer_lora(self, results: Dict[str, Any], source_model: str, 
                           target_model: str, dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤2: è¿ç§»LoRA"""
        progress_bar.set_description("ğŸ”„ æ­¥éª¤2: è¿ç§»LoRA")
        
        transferred_lora_path = self.transfer.transfer_lora(
            results['source_lora_path'], source_model, target_model, dataset
        )
        if transferred_lora_path is None:
            return False
        
        results['transferred_lora_path'] = transferred_lora_path
        self.results.save_partial_results(results, "LoRAè¿ç§»å®Œæˆ")
        progress_bar.update(1)
        return True
    
    def _step_eval_target_base(self, results: Dict[str, Any], target_model: str, 
                              dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤3: è¯„ä¼°ç›®æ ‡åŸºç¡€æ¨¡å‹"""
        progress_bar.set_description("ğŸ“Š æ­¥éª¤3: è¯„ä¼°ç›®æ ‡åŸºç¡€æ¨¡å‹")
        
        target_acc = self.evaluator.evaluate_base_model(target_model, dataset)
        results['target_acc'] = target_acc
        self.results.save_partial_results(results, "ç›®æ ‡åŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ")
        progress_bar.update(1)
        return target_acc is not None
    
    def _step_eval_transferred_lora(self, results: Dict[str, Any], target_model: str, 
                                   dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤4: è¯„ä¼°è¿ç§»LoRA"""
        progress_bar.set_description("ğŸ“Š æ­¥éª¤4: è¯„ä¼°è¿ç§»LoRA")
        
        transferred_acc = self.evaluator.evaluate_lora_model(
            results['transferred_lora_path'], target_model, dataset
        )
        results['transferred_acc'] = transferred_acc
        self.results.save_partial_results(results, "è¿ç§»LoRAè¯„ä¼°å®Œæˆ")
        progress_bar.update(1)
        return transferred_acc is not None
    
    def _step_train_target_lora(self, results: Dict[str, Any], target_model: str, 
                               dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤5: è®­ç»ƒç›®æ ‡LoRA"""
        progress_bar.set_description("ğŸ¯ æ­¥éª¤5: è®­ç»ƒç›®æ ‡LoRA")
        
        target_lora_path, target_lora_acc = self.trainer.train_model(target_model, dataset)
        if target_lora_path is None:
            target_lora_acc = None
        
        results.update({
            'target_lora_path': target_lora_path,
            'target_lora_acc': target_lora_acc,
        })
        self.results.save_partial_results(results, "ç›®æ ‡LoRAè®­ç»ƒå®Œæˆ")
        progress_bar.update(1)
        return True  # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­
    
    def _step_eval_source_base(self, results: Dict[str, Any], source_model: str, 
                              dataset: str, progress_bar: tqdm) -> bool:
        """æ­¥éª¤6: è¯„ä¼°æºåŸºç¡€æ¨¡å‹"""
        progress_bar.set_description("ğŸ“Š æ­¥éª¤6: è¯„ä¼°æºåŸºç¡€æ¨¡å‹")
        
        source_acc = self.evaluator.evaluate_base_model(source_model, dataset)
        results['source_acc'] = source_acc
        self.results.save_partial_results(results, "æºåŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ")
        progress_bar.update(1)
        return source_acc is not None
    
    def _print_summary(self, results: Dict[str, Any]):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\nğŸ‰ å®éªŒå®Œæˆ! æ€»ç»“å¦‚ä¸‹:")
        print("=" * 60)
        
        source_name = ModelUtils.get_model_short_name(results['source_model'])
        target_name = ModelUtils.get_model_short_name(results['target_model'])
        
        # å¤„ç†å¯èƒ½ä¸ºNoneçš„å€¼
        source_acc = results.get('source_acc', 0) or 0
        target_acc = results.get('target_acc', 0) or 0
        source_lora_acc = results.get('source_lora_acc')
        target_lora_acc = results.get('target_lora_acc')
        transferred_acc = results.get('transferred_acc')
        
        print(f"ğŸ“Š {source_name} (æºæ¨¡å‹): {source_acc:.4f}")
        if source_lora_acc is not None:
            improvement = (source_lora_acc - source_acc) * 100
            print(f"ğŸ“Š {source_name} + LoRA: {source_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print(f"ğŸ“Š {target_name} (ç›®æ ‡æ¨¡å‹): {target_acc:.4f}")
        
        if transferred_acc is not None:
            improvement = (transferred_acc - target_acc) * 100
            print(f"ğŸ“Š {target_name} + è¿ç§»LoRA: {transferred_acc:.4f} (+{improvement:.2f}%)")
        
        if target_lora_acc is not None:
            improvement = (target_lora_acc - target_acc) * 100
            print(f"ğŸ“Š {target_name} + ç›´è®­LoRA: {target_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print("=" * 60)
        print(f"ğŸ“ è¯¦ç»†ç»“æœ: results/experiment_summary.md")
    
    def _print_optional_commands(self, source_model: str, target_model: str, dataset: str):
        """æ‰“å°å¯é€‰çš„ç›®æ ‡æ¨¡å‹LoRAè®­ç»ƒå‘½ä»¤"""
        target_name = ModelUtils.get_model_short_name(target_model)
        
        print(f"\nğŸ’¡ å¯é€‰ï¼šè®­ç»ƒç›®æ ‡æ¨¡å‹ {target_name} çš„LoRAè¿›è¡Œå¯¹æ¯”")
        print("=" * 60)
        
        # è®­ç»ƒå‘½ä»¤
        train_cmd = f"python {self.config.get('paths.train_script')} " \
                   f"--dataset {dataset} " \
                   f"--base_model {target_model} " \
                   f"--bs {self.config.get('training.default_batch_size')} " \
                   f"--max_steps {self.config.get('training.default_max_steps')}"
        
        print(f"ğŸ¯ è®­ç»ƒ {target_name} LoRA:")
        print(f"   {train_cmd}")
        
        # è¯„ä¼°å‘½ä»¤ 
        eval_cmd = f"python {self.config.get('paths.eval_script')} " \
                  f"--models_list [è®­ç»ƒåçš„æ¨¡å‹è·¯å¾„] " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {self.config.get('evaluation.sample_ratio')} " \
                  f"--base_model {target_model}"
        
        print(f"\nğŸ“Š è¯„ä¼° {target_name} LoRA:")
        print(f"   {eval_cmd}")
        print()
        print("ğŸ’¡ è®­ç»ƒå®Œæˆåå¯ä»¥å¯¹æ¯” 'ç›®æ ‡æ¨¡å‹+LoRA' vs 'ç›®æ ‡æ¨¡å‹+è¿ç§»LoRA' çš„æ€§èƒ½å·®å¼‚")
