"""
LoRAËÆ≠ÁªÉÂíåËøÅÁßª‰∏ªÁÆ°ÈÅì
Êï¥ÂêàÊâÄÊúâÊ®°ÂùóÔºåÊèê‰æõÁªü‰∏ÄÁöÑÁÆ°ÈÅìÊé•Âè£
"""

import os
from typing import Dict, Any, Optional
from tqdm import tqdm

from .config import PipelineConfig, QuickTestConfig
from .trainer import ModelTrainer
from .evaluator import ModelEvaluator
from .transfer import LoRATransfer
from .results import ResultsManager
from .utils import ModelUtils, get_timestamp


class TransferPipeline:
    """LoRAËøÅÁßªÁÆ°ÈÅì‰∏ªÁ±ª"""
    
    def __init__(self, config_path: str = None, quick_test: bool = False):
        """ÂàùÂßãÂåñÁÆ°ÈÅì
        
        Args:
            config_path: ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ
            quick_test: ÊòØÂê¶‰ΩøÁî®Âø´ÈÄüÊµãËØïÈÖçÁΩÆ
        """
        if quick_test:
            self.config = QuickTestConfig()
        else:
            self.config = PipelineConfig(config_path)
        
        self.timestamp = get_timestamp()
        self.experiment_id = None
        
        # ÂàùÂßãÂåñÊ®°Âùó
        self.trainer = ModelTrainer(self.config)
        self.evaluator = ModelEvaluator(self.config)
        self.transfer = LoRATransfer(self.config)
        self.results = ResultsManager(self.config)
    
    def run_pipeline(self, source_model: str, target_model: str, dataset: str, 
                    eval_only: bool = False) -> bool:
        """ËøêË°åÂÆåÊï¥ÁÆ°ÈÅì - Êñ∞ÊµÅÁ®ãÔºöËÆ≠ÁªÉÊ∫êLoRA ‚Üí ËøÅÁßª ‚Üí ËØÑ‰º∞ÁõÆÊ†áÂü∫Á°Ä ‚Üí ËØÑ‰º∞ËøÅÁßªLoRA ‚Üí ËÆ≠ÁªÉÁõÆÊ†áLoRA ‚Üí ËØÑ‰º∞Ê∫êÂü∫Á°Ä
        
        Args:
            source_model: Ê∫êÊ®°ÂûãË∑ØÂæÑ
            target_model: ÁõÆÊ†áÊ®°ÂûãË∑ØÂæÑ
            dataset: Êï∞ÊçÆÈõÜÂêçÁß∞
            eval_only: ‰ªÖËøêË°åËØÑ‰º∞ÔºåË∑≥ËøáËÆ≠ÁªÉÂíåËøÅÁßª
            
        Returns:
            ÊòØÂê¶ÊàêÂäü
        """
        # È™åËØÅËæìÂÖ•
        if not self._validate_inputs(source_model, target_model, dataset):
            return False
        
        # ÂàõÂª∫ÂÆûÈ™åID
        self.experiment_id = ModelUtils.create_experiment_id(
            source_model, target_model, dataset, self.timestamp
        )
        
        print("\n" + "="*60)
        print("LoRA Transfer Pipeline - Experiment Started")
        print("="*60)
        print(f"Experiment ID: {self.experiment_id}")
        print(f"Source Model:  {ModelUtils.get_model_short_name(source_model)}")
        print(f"Target Model:  {ModelUtils.get_model_short_name(target_model)}")
        print(f"Dataset:       {dataset}")
        print("="*60)
        
        # Ê£ÄÊü•ÊòØÂê¶ÊúâÂéÜÂè≤ËÆ∞ÂΩï
        if not eval_only:
            existing = self.results.check_existing_experiment(source_model, target_model, dataset)
            if existing is not None:
                print(f"\nWarning: Found existing experiment (timestamp: {existing['timestamp']})")
                response = input("Continue anyway? (y/N): ").strip().lower()
                if response not in ['y', 'yes']:
                    print("Experiment cancelled.")
                    return False
        
        # ÂàùÂßãÂåñÁªìÊûúÂ≠óÂÖ∏
        results = self._init_results_dict(source_model, target_model, dataset)
        
        # ÊâßË°åÁÆ°ÈÅìÊ≠•È™§
        return self._execute_pipeline_steps(results, source_model, target_model, dataset, eval_only)
    
    def _validate_inputs(self, source_model: str, target_model: str, dataset: str) -> bool:
        """È™åËØÅËæìÂÖ•ÂèÇÊï∞"""
        # Â§ÑÁêÜÊ®°ÂûãË∑ØÂæÑ
        if not source_model.startswith('/'):
            source_model = self.config.get_model_path(source_model)
        if not target_model.startswith('/'):
            target_model = self.config.get_model_path(target_model)
        
        # È™åËØÅÊ®°ÂûãÂ≠òÂú®
        if not ModelUtils.check_model_exists(source_model):
            print(f"‚ùå Ê∫êÊ®°Âûã‰∏çÂ≠òÂú®: {source_model}")
            return False
        if not ModelUtils.check_model_exists(target_model):
            print(f"‚ùå ÁõÆÊ†áÊ®°Âûã‰∏çÂ≠òÂú®: {target_model}")
            return False
        
        # È™åËØÅÊï∞ÊçÆÈõÜ
        supported_datasets = self.config.get('training.datasets', [])
        if dataset not in supported_datasets:
            print(f"‚ùå ‰∏çÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜ: {dataset}")
            print(f"‚úÖ ÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜ: {', '.join(supported_datasets)}")
            return False
        
        return True
    
    def _init_results_dict(self, source_model: str, target_model: str, dataset: str) -> Dict[str, Any]:
        """ÂàùÂßãÂåñÁªìÊûúÂ≠óÂÖ∏"""
        return {
            'experiment_id': self.experiment_id,
            'source_model': source_model,
            'target_model': target_model,
            'dataset': dataset,
            'timestamp': self.timestamp,
            'training_config': f"batch_size={self.config.get('training.default_batch_size')}, "
                              f"max_steps={self.config.get('training.default_max_steps')}, "
                              f"lr={self.config.get('training.default_lr')}",
            'notes': 'Ëá™Âä®ÂåñÁÆ°ÈÅìÁîüÊàê'
        }
    
    def _execute_pipeline_steps(self, results: Dict[str, Any], source_model: str, 
                               target_model: str, dataset: str, eval_only: bool) -> bool:
        """ÊâßË°åÁÆ°ÈÅìÊ≠•È™§"""
        # ÊÄªÊòØÊòæÁ§∫ÂÆåÊï¥ÁöÑ6Ê≠•ËøõÂ∫¶Êù°
        progress_bar = tqdm(total=6, desc="Pipeline Progress", position=1, leave=True, ncols=80)
        
        try:
            # Ê≠•È™§1: ËÆ≠ÁªÉÊ∫êLoRA
            if not eval_only:
                if not self._step_train_source_lora(results, source_model, dataset, progress_bar):
                    raise Exception("Ê∫êÊ®°ÂûãËÆ≠ÁªÉÂ§±Ë¥•")
            else:
                self._step_skip_with_reason("STEP 1/6: TRAIN SOURCE LORA", "‰ªÖËØÑ‰º∞Ê®°ÂºèÔºåË∑≥ËøáËÆ≠ÁªÉ", progress_bar)
            
            # Ê≠•È™§2: ËøÅÁßªLoRA
            if not eval_only:
                if not self._step_transfer_lora(results, source_model, target_model, dataset, progress_bar):
                    raise Exception("LoRAËøÅÁßªÂ§±Ë¥•")
            else:
                self._step_skip_with_reason("STEP 2/6: TRANSFER LORA", "‰ªÖËØÑ‰º∞Ê®°ÂºèÔºåË∑≥ËøáËøÅÁßª", progress_bar)
            
            # Ê≠•È™§3: ËØÑ‰º∞ÁõÆÊ†áÂü∫Á°ÄÊ®°Âûã
            if not self._step_eval_target_base(results, target_model, dataset, progress_bar):
                print("‚ö†Ô∏è ÁõÆÊ†áÂü∫Á°ÄÊ®°ÂûãËØÑ‰º∞Â§±Ë¥•Ôºå‰ΩÜÁªßÁª≠ÊâßË°å")
            
            # Ê≠•È™§4: ËØÑ‰º∞ËøÅÁßªLoRA
            if not eval_only:
                if not self._step_eval_transferred_lora(results, target_model, dataset, progress_bar):
                    print("‚ö†Ô∏è ËøÅÁßªLoRAËØÑ‰º∞Â§±Ë¥•Ôºå‰ΩÜÁªßÁª≠ÊâßË°å")
            else:
                self._step_skip_with_reason("STEP 4/6: EVAL TRANSFERRED LORA", "‰ªÖËØÑ‰º∞Ê®°ÂºèÔºåÊó†ËøÅÁßªLoRAÂèØËØÑ‰º∞", progress_bar)
            
            # Ê≠•È™§5: ËÆ≠ÁªÉÁõÆÊ†áLoRA
            if not eval_only:
                if not self._step_train_target_lora(results, target_model, dataset, progress_bar):
                    print("‚ö†Ô∏è ÁõÆÊ†áÊ®°ÂûãËÆ≠ÁªÉÂ§±Ë¥•Ôºå‰ΩÜÁªßÁª≠ÊâßË°å")
            else:
                self._step_skip_with_reason("STEP 5/6: TRAIN TARGET LORA", "‰ªÖËØÑ‰º∞Ê®°ÂºèÔºåË∑≥ËøáËÆ≠ÁªÉ", progress_bar)
            
            # Ê≠•È™§6: ËØÑ‰º∞Ê∫êÂü∫Á°ÄÊ®°Âûã
            if not self._step_eval_source_base(results, source_model, dataset, progress_bar):
                print("‚ö†Ô∏è Ê∫êÂü∫Á°ÄÊ®°ÂûãËØÑ‰º∞Â§±Ë¥•Ôºå‰ΩÜÁªßÁª≠ÊâßË°å")
            
            # ÊúÄÁªà‰øùÂ≠òÂÆåÊï¥ÁªìÊûú
            progress_bar.set_description("Saving Results")
            self.results.save_results(results)
            progress_bar.close()
            
            # ÊâìÂç∞ÊÄªÁªì
            self._print_summary(results)
            
            # ÊèêÁ§∫ÂèØÈÄâÂëΩ‰ª§
            if not eval_only:
                self._print_optional_commands(source_model, target_model, dataset)
            
            print("\nPipeline completed successfully!")
            return True
            
        except Exception as e:
            progress_bar.close()
            print(f"\nPipeline failed: {e}")
            # ‰øùÂ≠òÈÉ®ÂàÜÁªìÊûú
            self.results.save_partial_results(results, f"Â§±Ë¥•: {e}")
            return False
    
    def _step_skip_with_reason(self, step_title: str, reason: str, progress_bar: tqdm):
        """ÊòæÁ§∫Ë∑≥ËøáÁöÑÊ≠•È™§ÂèäÂéüÂõ†"""
        print(f"\n{'='*60}")
        print(step_title)
        print("="*60)
        print(f"üö´ Ë∑≥ËøáÂéüÂõ†: {reason}")
        print("="*60)
        progress_bar.update(1)
    
    def _step_train_source_lora(self, results: Dict[str, Any], source_model: str, 
                               dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§1: ËÆ≠ÁªÉÊ∫êLoRA"""
        print(f"\n{'='*60}")
        print("STEP 1/6: TRAIN SOURCE LORA")
        print("="*60)
        
        source_lora_path, source_lora_acc, status_msg = self.trainer.train_model(source_model, dataset)
        print(f"Áä∂ÊÄÅ: {status_msg}")
        if source_lora_path is None:
            return False
        
        results.update({
            'source_lora_path': source_lora_path,
            'source_lora_acc': source_lora_acc,
        })
        self.results.save_partial_results(results, "Ê∫êLoRAËÆ≠ÁªÉÂÆåÊàê")
        progress_bar.update(1)
        return True
    
    def _step_transfer_lora(self, results: Dict[str, Any], source_model: str,
                           target_model: str, dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§2: ËøÅÁßªLoRA"""
        print(f"\n{'='*60}")
        print("STEP 2/6: TRANSFER LORA")
        print("="*60)
        
        transferred_lora_path = self.transfer.transfer_lora(
            results['source_lora_path'], source_model, target_model, dataset
        )
        if transferred_lora_path is None:
            return False
        
        results['transferred_lora_path'] = transferred_lora_path
        self.results.save_partial_results(results, "LoRAËøÅÁßªÂÆåÊàê")
        progress_bar.update(1)
        return True
    
    def _step_eval_target_base(self, results: Dict[str, Any], target_model: str, 
                              dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§3: ËØÑ‰º∞ÁõÆÊ†áÂü∫Á°ÄÊ®°Âûã"""
        print(f"\n{'='*60}")
        print("STEP 3/6: EVAL TARGET BASE MODEL")
        print("="*60)
        
        target_acc = self.evaluator.evaluate_base_model(target_model, dataset)
        results['target_acc'] = target_acc
        self.results.save_partial_results(results, "ÁõÆÊ†áÂü∫Á°ÄÊ®°ÂûãËØÑ‰º∞ÂÆåÊàê")
        progress_bar.update(1)
        return target_acc is not None
    
    def _step_eval_transferred_lora(self, results: Dict[str, Any], target_model: str, 
                                   dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§4: ËØÑ‰º∞ËøÅÁßªLoRA"""
        print(f"\n{'='*60}")
        print("STEP 4/6: EVAL TRANSFERRED LORA")
        print("="*60)
        
        transferred_acc = self.evaluator.evaluate_lora_model(
            results['transferred_lora_path'], target_model, dataset
        )
        results['transferred_acc'] = transferred_acc
        self.results.save_partial_results(results, "ËøÅÁßªLoRAËØÑ‰º∞ÂÆåÊàê")
        progress_bar.update(1)
        return transferred_acc is not None
    
    def _step_train_target_lora(self, results: Dict[str, Any], target_model: str, 
                               dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§5: ËÆ≠ÁªÉÁõÆÊ†áLoRA"""
        print(f"\n{'='*60}")
        print("STEP 5/6: TRAIN TARGET LORA")
        print("="*60)
        
        target_lora_path, target_lora_acc, status_msg = self.trainer.train_model(target_model, dataset)
        print(f"Áä∂ÊÄÅ: {status_msg}")
        if target_lora_path is None:
            target_lora_acc = None
        
        results.update({
            'target_lora_path': target_lora_path,
            'target_lora_acc': target_lora_acc,
        })
        self.results.save_partial_results(results, "ÁõÆÊ†áLoRAËÆ≠ÁªÉÂÆåÊàê")
        progress_bar.update(1)
        return True  # Âç≥‰ΩøÂ§±Ë¥•‰πüÁªßÁª≠
    
    def _step_eval_source_base(self, results: Dict[str, Any], source_model: str, 
                              dataset: str, progress_bar: tqdm) -> bool:
        """Ê≠•È™§6: ËØÑ‰º∞Ê∫êÂü∫Á°ÄÊ®°Âûã"""
        print(f"\n{'='*60}")
        print("STEP 6/6: EVAL SOURCE BASE MODEL")
        print("="*60)
        
        source_acc = self.evaluator.evaluate_base_model(source_model, dataset)
        results['source_acc'] = source_acc
        self.results.save_partial_results(results, "Ê∫êÂü∫Á°ÄÊ®°ÂûãËØÑ‰º∞ÂÆåÊàê")
        progress_bar.update(1)
        return source_acc is not None
    
    def _print_summary(self, results: Dict[str, Any]):
        """Print experiment summary"""
        print(f"\n{'='*60}")
        print("EXPERIMENT SUMMARY")
        print("=" * 60)
        
        source_name = ModelUtils.get_model_short_name(results['source_model'])
        target_name = ModelUtils.get_model_short_name(results['target_model'])
        
        # Handle potentially None values
        source_acc = results.get('source_acc', 0) or 0
        target_acc = results.get('target_acc', 0) or 0
        source_lora_acc = results.get('source_lora_acc')
        target_lora_acc = results.get('target_lora_acc')
        transferred_acc = results.get('transferred_acc')
        
        print(f"Source Model ({source_name}):     {source_acc:.4f}")
        if source_lora_acc is not None:
            improvement = (source_lora_acc - source_acc) * 100
            print(f"Source + LoRA:              {source_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print(f"Target Model ({target_name}):     {target_acc:.4f}")
        
        if transferred_acc is not None:
            improvement = (transferred_acc - target_acc) * 100
            print(f"Target + Transferred LoRA:  {transferred_acc:.4f} (+{improvement:.2f}%)")
        
        if target_lora_acc is not None:
            improvement = (target_lora_acc - target_acc) * 100
            print(f"Target + Direct LoRA:       {target_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print("=" * 60)
        print(f"Detailed results: results/experiment_summary.md")
    
    def _print_optional_commands(self, source_model: str, target_model: str, dataset: str):
        """Print optional target model LoRA training commands"""
        target_name = ModelUtils.get_model_short_name(target_model)
        
        print(f"\n{'-'*60}")
        print(f"OPTIONAL: Train {target_name} LoRA for Comparison")
        print("-" * 60)
        
        # Training command
        train_cmd = f"python {self.config.get('paths.train_script')} " \
                   f"--dataset {dataset} " \
                   f"--base_model {target_model} " \
                   f"--bs {self.config.get('training.default_batch_size')} " \
                   f"--max_steps {self.config.get('training.default_max_steps')}"
        
        print(f"Train {target_name} LoRA:")
        print(f"  {train_cmd}")
        
        # Evaluation command 
        eval_cmd = f"python {self.config.get('paths.eval_script')} " \
                  f"--models_list [trained_model_path] " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {self.config.get('evaluation.sample_ratio')} " \
                  f"--base_model {target_model}"
        
        print(f"\nEvaluate {target_name} LoRA:")
        print(f"  {eval_cmd}")
        print()
        print("NOTE: After training, you can compare 'Target+LoRA' vs 'Target+Transferred LoRA' performance")
