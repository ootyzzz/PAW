"""
ç»“æœç®¡ç†æ¨¡å—
è´Ÿè´£å®éªŒç»“æœçš„ä¿å­˜ã€åŠ è½½å’Œç®¡ç†
"""

import os
import csv
from datetime import datetime
from typing import Dict, Any, Optional, List
from .config import PipelineConfig
from .utils import ModelUtils


class ResultsManager:
    """ç»“æœç®¡ç†å™¨ - åŸºäºCSVæ ¼å¼"""
    
    def __init__(self, config: PipelineConfig, verbose: bool = True):
        self.config = config
        self.verbose = verbose
        self._ensure_results_dir()
        self.csv_headers = [
            'base_model', 'lora_source', 'dataset', 'accuracy', 'improvement_pct', 
            'config_details', 'run_file', 'timestamp', 'note'
        ]
    
    def _ensure_results_dir(self):
        """ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨"""
        results_dir = self.config.get('paths.results_dir')
        os.makedirs(results_dir, exist_ok=True)
    
    def _get_csv_path(self) -> str:
        """è·å–CSVæ–‡ä»¶è·¯å¾„"""
        return os.path.join(
            self.config.get('paths.results_dir'), 
            self.config.get('results.csv_file')
        )
    
    def _ensure_csv_exists(self):
        """ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¸¦å¤´éƒ¨çš„æ–‡ä»¶"""
        csv_path = self._get_csv_path()
        if not os.path.exists(csv_path):
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(self.csv_headers)
    
    def add_result(self, base_model: str, lora_source: str, dataset: str, 
                   accuracy: float, improvement_pct: float, config_details: str,
                   run_file: str = "", note: str = ""):
        """æ·»åŠ å•ä¸ªç»“æœåˆ°CSV"""
        self._ensure_csv_exists()
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        row_data = [
            base_model, lora_source, dataset, f"{accuracy:.4f}", 
            f"{improvement_pct:.2f}", config_details, run_file, timestamp, note
        ]
        
        csv_path = self._get_csv_path()
        with open(csv_path, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(row_data)
        
        if self.verbose:
            print(f"ğŸ’¾ ç»“æœå·²æ·»åŠ : {base_model} - {lora_source} - {accuracy:.4f}")
    
    def save_pipeline_results(self, experiment_data: Dict[str, Any]):
        """ä¿å­˜å®Œæ•´ç®¡é“å®éªŒç»“æœ"""
        if self.verbose:
            print(f"\nğŸ’¾ ä¿å­˜ç®¡é“å®éªŒç»“æœ...")
        
        # æå–åŸºç¡€ä¿¡æ¯
        source_model = ModelUtils.get_model_short_name(experiment_data.get('source_model', ''))
        target_model = ModelUtils.get_model_short_name(experiment_data.get('target_model', ''))
        dataset = experiment_data.get('dataset', '')
        experiment_id = experiment_data.get('experiment_id', '')
        
        # è·å–é…ç½®ä¿¡æ¯
        training_config = experiment_data.get('training_config', '')
        
        # æ·»åŠ å„ç§æ¨¡å‹ç»“æœ
        results_added = 0
        
        # 1. æºåŸºç¡€æ¨¡å‹
        if 'source_acc' in experiment_data and experiment_data['source_acc'] is not None:
            self.add_result(
                base_model=source_model,
                lora_source="base",
                dataset=dataset,
                accuracy=experiment_data['source_acc'],
                improvement_pct=0.0,
                config_details="-",
                run_file=experiment_id,
                note="æºåŸºç¡€æ¨¡å‹"
            )
            results_added += 1
        
        # 2. æºLoRAæ¨¡å‹
        if 'source_lora_acc' in experiment_data and experiment_data['source_lora_acc'] is not None:
            source_base_acc = experiment_data.get('source_acc', 0)
            improvement = ((experiment_data['source_lora_acc'] - source_base_acc) / source_base_acc * 100) if source_base_acc > 0 else 0
            
            self.add_result(
                base_model=source_model,
                lora_source="lora",
                dataset=dataset,
                accuracy=experiment_data['source_lora_acc'],
                improvement_pct=improvement,
                config_details=f"LoRA: {source_model}, {training_config}",
                run_file=experiment_data.get('source_lora_path', ''),
                note="æºLoRAæ¨¡å‹"
            )
            results_added += 1
        
        # 3. ç›®æ ‡åŸºç¡€æ¨¡å‹
        if 'target_acc' in experiment_data and experiment_data['target_acc'] is not None:
            self.add_result(
                base_model=target_model,
                lora_source="base",
                dataset=dataset,
                accuracy=experiment_data['target_acc'],
                improvement_pct=0.0,
                config_details="-",
                run_file=experiment_id,
                note="ç›®æ ‡åŸºç¡€æ¨¡å‹"
            )
            results_added += 1
        
        # 4. è¿ç§»LoRAæ¨¡å‹
        if 'transferred_acc' in experiment_data and experiment_data['transferred_acc'] is not None:
            target_base_acc = experiment_data.get('target_acc', 0)
            improvement = ((experiment_data['transferred_acc'] - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
            
            # è·å–è¿ç§»é…ç½®
            similarity_threshold = self.config.get('transfer.similarity_threshold', 0.0001)
            transfer_config = f"LoRA source: {source_model}, {training_config}; Adapter: è¿ç§», sim={similarity_threshold}"
            
            self.add_result(
                base_model=target_model,
                lora_source="adpt",
                dataset=dataset,
                accuracy=experiment_data['transferred_acc'],
                improvement_pct=improvement,
                config_details=transfer_config,
                run_file=experiment_data.get('transferred_lora_path', ''),
                note="è¿ç§»LoRAæ¨¡å‹"
            )
            results_added += 1
        
        # 5. ç›®æ ‡LoRAæ¨¡å‹
        if 'target_lora_acc' in experiment_data and experiment_data['target_lora_acc'] is not None:
            target_base_acc = experiment_data.get('target_acc', 0)
            improvement = ((experiment_data['target_lora_acc'] - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
            
            self.add_result(
                base_model=target_model,
                lora_source="lora",
                dataset=dataset,
                accuracy=experiment_data['target_lora_acc'],
                improvement_pct=improvement,
                config_details=f"LoRA: {target_model}, {training_config}",
                run_file=experiment_data.get('target_lora_path', ''),
                note="ç›®æ ‡LoRAæ¨¡å‹"
            )
            results_added += 1
        
        if self.verbose:
            print(f"âœ… å·²æ·»åŠ  {results_added} æ¡ç»“æœåˆ° {self._get_csv_path()}")
        
        return True
    
    def save_results(self, experiment_data: Dict[str, Any]):
        """ä¿å­˜å®éªŒç»“æœ - å…¼å®¹åŸæ¥å£ï¼Œä½†é¿å…é‡å¤ä¿å­˜"""
        if self.verbose:
            print(f"\nğŸ’¾ ä¿å­˜å®Œæ•´å®éªŒç»“æœ...")
        
        # å¦‚æœå·²ç»é€šè¿‡save_partial_resultsä¿å­˜äº†ç»“æœï¼Œå°±ä¸é‡å¤ä¿å­˜
        if hasattr(self, '_saved_keys') and self._saved_keys:
            if self.verbose:
                print(f"âœ… æ‰€æœ‰ç»“æœå·²é€šè¿‡å¢é‡ä¿å­˜å®Œæˆï¼Œè·³è¿‡é‡å¤ä¿å­˜")
            return True
        else:
            # å¦‚æœæ²¡æœ‰å¢é‡ä¿å­˜è¿‡ï¼Œå°±ä½¿ç”¨å®Œæ•´ä¿å­˜
            return self.save_pipeline_results(experiment_data)
    
    def save_partial_results(self, results: Dict[str, Any], message: str):
        """ä¿å­˜éƒ¨åˆ†ç»“æœ - å¢é‡ä¿å­˜ï¼Œé¿å…é‡å¤"""
        if self.verbose:
            print(f"ğŸ’¾ {message} - ç«‹å³æ›´æ–°ç»“æœ...")
        
        # ä½¿ç”¨å®ä¾‹å˜é‡è¿½è¸ªå·²ä¿å­˜çš„ç»“æœï¼Œé¿å…é‡å¤
        if not hasattr(self, '_saved_keys'):
            self._saved_keys = set()
        
        try:
            # æå–åŸºç¡€ä¿¡æ¯
            source_model = ModelUtils.get_model_short_name(results.get('source_model', ''))
            target_model = ModelUtils.get_model_short_name(results.get('target_model', ''))
            dataset = results.get('dataset', '')
            experiment_id = results.get('experiment_id', '')
            training_config = results.get('training_config', '')
            
            # æ ¹æ®messageç±»å‹å†³å®šä¿å­˜å“ªä¸ªç»“æœ
            if "æºLoRAè®­ç»ƒå®Œæˆ" in message and 'source_lora_acc' in results:
                key = f"{source_model}_lora_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    source_base_acc = results.get('source_acc', 0)
                    improvement = ((results['source_lora_acc'] - source_base_acc) / source_base_acc * 100) if source_base_acc > 0 else 0
                    self.add_result(
                        base_model=source_model,
                        lora_source="lora",
                        dataset=dataset,
                        accuracy=results['source_lora_acc'],
                        improvement_pct=improvement,
                        config_details=f"LoRA: {source_model}, {training_config}",
                        run_file=results.get('source_lora_path', ''),
                        note="æºLoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "ç›®æ ‡åŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ" in message and 'target_acc' in results:
                key = f"{target_model}_base_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    self.add_result(
                        base_model=target_model,
                        lora_source="base",
                        dataset=dataset,
                        accuracy=results['target_acc'],
                        improvement_pct=0.0,
                        config_details="-",
                        run_file=experiment_id,
                        note="ç›®æ ‡åŸºç¡€æ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "è¿ç§»LoRAè¯„ä¼°å®Œæˆ" in message and 'transferred_acc' in results:
                key = f"{target_model}_adpt_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    target_base_acc = results.get('target_acc', 0)
                    improvement = ((results['transferred_acc'] - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
                    similarity_threshold = self.config.get('transfer.similarity_threshold', 0.0001)
                    transfer_config = f"LoRA source: {source_model}, {training_config}; Adapter: è¿ç§», sim={similarity_threshold}"
                    self.add_result(
                        base_model=target_model,
                        lora_source="adpt",
                        dataset=dataset,
                        accuracy=results['transferred_acc'],
                        improvement_pct=improvement,
                        config_details=transfer_config,
                        run_file=results.get('transferred_lora_path', ''),
                        note="è¿ç§»LoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "ç›®æ ‡LoRAè®­ç»ƒå®Œæˆ" in message and 'target_lora_acc' in results:
                key = f"{target_model}_lora_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    target_base_acc = results.get('target_acc', 0)
                    improvement = ((results['target_lora_acc'] - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
                    self.add_result(
                        base_model=target_model,
                        lora_source="lora",
                        dataset=dataset,
                        accuracy=results['target_lora_acc'],
                        improvement_pct=improvement,
                        config_details=f"LoRA: {target_model}, {training_config}",
                        run_file=results.get('target_lora_path', ''),
                        note="ç›®æ ‡LoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "æºåŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ" in message and 'source_acc' in results:
                key = f"{source_model}_base_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    self.add_result(
                        base_model=source_model,
                        lora_source="base",
                        dataset=dataset,
                        accuracy=results['source_acc'],
                        improvement_pct=0.0,
                        config_details="-",
                        run_file=experiment_id,
                        note="æºåŸºç¡€æ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "LoRAè¿ç§»å®Œæˆ" in message:
                # è¿ç§»å®Œæˆä½†è¿˜æ²¡è¯„ä¼°ï¼Œä¸ä¿å­˜accuracy
                pass
                
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ ä¿å­˜ç»“æœæ—¶å‡ºé”™: {e}")
                # ç®€å•çš„å¤‡ä»½åˆ°JSON
                backup_path = os.path.join(
                    self.config.get('paths.results_dir'),
                    f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                try:
                    import json
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
                    print(f"ğŸ“ å¤‡ç”¨ä¿å­˜: {backup_path}")
                except Exception as backup_e:
                    print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {backup_e}")
    
    def check_existing_experiment(self, source_model: str, target_model: str, dataset: str) -> Optional[Dict]:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒçš„å®éªŒ"""
        csv_path = self._get_csv_path()
        if not os.path.exists(csv_path):
            return None
        
        source_short = ModelUtils.get_model_short_name(source_model)
        target_short = ModelUtils.get_model_short_name(target_model)
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if (row['base_model'] in [source_short, target_short] and 
                        row['dataset'] == dataset and 
                        row['lora_source'] == 'adpt'):
                        return {'timestamp': row['timestamp']}
        except Exception:
            pass
        
        return None
