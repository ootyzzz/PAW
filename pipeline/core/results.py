"""
ç»“æœç®¡ç†æ¨¡å—
è´Ÿè´£å®éªŒç»“æœçš„ä¿å­˜ã€åŠ è½½å’Œç®¡ç†
"""

import os
import csv
from datetime import datetime
from typing import Dict, Any, Optional, List
from .config import PipelineConfig
from .utils import ModelUtils


class ResultsManager:
    """ç»“æœç®¡ç†å™¨ - åŸºäºCSVæ ¼å¼"""
    
    def __init__(self, config: PipelineConfig, verbose: bool = True):
        self.config = config
        self.verbose = verbose
        self._ensure_results_dir()
        self.csv_headers = [
            'base_model', 'lora_source', 'dataset', 'accuracy', 'improvement_pct', 
            'config_details', 'run_file', 'timestamp', 'note'
        ]
    
    def _ensure_results_dir(self):
        """ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨"""
        results_dir = self.config.get('paths.results_dir')
        os.makedirs(results_dir, exist_ok=True)
        # ç¡®ä¿backup_csvç›®å½•å­˜åœ¨
        backup_dir = os.path.join(results_dir, 'backup_csv')
        os.makedirs(backup_dir, exist_ok=True)
    
    def _get_csv_path(self) -> str:
        """è·å–CSVæ–‡ä»¶è·¯å¾„"""
        return os.path.join(
            self.config.get('paths.results_dir'), 
            self.config.get('results.csv_file')
        )
    
    def _ensure_csv_exists(self):
        """ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¸¦å¤´éƒ¨çš„æ–‡ä»¶"""
        csv_path = self._get_csv_path()
        if not os.path.exists(csv_path):
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(self.csv_headers)
    
    def _is_duplicate(self, base_model: str, lora_source: str, dataset: str, 
                     accuracy: float, config_details: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è®°å½•"""
        csv_path = self._get_csv_path()
        if not os.path.exists(csv_path):
            return False
        
        # æ ¼å¼åŒ–accuracyç”¨äºæ¯”è¾ƒ
        accuracy_str = f"{accuracy:.4f}" if accuracy is not None else "0.0000"
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if (row.get('base_model') == base_model and 
                        row.get('lora_source') == lora_source and
                        row.get('dataset') == dataset and
                        row.get('accuracy') == accuracy_str and
                        row.get('config_details') == config_details):
                        return True
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ æ£€æŸ¥é‡å¤è®°å½•æ—¶å‡ºé”™: {e}")
        
        return False
    
    def _validate_data(self, base_model: str, lora_source: str, dataset: str, 
                      accuracy: float, improvement_pct: float, config_details: str,
                      run_file: str, note: str) -> bool:
        """éªŒè¯æ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§"""
        try:
            # æ£€æŸ¥å¿…å¡«å­—æ®µ
            if not base_model or not lora_source or not dataset:
                if self.verbose:
                    print(f"âš ï¸ ç¼ºå°‘å¿…å¡«å­—æ®µ: base_model='{base_model}', lora_source='{lora_source}', dataset='{dataset}'")
                return False
            
            # æ£€æŸ¥å­—æ®µä¸­æ˜¯å¦åŒ…å«æ¢è¡Œç¬¦æˆ–é€—å·ï¼ˆä¼šç ´åCSVæ ¼å¼ï¼‰
            fields_to_check = [base_model, lora_source, dataset, config_details, run_file, note]
            for field in fields_to_check:
                if isinstance(field, str) and ('\n' in field or '\r' in field):
                    if self.verbose:
                        print(f"âš ï¸ å­—æ®µåŒ…å«æ¢è¡Œç¬¦ï¼Œå¯èƒ½ç ´åCSVæ ¼å¼: '{field[:50]}...'")
                    return False
            
            # æ£€æŸ¥æ•°å€¼å­—æ®µ
            if accuracy is not None and (accuracy < 0 or accuracy > 1):
                if self.verbose:
                    print(f"âš ï¸ accuracyå€¼å¼‚å¸¸: {accuracy}")
                # å…è®¸ä½†è­¦å‘Š
            
            return True
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ æ•°æ®éªŒè¯æ—¶å‡ºé”™: {e}")
            return False

    def add_result(self, base_model: str, lora_source: str, dataset: str, 
                   accuracy: float, improvement_pct: float, config_details: str,
                   run_file: str = "", note: str = ""):
        """æ·»åŠ å•ä¸ªç»“æœåˆ°CSVï¼Œæ”¯æŒæŸ¥é‡å’Œæ•°æ®éªŒè¯"""
        self._ensure_csv_exists()
        
        # æ•°æ®éªŒè¯
        if not self._validate_data(base_model, lora_source, dataset, accuracy, 
                                 improvement_pct, config_details, run_file, note):
            if self.verbose:
                print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡å†™å…¥")
            return False
        
        # æŸ¥é‡æ£€æŸ¥
        if self._is_duplicate(base_model, lora_source, dataset, accuracy, config_details):
            if self.verbose:
                accuracy_display = accuracy if accuracy is not None else 0.0
                print(f"ğŸ”„ é‡å¤è®°å½•ï¼Œè·³è¿‡å†™å…¥: {base_model} - {lora_source} - {accuracy_display:.4f}")
            return False
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # å¤„ç†Noneå€¼çš„æ ¼å¼åŒ–
        accuracy_str = f"{accuracy:.4f}" if accuracy is not None else "0.0000"
        improvement_str = f"{improvement_pct:.2f}" if improvement_pct is not None else "0.00"
        
        # æ¸…ç†å­—æ®µä¸­çš„æ¢è¡Œç¬¦
        base_model = base_model.replace('\n', ' ').replace('\r', ' ')
        lora_source = lora_source.replace('\n', ' ').replace('\r', ' ')
        dataset = dataset.replace('\n', ' ').replace('\r', ' ')
        config_details = config_details.replace('\n', ' ').replace('\r', ' ')
        run_file = run_file.replace('\n', ' ').replace('\r', ' ')
        note = note.replace('\n', ' ').replace('\r', ' ')
        
        row_data = [
            base_model, lora_source, dataset, accuracy_str, 
            improvement_str, config_details, run_file, timestamp, note
        ]
        
        csv_path = self._get_csv_path()
        try:
            with open(csv_path, 'a', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
            
            if self.verbose:
                accuracy_display = accuracy if accuracy is not None else 0.0
                print(f"ğŸ’¾ ç»“æœå·²æ·»åŠ : {base_model} - {lora_source} - {accuracy_display:.4f}")
            return True
        except Exception as e:
            if self.verbose:
                print(f"âŒ å†™å…¥CSVæ—¶å‡ºé”™: {e}")
            return False
    
    def save_results(self, experiment_data: Dict[str, Any]):
        """ä¿å­˜å®éªŒç»“æœ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ç”Ÿæˆæ±‡æ€»æ–‡ä»¶"""
        if self.verbose:
            print(f"\nğŸ’¾ ä¿å­˜å®Œæ•´å®éªŒç»“æœ...")
        
        # å¦‚æœå·²ç»é€šè¿‡save_partial_resultsä¿å­˜äº†ç»“æœï¼Œå°±ä¸é‡å¤ä¿å­˜
        if hasattr(self, '_saved_keys') and self._saved_keys:
            if self.verbose:
                print(f"âœ… æ‰€æœ‰ç»“æœå·²é€šè¿‡å¢é‡ä¿å­˜å®Œæˆï¼Œè·³è¿‡é‡å¤ä¿å­˜")
            return True
        else:
            if self.verbose:
                print(f"âœ… ç»“æœå·²é€šè¿‡åˆ†æ­¥ä¿å­˜å®Œæˆï¼Œæ— éœ€é¢å¤–å¤„ç†")
            return True
    
    def save_partial_results(self, results: Dict[str, Any], message: str):
        """ä¿å­˜éƒ¨åˆ†ç»“æœ - å¢é‡ä¿å­˜ï¼Œé¿å…é‡å¤"""
        if self.verbose:
            print(f"ğŸ’¾ {message} - ç«‹å³æ›´æ–°ç»“æœ...")
        
        # ä½¿ç”¨å®ä¾‹å˜é‡è¿½è¸ªå·²ä¿å­˜çš„ç»“æœï¼Œé¿å…é‡å¤
        if not hasattr(self, '_saved_keys'):
            self._saved_keys = set()
        
        try:
            # æå–åŸºç¡€ä¿¡æ¯
            source_model = ModelUtils.get_model_short_name(results.get('source_model', ''))
            target_model = ModelUtils.get_model_short_name(results.get('target_model', ''))
            dataset = results.get('dataset', '')
            experiment_id = results.get('experiment_id', '')
            training_config = results.get('training_config', '')
            
            # æ ¹æ®messageç±»å‹å†³å®šä¿å­˜å“ªä¸ªç»“æœ
            if "æºLoRAè®­ç»ƒå®Œæˆ" in message and 'source_lora_acc' in results:
                key = f"{source_model}_lora_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    source_base_acc = results.get('source_acc', 0) or 0
                    source_lora_acc = results.get('source_lora_acc', 0) or 0
                    improvement = ((source_lora_acc - source_base_acc) / source_base_acc * 100) if source_base_acc > 0 else 0
                    self.add_result(
                        base_model=source_model,
                        lora_source="lora",
                        dataset=dataset,
                        accuracy=source_lora_acc,
                        improvement_pct=improvement,
                        config_details=f"LoRA: {source_model}, {training_config}",
                        run_file=results.get('source_lora_path', ''),
                        note="æºLoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "ç›®æ ‡åŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ" in message and 'target_acc' in results:
                key = f"{target_model}_base_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    self.add_result(
                        base_model=target_model,
                        lora_source="base",
                        dataset=dataset,
                        accuracy=results['target_acc'],
                        improvement_pct=0.0,
                        config_details="-",
                        run_file=experiment_id,
                        note="ç›®æ ‡åŸºç¡€æ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "è¿ç§»LoRAè¯„ä¼°å®Œæˆ" in message and 'transferred_acc' in results:
                key = f"{target_model}_adpt_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    target_base_acc = results.get('target_acc', 0) or 0
                    transferred_acc = results.get('transferred_acc', 0) or 0
                    improvement = ((transferred_acc - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
                    similarity_threshold = self.config.get('transfer.similarity_threshold', 0.0001)
                    transfer_config = f"LoRA source: {source_model}, {training_config}; Adapter: è¿ç§», sim={similarity_threshold}"
                    self.add_result(
                        base_model=target_model,
                        lora_source="adpt",
                        dataset=dataset,
                        accuracy=transferred_acc,
                        improvement_pct=improvement,
                        config_details=transfer_config,
                        run_file=results.get('transferred_lora_path', ''),
                        note="è¿ç§»LoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "ç›®æ ‡LoRAè®­ç»ƒå®Œæˆ" in message and 'target_lora_acc' in results:
                key = f"{target_model}_lora_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    target_base_acc = results.get('target_acc', 0) or 0
                    target_lora_acc = results.get('target_lora_acc', 0) or 0
                    improvement = ((target_lora_acc - target_base_acc) / target_base_acc * 100) if target_base_acc > 0 else 0
                    self.add_result(
                        base_model=target_model,
                        lora_source="lora",
                        dataset=dataset,
                        accuracy=target_lora_acc,
                        improvement_pct=improvement,
                        config_details=f"LoRA: {target_model}, {training_config}",
                        run_file=results.get('target_lora_path', ''),
                        note="ç›®æ ‡LoRAæ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "æºåŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ" in message and 'source_acc' in results:
                key = f"{source_model}_base_{dataset}_{experiment_id}"
                if key not in self._saved_keys:
                    self.add_result(
                        base_model=source_model,
                        lora_source="base",
                        dataset=dataset,
                        accuracy=results['source_acc'],
                        improvement_pct=0.0,
                        config_details="-",
                        run_file=experiment_id,
                        note="æºåŸºç¡€æ¨¡å‹"
                    )
                    self._saved_keys.add(key)
            
            elif "LoRAè¿ç§»å®Œæˆ" in message:
                # è¿ç§»å®Œæˆä½†è¿˜æ²¡è¯„ä¼°ï¼Œä¸ä¿å­˜accuracy
                pass
                
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ ä¿å­˜ç»“æœæ—¶å‡ºé”™: {e}")
                # ç®€å•çš„å¤‡ä»½åˆ°JSON
                backup_path = os.path.join(
                    self.config.get('paths.results_dir'),
                    f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                )
                try:
                    import json
                    # CSVå†™å…¥å¤±è´¥æ—¶çš„å¤‡ä»½æ–‡ä»¶ - æ”¾åœ¨backup_csvç›®å½•
                    backup_dir = os.path.join(self.config.get('paths.results_dir'), 'backup_csv')
                    os.makedirs(backup_dir, exist_ok=True)
                    backup_filename = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    backup_path = os.path.join(backup_dir, backup_filename)
                    
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
                    print(f"ğŸ“ å¤‡ç”¨ä¿å­˜: {backup_path}")
                except Exception as backup_e:
                    print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {backup_e}")
    
    def check_existing_experiment(self, source_model: str, target_model: str, dataset: str) -> Optional[Dict]:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒçš„å®éªŒ"""
        csv_path = self._get_csv_path()
        if not os.path.exists(csv_path):
            return None
        
        source_short = ModelUtils.get_model_short_name(source_model)
        target_short = ModelUtils.get_model_short_name(target_model)
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if (row['base_model'] in [source_short, target_short] and 
                        row['dataset'] == dataset and 
                        row['lora_source'] == 'adpt'):
                        return {'timestamp': row['timestamp']}
        except Exception:
            pass
        
        return None
