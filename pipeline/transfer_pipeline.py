#!/usr/bin/env python3
"""
transfer_pipeline.py
è‡ªåŠ¨åŒ–LoRAè®­ç»ƒå’Œè¿ç§»ç®¡é“

ä¸»è¦åŠŸèƒ½:
1. è®­ç»ƒ source model + LoRA
2. è®­ç»ƒ target model + LoRA  
3. è¿ç§» source LoRA â†’ target model
4. è¯„ä¼°æ‰€æœ‰5ä¸ªæ¨¡å‹
5. æ›´æ–°ç»“æœè¡¨æ ¼

ä½¿ç”¨æ–¹æ³•:
python transfer_pipeline.py \
  --source_model Llama-3.2-3B-Instruct \
  --target_model Qwen_Qwen2.5-1.5B \
  --dataset arc-challenge
"""

import os
import sys
import yaml
import argparse
import subprocess
import pandas as pd
import warnings
from datetime import datetime
from pathlib import Path
import json
import shutil
from tqdm import tqdm
import time

# ä¿®å¤MKLçº¿ç¨‹å±‚å†²çª - å¿…é¡»åœ¨å¯¼å…¥numpy/pandasä¹‹å‰è®¾ç½®
os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'
os.environ['MKL_THREADING_LAYER'] = 'GNU'

# å±è”½ Transformers è­¦å‘Šï¼Œä½†ä¿ç•™é‡è¦ä¿¡æ¯
warnings.filterwarnings("ignore", message=".*cache_implementation.*")
warnings.filterwarnings("ignore", message=".*generation flags are not valid.*")
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

class TransferPipeline:
    def __init__(self, config_path="config/pipeline_config.yaml"):
        """åˆå§‹åŒ–ç®¡é“"""
        self.config = self._load_config(config_path)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_id = None
        
    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _get_model_short_name(self, model_path):
        """è·å–æ¨¡å‹ç®€ç§°"""
        model_name = os.path.basename(model_path)
        # ç§»é™¤å¸¸è§å‰ç¼€
        model_name = model_name.replace("models/", "")
        return model_name
    
    def _create_experiment_id(self, source_model, target_model, dataset):
        """åˆ›å»ºå®éªŒID"""
        source_short = self._get_model_short_name(source_model)
        target_short = self._get_model_short_name(target_model)
        return f"{source_short}_to_{target_short}_{dataset}_{self.timestamp}"
    
    def _check_existing_experiment(self, source_model, target_model, dataset):
        """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå®éªŒ"""
        csv_path = os.path.join(self.config['paths']['results_dir'], 
                               self.config['results']['csv_file'])
        
        if not os.path.exists(csv_path):
            return None
            
        try:
            df = pd.read_csv(csv_path)
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºæ–‡ä»¶æˆ–åªæœ‰è¡¨å¤´
            if df.empty or len(df) == 0:
                return None
                
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹è¿›è¡Œæ¯”è¾ƒ
            df['source_model'] = df['source_model'].astype(str)
            df['target_model'] = df['target_model'].astype(str)
            df['dataset'] = df['dataset'].astype(str)
            
            existing = df[
                (df['source_model'] == str(source_model)) & 
                (df['target_model'] == str(target_model)) & 
                (df['dataset'] == str(dataset))
            ]
            if not existing.empty:
                return existing.iloc[-1]  # è¿”å›æœ€æ–°çš„è®°å½•
        except (pd.errors.EmptyDataError, KeyError) as e:
            print(f"ğŸ’¡ å°†é‡æ–°åˆ›å»ºç»“æœæ–‡ä»¶")
            # é‡æ–°åˆ›å»ºCSVæ–‡ä»¶
            header = "experiment_id,source_model,target_model,dataset,source_acc,source_lora_acc,target_acc,target_lora_acc,transferred_acc,source_lora_path,target_lora_path,transferred_lora_path,timestamp,notes,training_config"
            with open(csv_path, 'w') as f:
                f.write(header + '\n')
        except Exception as e:
            print(f"âš ï¸ è¯»å–å†å²è®°å½•æ—¶å‡ºé”™: {e}")
            print(f"ğŸ’¡ å°†é‡æ–°åˆ›å»ºç»“æœæ–‡ä»¶")
        
        return None
    
    def _run_command(self, cmd, description, cwd=None):
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        print(f"\nğŸš€ {description}")
        print(f"ğŸ“ å‘½ä»¤: {cmd}")
        
        try:
            import re
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä¿ç•™è®­ç»ƒç›¸å…³è¾“å‡º
            env = os.environ.copy()
            env.update({
                'PYTHONUNBUFFERED': '1',  # ç¡®ä¿Pythonè¾“å‡ºä¸è¢«ç¼“å†²
                'PYTHONIOENCODING': 'utf-8'
            })
            
            # å¯åŠ¨è¿›ç¨‹ï¼Œä½¿ç”¨å®æ—¶è¾“å‡º
            process = subprocess.Popen(
                cmd,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,  # åˆå¹¶stderråˆ°stdout
                text=True,
                cwd=cwd,
                bufsize=0,  # æ— ç¼“å†²
                universal_newlines=True,
                env=env
            )
            
            stdout_lines = []
            current_progress_line = None
            
            # å®æ—¶å¤„ç†è¾“å‡º
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    line = output.strip()
                    stdout_lines.append(line)
                    
                    # æ˜¾ç¤ºé‡è¦çš„SwanLabä¿¡æ¯ï¼ˆåŒ…æ‹¬é“¾æ¥å’ŒåŸºæœ¬çŠ¶æ€ï¼‰
                    if any(keyword in line for keyword in [
                        'swanlab.cn', 'View run at', 'View project at',
                        'Tracking run with swanlab', 'Syncing run'
                    ]):
                        print(f"ğŸ”— {line}")
                        continue
                    
                    # æ˜¾ç¤ºè®­ç»ƒå¼€å§‹ä¿¡æ¯
                    if any(keyword in line for keyword in [
                        'ğŸš€ Lightning LoRA è®­ç»ƒ', 'å¼€å§‹Lightningè®­ç»ƒ',
                        'Lightningè®­ç»ƒå®Œæˆ', 'å®éªŒç›®å½•:', 'æœ€ç»ˆæ¨¡å‹:'
                    ]):
                        print(f"   {line}")
                        continue
                    
                    # å¤„ç†è¿›åº¦æ¡ - åªæ˜¾ç¤ºæœ€æ–°çš„è¿›åº¦
                    if re.search(r'\d+%\|[â–ˆâ–‰â–Šâ–‹â–Œâ–â–â– ]*\|', line) or ('it/s' in line and ('Epoch' in line or 'step' in line)):
                        if current_progress_line:
                            # æ¸…é™¤ä¹‹å‰çš„è¿›åº¦è¡Œ
                            print('\r' + ' ' * len(current_progress_line) + '\r', end='', flush=True)
                        print(f"\rğŸ“Š {line}", end='', flush=True)
                        current_progress_line = line
                    else:
                        # å¦‚æœæœ‰ä¹‹å‰çš„è¿›åº¦è¡Œï¼Œå…ˆæ¢è¡Œ
                        if current_progress_line:
                            print()  # æ¢è¡Œ
                            current_progress_line = None
                        
                        # æ˜¾ç¤ºé‡è¦çš„çŠ¶æ€ä¿¡æ¯ï¼Œä½†è¿‡æ»¤å™ªéŸ³
                        if not any(noise in line for noise in [
                            'LOCAL_RANK', 'CUDA_VISIBLE_DEVICES', 'Sanity Checking DataLoader',
                            'generation flags are not valid', 'cache_implementation',
                            'Using 16bit Automatic Mixed Precision', 'GPU available:', 'TPU available:'
                        ]) and line.strip():
                            # æ˜¾ç¤ºæœ‰ç”¨çš„ä¿¡æ¯
                            if any(useful in line for useful in [
                                'âœ…', 'ğŸ“Š', 'ğŸ¯', 'ğŸ“', 'âš ï¸', 'âŒ', 
                                'accuracy', 'loss', 'test_result', 'final_model',
                                'Lightningè®­ç»ƒ', 'æ¨¡å‹åŠ è½½', 'å¯è®­ç»ƒå‚æ•°'
                            ]):
                                print(f"   {line}")
            
            # ç¡®ä¿æœ€åæ¢è¡Œ
            if current_progress_line:
                print()
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            process.wait()
            
            if process.returncode != 0:
                print(f"âŒ å‘½ä»¤å¤±è´¥ (é€€å‡ºç : {process.returncode})")
                # æ˜¾ç¤ºæœ€åå‡ è¡Œè¾“å‡ºä½œä¸ºé”™è¯¯ä¿¡æ¯
                if stdout_lines:
                    print("æœ€åçš„è¾“å‡º:")
                    for line in stdout_lines[-5:]:
                        if line.strip():
                            print(f"   {line}")
                return None
            
            print(f"âœ… {description} å®Œæˆ")
            return '\n'.join(stdout_lines)
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
            return None
    
    def _parse_training_output(self, output):
        """è§£æè®­ç»ƒè¾“å‡ºï¼Œæå–å‡†ç¡®ç‡"""
        try:
            lines = output.split('\n')
            for line in lines:
                if 'test/accuracy' in line and 'test_result' in line:
                    # æå–ç±»ä¼¼ 'test/accuracy': 0.7465870380401611 çš„ä¿¡æ¯
                    import re
                    match = re.search(r"'test/accuracy':\s*([\d.]+)", line)
                    if match:
                        return float(match.group(1))
            return None
        except Exception as e:
            print(f"âš ï¸ è§£æè®­ç»ƒè¾“å‡ºæ—¶å‡ºé”™: {e}")
            return None
    
    def train_model(self, model_path, dataset):
        """è®­ç»ƒæ¨¡å‹+LoRA"""
        model_name = self._get_model_short_name(model_path)
        print(f"\nğŸ“š å¼€å§‹è®­ç»ƒ {model_name} + LoRA (æ•°æ®é›†: {dataset})")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœ
        runs_dir = os.path.join(self.config['paths']['runs_dir'], dataset, model_name)
        if os.path.exists(runs_dir):
            # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ
            existing_runs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
            if existing_runs:
                latest_run = sorted(existing_runs)[-1]
                final_model_path = os.path.join(runs_dir, latest_run, "final_model")
                if os.path.exists(final_model_path):
                    print(f"âœ… å‘ç°å·²æœ‰è®­ç»ƒç»“æœ: {final_model_path}")
                    return final_model_path, None  # è¿”å›è·¯å¾„å’Œç©ºçš„å‡†ç¡®ç‡(éœ€è¦è¯„ä¼°)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = f"cd {os.path.dirname(self.config['paths']['train_script'])} && " \
              f"python {os.path.basename(self.config['paths']['train_script'])} " \
              f"--dataset {dataset} " \
              f"--base_model {model_path} " \
              f"--bs {self.config['training']['default_batch_size']} " \
              f"--max_steps {self.config['training']['default_max_steps']}"
        
        output = self._run_command(cmd, f"è®­ç»ƒ {model_name} LoRA")
        if output is None:
            return None, None
        
        # è§£æè¾“å‡ºè·å–æ¨¡å‹è·¯å¾„å’Œå‡†ç¡®ç‡
        accuracy = self._parse_training_output(output)
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„æ¨¡å‹è·¯å¾„
        runs_dir = os.path.join(self.config['paths']['runs_dir'], dataset, model_name)
        if os.path.exists(runs_dir):
            runs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
            if runs:
                latest_run = sorted(runs)[-1]
                final_model_path = os.path.join(runs_dir, latest_run, "final_model")
                return final_model_path, accuracy
        
        return None, None
    
    def transfer_lora(self, source_lora_path, source_model, target_model, dataset):
        """è¿ç§»LoRA"""
        source_name = self._get_model_short_name(source_model)
        target_name = self._get_model_short_name(target_model)
        
        print(f"\nğŸ”„ å¼€å§‹è¿ç§» LoRA: {source_name} â†’ {target_name}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(
            self.config['paths']['transferred_lora_dir'],
            dataset,
            f"{source_name}_to_{target_name}",
            self.timestamp
        )
        os.makedirs(output_dir, exist_ok=True)
        
        # æ„å»ºè¿ç§»å‘½ä»¤
        cmd = f"cd {os.path.dirname(self.config['paths']['transfer_script'])} && " \
              f"python {os.path.basename(self.config['paths']['transfer_script'])} " \
              f"--source_lora {source_lora_path} " \
              f"--source_model {source_model} " \
              f"--target_model {target_model} " \
              f"--output {output_dir} " \
              f"--similarity_threshold {self.config['transfer']['similarity_threshold']}"
        
        output = self._run_command(cmd, f"è¿ç§» LoRA ({source_name} â†’ {target_name})")
        if output is None:
            return None
        
        return output_dir
    
    def evaluate_model(self, model_path, base_model, dataset, is_lora=True):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        model_type = "LoRA" if is_lora else "åŸºç¡€æ¨¡å‹"
        model_name = self._get_model_short_name(base_model)
        
        print(f"\nğŸ“Š å¼€å§‹è¯„ä¼° {model_name} {model_type}")
        
        # æ„å»ºè¯„ä¼°å‘½ä»¤ï¼Œä¿æŒåœ¨é¡¹ç›®æ ¹ç›®å½•
        if is_lora:
            cmd = f"python {self.config['paths']['eval_script']} " \
                  f"--models_list {model_path} " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {self.config['evaluation']['sample_ratio']} " \
                  f"--base_model {base_model}"
        else:
            # è¯„ä¼°åŸºç¡€æ¨¡å‹ - ä¹Ÿéœ€è¦ä½¿ç”¨models_listå‚æ•°
            cmd = f"python {self.config['paths']['eval_script']} " \
                  f"--models_list {base_model} " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {self.config['evaluation']['sample_ratio']}"
        
        output = self._run_command(cmd, f"è¯„ä¼° {model_name} {model_type}")
        if output is None:
            return None
        
        # è§£æè¯„ä¼°è¾“å‡ºè·å–å‡†ç¡®ç‡
        try:
            import re
            
            # æ–¹æ³•1: æŸ¥æ‰¾è¡¨æ ¼æ ¼å¼çš„accuracy
            table_pattern = r"\|\s*test/accuracy\s*\|\s*([\d.]+)\s*\|"
            match = re.search(table_pattern, output, re.IGNORECASE)
            if match:
                accuracy = float(match.group(1))
                print(f"   ğŸ“Š ä»è¡¨æ ¼æå–å‡†ç¡®ç‡: {accuracy:.4f}")
                return accuracy
            
            # æ–¹æ³•2: æŸ¥æ‰¾å­—å…¸æ ¼å¼çš„accuracy
            dict_pattern = r"['\"]?test/accuracy['\"]?\s*[:\|]\s*([\d.]+)"
            match = re.search(dict_pattern, output, re.IGNORECASE)
            if match:
                accuracy = float(match.group(1))
                print(f"   ğŸ“Š ä»å­—å…¸æå–å‡†ç¡®ç‡: {accuracy:.4f}")
                return accuracy
            
            # æ–¹æ³•3: æŸ¥æ‰¾ä¸€èˆ¬accuracyä¿¡æ¯
            general_pattern = r"accuracy['\"]?\s*[:\|=]\s*([\d.]+)"
            match = re.search(general_pattern, output, re.IGNORECASE)
            if match:
                accuracy = float(match.group(1))
                print(f"   ğŸ“Š ä»ä¸€èˆ¬æ ¼å¼æå–å‡†ç¡®ç‡: {accuracy:.4f}")
                return accuracy
            
            # æ–¹æ³•4: é€è¡Œåˆ†æ
            lines = output.split('\n')
            for line in lines:
                line = line.strip()
                if 'accuracy' in line.lower() and any(char.isdigit() for char in line):
                    # æå–è¡Œä¸­çš„æ‰€æœ‰æ•°å­—
                    numbers = re.findall(r'\d+\.?\d*', line)
                    for num_str in numbers:
                        try:
                            num = float(num_str)
                            # å‡†ç¡®ç‡é€šå¸¸åœ¨0-1ä¹‹é—´
                            if 0 <= num <= 1:
                                print(f"   ğŸ“Š ä»è¡Œæå–å‡†ç¡®ç‡: {num:.4f} (è¡Œ: {line[:50]}...)")
                                return num
                        except:
                            continue
            
            print(f"   âš ï¸ æœªèƒ½æå–å‡†ç¡®ç‡ï¼Œè¿”å›None")
            # è°ƒè¯•ï¼šæ˜¾ç¤ºè¯„ä¼°è¾“å‡ºçš„å…³é”®éƒ¨åˆ†
            print("   ğŸ” è¯„ä¼°è¾“å‡ºå…³é”®è¡Œ:")
            for line in output.split('\n')[-20:]:  # æ˜¾ç¤ºæœ€å20è¡Œ
                if any(keyword in line.lower() for keyword in ['accuracy', 'test', 'loss']):
                    print(f"     {line.strip()}")
            
        except Exception as e:
            print(f"âš ï¸ è§£æè¯„ä¼°è¾“å‡ºæ—¶å‡ºé”™: {e}")
        
        return None
    
    def save_results(self, experiment_data):
        """ä¿å­˜å®éªŒç»“æœ"""
        print(f"\nğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
        
        # æ·±åº¦æ¸…ç†æ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
        def deep_clean_value(value):
            if value is None:
                return None
            elif hasattr(value, 'item'):  # numpy scalar
                try:
                    return float(value.item())
                except:
                    return str(value)
            elif hasattr(value, 'tolist'):  # numpy array
                try:
                    return value.tolist()
                except:
                    return str(value)
            elif isinstance(value, (list, tuple)):
                return [deep_clean_value(v) for v in value]
            elif isinstance(value, dict):
                return {k: deep_clean_value(v) for k, v in value.items()}
            elif isinstance(value, float) and (value != value):  # NaN
                return None
            elif isinstance(value, (int, float, str, bool)):
                return value
            else:
                return str(value)
        
        clean_data = {}
        for key, value in experiment_data.items():
            clean_data[key] = deep_clean_value(value)
        
        # ä¿å­˜åˆ°CSV
        csv_path = os.path.join(self.config['paths']['results_dir'], 
                               self.config['results']['csv_file'])
        
        try:
            # åˆ›å»ºDataFrameæ—¶æŒ‡å®šåˆ—
            expected_columns = [
                'experiment_id', 'source_model', 'target_model', 'dataset',
                'source_acc', 'source_lora_acc', 'target_acc', 'target_lora_acc', 'transferred_acc',
                'source_lora_path', 'target_lora_path', 'transferred_lora_path',
                'timestamp', 'notes', 'training_config'
            ]
            
            # ç¡®ä¿æ‰€æœ‰æœŸæœ›çš„åˆ—éƒ½å­˜åœ¨
            for col in expected_columns:
                if col not in clean_data:
                    clean_data[col] = None
            
            # åˆ›å»ºæ–°è¡Œï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯åŸºæœ¬ç±»å‹
            new_row_data = {}
            for col in expected_columns:
                value = clean_data[col]
                if value is None:
                    new_row_data[col] = None
                else:
                    new_row_data[col] = str(value) if not isinstance(value, (int, float, bool)) else value
            
            df_new = pd.DataFrame([new_row_data])
            
            if os.path.exists(csv_path):
                try:
                    # å®‰å…¨è¯»å–CSVï¼Œå¤„ç†å¯èƒ½çš„numpyæ•°ç»„
                    df_existing = pd.read_csv(csv_path, converters={
                        col: lambda x: x if not str(x).startswith('[') else str(x) 
                        for col in expected_columns
                    })
                    # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
                    for col in expected_columns:
                        if col not in df_existing.columns:
                            df_existing[col] = None
                    df_existing = df_existing[expected_columns]
                    df_combined = pd.concat([df_existing, df_new], ignore_index=True)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–ç°æœ‰ç»“æœæ—¶å‡ºé”™: {e}")
                    print("ğŸ’¡ å°†åˆ›å»ºæ–°çš„ç»“æœæ–‡ä»¶")
                    df_combined = df_new
            else:
                df_combined = df_new
            
            df_combined.to_csv(csv_path, index=False)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVæ—¶å‡ºé”™: {e}")
            print("ğŸ’¡ å°†å°è¯•ç®€åŒ–æ•°æ®æ ¼å¼ä¿å­˜")
            
            # å¤‡ç”¨ä¿å­˜æ–¹æ³•ï¼šç›´æ¥å†™å…¥æ–‡æœ¬æ ¼å¼
            backup_path = csv_path.replace('.csv', '_backup.txt')
            try:
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(f"å®éªŒç»“æœå¤‡ä»½ - {datetime.now()}\n")
                    f.write("=" * 50 + "\n")
                    for key, value in clean_data.items():
                        f.write(f"{key}: {value}\n")
                print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°å¤‡ç”¨æ–‡ä»¶: {backup_path}")
                return  # æå‰è¿”å›ï¼Œé¿å…è°ƒç”¨_update_markdown_summary
            except Exception as backup_error:
                print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {backup_error}")
                return
        
        # æ›´æ–°Markdownæ€»ç»“
        try:
            self._update_markdown_summary(df_combined)
        except Exception as md_error:
            print(f"âš ï¸ æ›´æ–°Markdownå¤±è´¥: {md_error}")
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°:")
        print(f"   ğŸ“Š CSV: {csv_path}")
        print(f"   ğŸ“ Markdown: {os.path.join(self.config['paths']['results_dir'], self.config['results']['markdown_file'])}")
    
    def _update_markdown_summary(self, df):
        """æ›´æ–°Markdownæ€»ç»“æ–‡ä»¶"""
        md_path = os.path.join(self.config['paths']['results_dir'], 
                              self.config['results']['markdown_file'])
        
        content = f"""# ğŸ“Š LoRAè¿ç§»å®éªŒç»“æœæ±‡æ€»

> è‡ªåŠ¨ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
> ç®¡ç†è„šæœ¬: transfer_pipeline.py  
> æ€»å®éªŒæ•°: {len(df)}

## å®éªŒæ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•æ‰€æœ‰LoRAè®­ç»ƒå’Œè¿ç§»å®éªŒçš„ç»“æœï¼ŒåŒ…æ‹¬ï¼š
- åŸºç¡€æ¨¡å‹æ€§èƒ½
- LoRAå¾®è°ƒåæ€§èƒ½  
- è·¨æ¨¡å‹LoRAè¿ç§»æ€§èƒ½
- è¯¦ç»†çš„é…ç½®ä¿¡æ¯

---

## æœ€æ–°å®éªŒç»“æœ

"""
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„æ˜¾ç¤ºç»“æœ
        for dataset in df['dataset'].unique():
            dataset_df = df[df['dataset'] == dataset]
            content += f"\n### æ•°æ®é›†: {dataset}\n\n"
            
            for _, row in dataset_df.iterrows():
                content += f"#### å®éªŒ: {row['source_model']} â†’ {row['target_model']}\n\n"
                content += "| æ¨¡å‹é…ç½® | å‡†ç¡®ç‡ | æå‡ | å¤‡æ³¨ |\n"
                content += "|---------|--------|------|------|\n"
                
                # åŸºç¡€æ¨¡å‹è¡Œ
                content += f"| {self._get_model_short_name(row['source_model'])} (source) | {row['source_acc']:.4f} | - | åŸºç¡€æ¨¡å‹ |\n"
                if pd.notna(row['source_lora_acc']):
                    improvement = (row['source_lora_acc'] - row['source_acc']) * 100
                    content += f"| {self._get_model_short_name(row['source_model'])} + LoRA | {row['source_lora_acc']:.4f} | +{improvement:.2f}% | æºæ¨¡å‹å¾®è°ƒ |\n"
                
                content += f"| {self._get_model_short_name(row['target_model'])} (target) | {row['target_acc']:.4f} | - | åŸºç¡€æ¨¡å‹ |\n"
                if pd.notna(row['target_lora_acc']):
                    improvement = (row['target_lora_acc'] - row['target_acc']) * 100
                    content += f"| {self._get_model_short_name(row['target_model'])} + LoRA | {row['target_lora_acc']:.4f} | +{improvement:.2f}% | ç›®æ ‡æ¨¡å‹å¾®è°ƒ |\n"
                
                if pd.notna(row['transferred_acc']):
                    improvement = (row['transferred_acc'] - row['target_acc']) * 100
                    content += f"| {self._get_model_short_name(row['target_model'])} + è¿ç§»LoRA | {row['transferred_acc']:.4f} | +{improvement:.2f}% | è¿ç§»LoRA |\n"
                
                content += f"\n**å®éªŒæ—¶é—´:** {row['timestamp']}  \n"
                content += f"**é…ç½®:** {row['training_config']}\n\n"
                content += "---\n\n"
        
        content += f"""
## ä½¿ç”¨è¯´æ˜

### è¿è¡Œæ–°å®éªŒ
```bash
python transfer_pipeline.py \\
  --source_model Llama-3.2-3B-Instruct \\
  --target_model Qwen_Qwen2.5-1.5B \\
  --dataset arc-challenge
```

### æŸ¥çœ‹è¯¦ç»†æ•°æ®
```bash
# æŸ¥çœ‹CSVæ ¼å¼æ•°æ® (å¯ç”¨Excelæ‰“å¼€)
cat results/experiment_results.csv

# åªè¿è¡Œè¯„ä¼° (è·³è¿‡è®­ç»ƒ)
python transfer_pipeline.py --source_model ... --target_model ... --dataset ... --eval_only
```

---

*æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _save_partial_results(self, results, status_message):
        """ç«‹å³ä¿å­˜éƒ¨åˆ†ç»“æœ"""
        try:
            print(f"ğŸ’¾ {status_message} - ç«‹å³æ›´æ–°ç»“æœ...")
            
            # æ·±åº¦æ¸…ç†æ•°æ®ç±»å‹ï¼Œç¡®ä¿pandaså…¼å®¹
            def deep_clean_value(value):
                if value is None:
                    return None
                elif hasattr(value, 'item'):  # numpy scalar
                    try:
                        return float(value.item())
                    except:
                        return str(value)
                elif hasattr(value, 'tolist'):  # numpy array
                    try:
                        return value.tolist()
                    except:
                        return str(value)
                elif isinstance(value, (list, tuple)):
                    return [deep_clean_value(v) for v in value]
                elif isinstance(value, dict):
                    return {k: deep_clean_value(v) for k, v in value.items()}
                elif isinstance(value, float) and (value != value):  # NaN
                    return None
                elif isinstance(value, (int, float, str, bool)):
                    return value
                else:
                    return str(value)
            
            clean_results = {}
            for key, value in results.items():
                clean_results[key] = deep_clean_value(value)
            
            # ç«‹å³å†™å…¥CSV (è¿½åŠ æ¨¡å¼)
            csv_path = os.path.join(self.config['paths']['results_dir'], 
                                   self.config['results']['csv_file'])
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(csv_path), exist_ok=True)
            
            # è¯»å–ç°æœ‰æ•°æ®
            if os.path.exists(csv_path):
                try:
                    # å®‰å…¨è¯»å–CSVï¼Œå¤„ç†å¯èƒ½çš„ç±»å‹é—®é¢˜
                    df_existing = pd.read_csv(csv_path, dtype=str)  # å…ˆéƒ½è¯»æˆå­—ç¬¦ä¸²
                    # ç„¶åå¤„ç†æ•°å€¼åˆ—
                    numeric_cols = ['source_acc', 'target_acc', 'transferred_acc', 'source_lora_acc', 'target_lora_acc']
                    for col in numeric_cols:
                        if col in df_existing.columns:
                            df_existing[col] = pd.to_numeric(df_existing[col], errors='coerce')
                    
                    # ç¡®ä¿åˆ—ç±»å‹ä¸€è‡´
                    for col in df_existing.columns:
                        if col in clean_results:
                            # å°†æ‰€æœ‰å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†è½¬å›é€‚å½“ç±»å‹ï¼Œé¿å…ç±»å‹å†²çª
                            if df_existing[col].dtype == 'object':
                                continue
                            try:
                                clean_results[col] = str(clean_results[col]) if clean_results[col] is not None else None
                            except:
                                clean_results[col] = str(clean_results[col])
                except Exception as read_error:
                    print(f"âš ï¸ è¯»å–ç°æœ‰CSVå¤±è´¥: {read_error}")
                    df_existing = pd.DataFrame()
            else:
                df_existing = pd.DataFrame()
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå®éªŒ
            experiment_id = clean_results.get('experiment_id')
            if not df_existing.empty and experiment_id:
                # æ›´æ–°ç°æœ‰è®°å½•
                mask = df_existing['experiment_id'] == experiment_id
                if mask.any():
                    for key, value in clean_results.items():
                        if key in df_existing.columns:
                            df_existing.loc[mask, key] = value
                        else:
                            df_existing[key] = None
                            df_existing.loc[mask, key] = value
                else:
                    # æ·»åŠ æ–°è®°å½•
                    new_row = pd.DataFrame([clean_results])
                    df_existing = pd.concat([df_existing, new_row], ignore_index=True)
            else:
                # æ·»åŠ æ–°è®°å½•
                new_row = pd.DataFrame([clean_results])
                df_existing = pd.concat([df_existing, new_row], ignore_index=True)
            
            # ä¿å­˜æ›´æ–°åçš„CSV
            df_existing.to_csv(csv_path, index=False)
            
            # ç«‹å³æ›´æ–°Markdownæ‘˜è¦
            self._update_markdown_summary(df_existing)
            
            print(f"âœ… ç»“æœå·²ä¿å­˜: {csv_path}")
            
        except Exception as e:
            print(f"âš ï¸ éƒ¨åˆ†ç»“æœä¿å­˜å¤±è´¥: {e}")
            # å¤‡ç”¨ä¿å­˜æ–¹æ³•
            backup_path = os.path.join(self.config['paths']['results_dir'], 
                                     f"partial_backup_{self.timestamp}.json")
            try:
                with open(backup_path, 'w', encoding='utf-8') as f:
                    json.dump(clean_results, f, indent=2, ensure_ascii=False, default=str)
                print(f"ğŸ“ å¤‡ç”¨ä¿å­˜: {backup_path}")
            except Exception as backup_error:
                print(f"âš ï¸ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {backup_error}")
                # æœ€åçš„æ–‡æœ¬å¤‡ç”¨
                text_backup = os.path.join(self.config['paths']['results_dir'], 
                                         f"text_backup_{self.timestamp}.txt")
                with open(text_backup, 'w', encoding='utf-8') as f:
                    f.write(f"å®éªŒç»“æœ - {datetime.now()}\n")
                    f.write("=" * 50 + "\n")
                    for key, value in results.items():
                        f.write(f"{key}: {value}\n")
                print(f"ğŸ“ æ–‡æœ¬å¤‡ç”¨ä¿å­˜: {text_backup}")
    
    def _check_step_completed(self, step_name, model_path, dataset):
        """æ£€æŸ¥æ­¥éª¤æ˜¯å¦å·²å®Œæˆï¼Œè¿”å›(å·²å®Œæˆ, ç»“æœ)"""
        if step_name == "source_lora_training":
            model_name = self._get_model_short_name(model_path)
            runs_dir = os.path.join(self.config['paths']['runs_dir'], dataset, model_name)
            if os.path.exists(runs_dir):
                existing_runs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
                if existing_runs:
                    latest_run = sorted(existing_runs)[-1]
                    final_model_path = os.path.join(runs_dir, latest_run, "final_model")
                    if os.path.exists(final_model_path):
                        return True, final_model_path
        
        elif step_name == "target_lora_training":
            model_name = self._get_model_short_name(model_path)
            runs_dir = os.path.join(self.config['paths']['runs_dir'], dataset, model_name)
            if os.path.exists(runs_dir):
                existing_runs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
                if existing_runs:
                    latest_run = sorted(existing_runs)[-1]
                    final_model_path = os.path.join(runs_dir, latest_run, "final_model")
                    if os.path.exists(final_model_path):
                        return True, final_model_path
        
        elif step_name == "lora_transfer":
            # æ£€æŸ¥è¿ç§»ç»“æœç›®å½•
            source_name = self._get_model_short_name(model_path)  # è¿™é‡Œmodel_pathæ˜¯source_model
            target_name = self._get_model_short_name(dataset)     # è¿™é‡Œdatasetæ˜¯target_model (å‚æ•°é‡ç”¨)
            transfer_base_dir = os.path.join(
                self.config['paths']['transferred_lora_dir'],
                dataset,  # å®é™…dataset
                f"{source_name}_to_{target_name}"
            )
            if os.path.exists(transfer_base_dir):
                existing_transfers = [d for d in os.listdir(transfer_base_dir) if os.path.isdir(os.path.join(transfer_base_dir, d))]
                if existing_transfers:
                    latest_transfer = sorted(existing_transfers)[-1]
                    transfer_path = os.path.join(transfer_base_dir, latest_transfer)
                    return True, transfer_path
        
        return False, None
    
    def run_pipeline(self, source_model, target_model, dataset, eval_only=False):
        """è¿è¡Œå®Œæ•´ç®¡é“ - æ–°æµç¨‹ï¼šè®­ç»ƒæºLoRA â†’ è¿ç§» â†’ è¯„ä¼°ç›®æ ‡åŸºç¡€ â†’ è¯„ä¼°è¿ç§»LoRA â†’ è®­ç»ƒç›®æ ‡LoRA â†’ è¯„ä¼°æºåŸºç¡€"""
        self.experiment_id = self._create_experiment_id(source_model, target_model, dataset)
        
        print(f"\nğŸ¯ å¼€å§‹LoRAè¿ç§»å®éªŒ")
        print(f"ğŸ“‹ å®éªŒID: {self.experiment_id}")
        print(f"ğŸ² æºæ¨¡å‹: {source_model}")
        print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {target_model}")
        print(f"ğŸ“š æ•°æ®é›†: {dataset}")
        print("=" * 80)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å†å²è®°å½•
        existing = self._check_existing_experiment(source_model, target_model, dataset)
        if existing is not None and not eval_only:
            print(f"âš ï¸ å‘ç°ç›¸åŒå®éªŒè®°å½• (æ—¶é—´: {existing['timestamp']})")
            response = input("æ˜¯å¦ç»§ç»­? (y/N): ").strip().lower()
            if response not in ['y', 'yes']:
                print("ğŸš« å®éªŒå–æ¶ˆ")
                return False
        
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        results = {
            'experiment_id': self.experiment_id,
            'source_model': source_model,
            'target_model': target_model,
            'dataset': dataset,
            'timestamp': self.timestamp,
            'training_config': f"batch_size={self.config['training']['default_batch_size']}, "
                              f"max_steps={self.config['training']['default_max_steps']}, "
                              f"lr={self.config['training']['default_lr']}",
            'notes': 'è‡ªåŠ¨åŒ–ç®¡é“ç”Ÿæˆ'
        }
        
        # ğŸ¯ æ–°æµç¨‹ï¼š6ä¸ªæ­¥éª¤
        total_steps = 6 if not eval_only else 4
        progress_bar = tqdm(total=total_steps, desc="ğŸš€ LoRAè¿ç§»ç®¡é“", position=0, leave=True)
        
        try:
            if not eval_only:
                # æ­¥éª¤1: è®­ç»ƒæºLoRA (è‡ªåŠ¨åŒ…å«æµ‹è¯•)
                progress_bar.set_description("ğŸ¯ æ­¥éª¤1: è®­ç»ƒæºLoRA")
                source_lora_path, source_lora_acc = self.train_model(source_model, dataset)
                if source_lora_path is None:
                    raise Exception("æºæ¨¡å‹è®­ç»ƒå¤±è´¥")
                
                results.update({
                    'source_lora_path': source_lora_path,
                    'source_lora_acc': source_lora_acc,
                })
                self._save_partial_results(results, "æºLoRAè®­ç»ƒå®Œæˆ")
                progress_bar.update(1)
                
                # æ­¥éª¤2: è¿ç§»LoRA  
                progress_bar.set_description("ğŸ”„ æ­¥éª¤2: è¿ç§»LoRA")
                transferred_lora_path = self.transfer_lora(
                    source_lora_path, source_model, target_model, dataset
                )
                if transferred_lora_path is None:
                    raise Exception("LoRAè¿ç§»å¤±è´¥")
                
                results['transferred_lora_path'] = transferred_lora_path
                self._save_partial_results(results, "LoRAè¿ç§»å®Œæˆ")
                progress_bar.update(1)
            
            # æ­¥éª¤3: è¯„ä¼°ç›®æ ‡åŸºç¡€æ¨¡å‹
            progress_bar.set_description("ğŸ“Š æ­¥éª¤3: è¯„ä¼°ç›®æ ‡åŸºç¡€æ¨¡å‹")
            target_acc = self.evaluate_model(target_model, target_model, dataset, is_lora=False)
            results['target_acc'] = target_acc
            self._save_partial_results(results, "ç›®æ ‡åŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ")
            progress_bar.update(1)
            
            if not eval_only:
                # æ­¥éª¤4: è¯„ä¼°è¿ç§»LoRA
                progress_bar.set_description("ğŸ“Š æ­¥éª¤4: è¯„ä¼°è¿ç§»LoRA")
                transferred_acc = self.evaluate_model(
                    results['transferred_lora_path'], target_model, dataset, is_lora=True
                )
                results['transferred_acc'] = transferred_acc
                self._save_partial_results(results, "è¿ç§»LoRAè¯„ä¼°å®Œæˆ")
                progress_bar.update(1)
                
                # æ­¥éª¤5: è®­ç»ƒç›®æ ‡LoRA (è‡ªåŠ¨åŒ…å«æµ‹è¯•)
                progress_bar.set_description("ğŸ¯ æ­¥éª¤5: è®­ç»ƒç›®æ ‡LoRA")
                target_lora_path, target_lora_acc = self.train_model(target_model, dataset)
                if target_lora_path is None:
                    print("âš ï¸ ç›®æ ‡æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡")
                    target_lora_acc = None
                
                results.update({
                    'target_lora_path': target_lora_path,
                    'target_lora_acc': target_lora_acc,
                })
                self._save_partial_results(results, "ç›®æ ‡LoRAè®­ç»ƒå®Œæˆ")
                progress_bar.update(1)
            
            # æ­¥éª¤6: è¯„ä¼°æºåŸºç¡€æ¨¡å‹ (è¡¥é½)
            progress_bar.set_description("ğŸ“Š æ­¥éª¤6: è¯„ä¼°æºåŸºç¡€æ¨¡å‹")
            source_acc = self.evaluate_model(source_model, source_model, dataset, is_lora=False)
            results['source_acc'] = source_acc
            self._save_partial_results(results, "æºåŸºç¡€æ¨¡å‹è¯„ä¼°å®Œæˆ")
            progress_bar.update(1)
            
            # æœ€ç»ˆä¿å­˜å®Œæ•´ç»“æœ
            progress_bar.set_description("ğŸ’¾ ä¿å­˜æœ€ç»ˆç»“æœ")
            self.save_results(results)
            progress_bar.close()
            
            # æ‰“å°æ€»ç»“
            self._print_summary(results)
            
            # æç¤ºå¯é€‰å‘½ä»¤
            if not eval_only:
                self._print_optional_commands(source_model, target_model, dataset)
            
            print("\nğŸ‰ ç®¡é“æ‰§è¡ŒæˆåŠŸ!")
            return True
            
        except Exception as e:
            progress_bar.close()
            print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            # ä¿å­˜éƒ¨åˆ†ç»“æœ
            self._save_partial_results(results, f"å¤±è´¥: {e}")
            return False
    
    def _print_summary(self, results):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\nğŸ‰ å®éªŒå®Œæˆ! æ€»ç»“å¦‚ä¸‹:")
        print("=" * 60)
        
        source_name = self._get_model_short_name(results['source_model'])
        target_name = self._get_model_short_name(results['target_model'])
        
        # å¤„ç†å¯èƒ½ä¸ºNoneçš„å€¼
        source_acc = results.get('source_acc', 0)
        target_acc = results.get('target_acc', 0)
        source_lora_acc = results.get('source_lora_acc')
        target_lora_acc = results.get('target_lora_acc')
        transferred_acc = results.get('transferred_acc')
        
        print(f"ğŸ“Š {source_name} (æºæ¨¡å‹): {source_acc:.4f}")
        if source_lora_acc is not None:
            improvement = (source_lora_acc - source_acc) * 100
            print(f"ğŸ“Š {source_name} + LoRA: {source_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print(f"ğŸ“Š {target_name} (ç›®æ ‡æ¨¡å‹): {target_acc:.4f}")
        
        if transferred_acc is not None:
            improvement = (transferred_acc - target_acc) * 100
            print(f"ğŸ“Š {target_name} + è¿ç§»LoRA: {transferred_acc:.4f} (+{improvement:.2f}%)")
        
        if target_lora_acc is not None:
            improvement = (target_lora_acc - target_acc) * 100
            print(f"ğŸ“Š {target_name} + ç›´è®­LoRA: {target_lora_acc:.4f} (+{improvement:.2f}%)")
        
        print("=" * 60)
        print(f"ğŸ“ è¯¦ç»†ç»“æœ: results/experiment_summary.md")
    
    def _print_optional_commands(self, source_model, target_model, dataset):
        """æ‰“å°å¯é€‰çš„ç›®æ ‡æ¨¡å‹LoRAè®­ç»ƒå‘½ä»¤"""
        target_name = self._get_model_short_name(target_model)
        
        print(f"\nğŸ’¡ å¯é€‰ï¼šè®­ç»ƒç›®æ ‡æ¨¡å‹ {target_name} çš„LoRAè¿›è¡Œå¯¹æ¯”")
        print("=" * 60)
        
        # è®­ç»ƒå‘½ä»¤
        train_cmd = f"python {self.config['paths']['train_script']} " \
                   f"--dataset {dataset} " \
                   f"--base_model {target_model} " \
                   f"--bs {self.config['training']['default_batch_size']} " \
                   f"--max_steps {self.config['training']['default_max_steps']}"
        
        print(f"ï¿½ è®­ç»ƒ {target_name} LoRA:")
        print(f"   {train_cmd}")
        
        # è¯„ä¼°å‘½ä»¤ 
        eval_cmd = f"python {self.config['paths']['eval_script']} " \
                  f"--models_list [è®­ç»ƒåçš„æ¨¡å‹è·¯å¾„] " \
                  f"--dataset {dataset} " \
                  f"--sample_ratio {self.config['evaluation']['sample_ratio']} " \
                  f"--base_model {target_model}"
        
        print(f"\nğŸ“Š è¯„ä¼° {target_name} LoRA:")
        print(f"   {eval_cmd}")
        print()
        print("ğŸ’¡ è®­ç»ƒå®Œæˆåå¯ä»¥å¯¹æ¯” 'ç›®æ ‡æ¨¡å‹+LoRA' vs 'ç›®æ ‡æ¨¡å‹+è¿ç§»LoRA' çš„æ€§èƒ½å·®å¼‚")


def main():
    parser = argparse.ArgumentParser(
        description="LoRAè®­ç»ƒå’Œè¿ç§»è‡ªåŠ¨åŒ–ç®¡é“",
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¿«é€Ÿæµ‹è¯• (0.5Bâ†’1.5B, 20æ­¥è®­ç»ƒ, 5%è¯„ä¼°)
  python transfer_pipeline.py --quick_test
  
  # è‡ªå®šä¹‰æ¨¡å‹
  python transfer_pipeline.py --source_model gemma-2-2b-it --target_model Qwen_Qwen2.5-1.5B --dataset arc-challenge
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("--source_model", type=str, 
                       help="æºæ¨¡å‹è·¯å¾„æˆ–åç§°")
    parser.add_argument("--target_model", type=str, 
                       help="ç›®æ ‡æ¨¡å‹è·¯å¾„æˆ–åç§°")
    parser.add_argument("--dataset", type=str, 
                       help="æ•°æ®é›†åç§°")
    parser.add_argument("--config", type=str, default="config/pipeline_config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--eval_only", action="store_true",
                       help="ä»…è¿è¡Œè¯„ä¼°ï¼Œè·³è¿‡è®­ç»ƒå’Œè¿ç§»")
    parser.add_argument("--quick_test", action="store_true",
                       help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šè‡ªåŠ¨ä½¿ç”¨0.5Bâ†’1.5Bé…ç½®")
    
    args = parser.parse_args()
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨é¢„è®¾é…ç½®
    if args.quick_test:
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼š0.5B â†’ 1.5B")
        args.config = "config/quick_test_config.yaml"
        quick_config = yaml.safe_load(open(args.config, 'r', encoding='utf-8'))
        
        # ä½¿ç”¨æ¨èé…ç½®
        if not args.source_model:
            args.source_model = quick_config['recommended_models']['source']
        if not args.target_model:
            args.target_model = quick_config['recommended_models']['target'] 
        if not args.dataset:
            args.dataset = quick_config['recommended_models']['dataset']
            
        print(f"ğŸ“¦ æºæ¨¡å‹: {args.source_model}")
        print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {args.target_model}")
        print(f"ğŸ“š æ•°æ®é›†: {args.dataset}")
        print(f"âš¡ è®­ç»ƒæ­¥æ•°: 20, è¯„ä¼°æ¯”ä¾‹: 5%")
        print("")
    
    # éªŒè¯å¿…éœ€å‚æ•°
    if not all([args.source_model, args.target_model, args.dataset]):
        print("âŒ é”™è¯¯: éœ€è¦æŒ‡å®š --source_model, --target_model, --dataset")
        print("ğŸ’¡ æˆ–è€…ä½¿ç”¨ --quick_test è‡ªåŠ¨é…ç½®")
        parser.print_help()
        return
    
    # éªŒè¯æ¨¡å‹è·¯å¾„
    config = yaml.safe_load(open(args.config, 'r', encoding='utf-8'))
    models_dir = config['paths']['models_dir']
    
    # å¤„ç†æ¨¡å‹è·¯å¾„
    if not args.source_model.startswith('/'):
        args.source_model = os.path.join(models_dir, args.source_model)
    if not args.target_model.startswith('/'):
        args.target_model = os.path.join(models_dir, args.target_model)
    
    # éªŒè¯æ¨¡å‹å­˜åœ¨
    if not os.path.exists(args.source_model):
        print(f"âŒ æºæ¨¡å‹ä¸å­˜åœ¨: {args.source_model}")
        return False
    if not os.path.exists(args.target_model):
        print(f"âŒ ç›®æ ‡æ¨¡å‹ä¸å­˜åœ¨: {args.target_model}")
        return False
    
    # éªŒè¯æ•°æ®é›†
    if args.dataset not in config['training']['datasets']:
        print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®é›†: {args.dataset}")
        print(f"âœ… æ”¯æŒçš„æ•°æ®é›†: {', '.join(config['training']['datasets'])}")
        return False
    
    # è¿è¡Œç®¡é“
    pipeline = TransferPipeline(args.config)
    success = pipeline.run_pipeline(
        args.source_model, 
        args.target_model, 
        args.dataset,
        eval_only=args.eval_only
    )
    
    if success:
        print(f"\nğŸ‰ ç®¡é“æ‰§è¡ŒæˆåŠŸ!")
        return True
    else:
        print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥!")
        return False


if __name__ == "__main__":
    main()
