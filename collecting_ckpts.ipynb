{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3860e65",
   "metadata": {},
   "source": [
    "# Collecting Commonsense Checkpoints\n",
    "本 notebook 按照 commonsense 预训练 + 微调流程，自动收集 7 个数据集的 checkpoint。\n",
    "\n",
    "数据集目录：raw_datasets/\n",
    "\n",
    "数据集列表：\n",
    "- arc-challenge\n",
    "- arc-easy\n",
    "- boolq\n",
    "- hellaswag\n",
    "- openbookqa\n",
    "- piqa\n",
    "- winogrande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8512bda",
   "metadata": {},
   "source": [
    "# 实验 Setup 说明\n",
    "本实验将 7 个 commonsense 数据集（arc-challenge, arc-easy, boolq, hellaswag, openbookqa, piqa, winogrande）合并并打乱，生成一个大的训练集，存放于 raw_datasets/commonsense/commonsense_train.jsonl。\n",
    "训练流程如下：\n",
    "- 使用合并后的大数据集分 batch 训练。\n",
    "- 预训练参数：\n",
    "    - 学习率 lr = 1e-4\n",
    "    - 训练步数 training step = 75\n",
    "    - batch size = 32\n",
    "    - 样本数 num_samples = 5000\n",
    "- 微调参数：\n",
    "    - 学习率 lr = 1e-5\n",
    "    - 训练步数 training step = 50\n",
    "- 每个 batch 训练时，保存最后 50 个 checkpoint，存放在专门的文件夹（如 checkpoints/commonsense_batch_x/）。\n",
    "- 训练和微调均基于同一个大数据集，按上述参数执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1da6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 数据集路径和名称\n",
    "DATASET_DIR = 'raw_datasets'\n",
    "DATASETS = [\n",
    "    'arc-challenge', 'arc-easy', 'boolq', 'hellaswag', 'openbookqa', 'piqa', 'winogrande'\n",
    "]\n",
    "CKPT_DIR = 'checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f974921",
   "metadata": {},
   "source": [
    "## Step 1: Commonsense Pretrain\n",
    "对所有数据集进行预训练，保存预训练 checkpoint。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_on_dataset(dataset):\n",
    "    print(f'Pretraining on {dataset} ...')\n",
    "    # 这里调用你的预训练脚本或函数，假设为 train.py --mode pretrain\n",
    "    ckpt_path = os.path.join(CKPT_DIR, f'{dataset}_pretrain.ckpt')\n",
    "    # 模拟保存 checkpoint\n",
    "    Path(ckpt_path).touch()\n",
    "    print(f'Checkpoint saved: {ckpt_path}')\n",
    "\n",
    "for ds in DATASETS:\n",
    "    pretrain_on_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f51e9",
   "metadata": {},
   "source": [
    "## Step 2: Fine-tune\n",
    "在预训练 checkpoint 基础上，对每个数据集进行微调，保存微调 checkpoint。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e988abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_on_dataset(dataset):\n",
    "    print(f'Fine-tuning on {dataset} ...')\n",
    "    pretrain_ckpt = os.path.join(CKPT_DIR, f'{dataset}_pretrain.ckpt')\n",
    "    finetune_ckpt = os.path.join(CKPT_DIR, f'{dataset}_finetune.ckpt')\n",
    "    # 这里调用你的微调脚本或函数，假设为 train.py --mode finetune\n",
    "    # 模拟保存 checkpoint\n",
    "    Path(finetune_ckpt).touch()\n",
    "    print(f'Checkpoint saved: {finetune_ckpt}')\n",
    "\n",
    "for ds in DATASETS:\n",
    "    finetune_on_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30444ce7",
   "metadata": {},
   "source": [
    "## Step 3: 汇总所有 checkpoint 路径\n",
    "最终每个数据集会有 pretrain 和 finetune 两个 checkpoint。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ckpts = []\n",
    "for ds in DATASETS:\n",
    "    all_ckpts.append(os.path.join(CKPT_DIR, f'{ds}_pretrain.ckpt'))\n",
    "    all_ckpts.append(os.path.join(CKPT_DIR, f'{ds}_finetune.ckpt'))\n",
    "print('所有 checkpoint 路径:')\n",
    "for ckpt in all_ckpts:\n",
    "    print(ckpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
