{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d6f33c",
   "metadata": {},
   "source": [
    "# LoRA-X实验记录\n",
    "\n",
    "## 实验设计\n",
    "**目标**: 验证LoRA-X跨模型迁移在NLP任务中的有效性\n",
    "\n",
    "**创新点**: \n",
    "- 原文针对文生图(风格迁移)，我们应用于NLP(常识推理)\n",
    "- 从Diffusion模型迁移到Autoregressive语言模型\n",
    "- 验证不同架构间的适配器迁移能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f4752",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃        Test metric        ┃       DataLoader 0        ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│       test/accuracy       │    0.7081910967826843     │\n",
    "│         test/loss         │    0.1193200945854187     │\n",
    "│      test/perplexity      │     1.127521276473999     │\n",
    "└───────────────────────────┴───────────────────────────┘\n",
    "📊 测试结果:\n",
    "  - test/loss: 0.1193\n",
    "  - test/accuracy: 0.7082\n",
    "  - test/perplexity: 1.1275\n",
    "\n",
    "💾 保存最终模型到: runs/Llama-3.2-3B-Instruct/arc-challenge_lora_20250724_140508/final_model\n",
    "swanlab: 🏠 View project at https://swanlab.cn/@ootyzzz/lora-training\n",
    "swanlab: 🚀 View run at https://swanlab.cn/@ootyzzz/lora-training/runs/226yndmay1ieu2zqgaecl\n",
    "\n",
    "✅ Lightning训练完成!\n",
    "📁 实验目录: runs/Llama-3.2-3B-Instruct/arc-challenge_lora_20250724_140508\n",
    "📁 最终模型: runs/Llama-3.2-3B-Instruct/arc-challenge_lora_20250724_140508/final_model\n",
    "📊 训练步数: 600\n",
    "🎯 最终测试结果: {'test/loss': 0.1193200945854187, 'test/accuracy': 0.7081910967826843, 'test/perplexity': 1.127521276473999}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a1794",
   "metadata": {},
   "source": [
    "## 实验假设\n",
    "\n",
    "**成功标准**: Gemma + 迁移LoRA > 0.7491 (基础模型)\n",
    "\n",
    "**预期结果范围**:\n",
    "- 乐观: 0.750-0.755 (保留大部分Qwen LoRA的提升效果)\n",
    "- 现实: 0.745-0.750 (部分迁移成功)\n",
    "- 保守: 0.740-0.745 (轻微提升)\n",
    "- 失败: < 0.740 (迁移无效或有害)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff11ba",
   "metadata": {},
   "source": [
    "## 算法增强 - Frobenius Norm最小化投影\n",
    "\n",
    "**问题**: 维度不兼容时直接跳过层，导致迁移层数过少\n",
    "**解决方案**: 实现Frobenius norm最小化投影，自动处理维度不匹配\n",
    "\n",
    "### 技术细节\n",
    "```python\n",
    "def _frobenius_projection(self, lora_weight, source_base, target_base):\n",
    "    # SVD分解，截断到最小rank\n",
    "    min_rank = min(各维度, 16)  # 限制计算复杂度\n",
    "    U_s, Vh_s = svd(lora_weight)[:min_rank]\n",
    "    U_t, Vh_t = svd(target_base)[:min_rank]\n",
    "    \n",
    "    # Frobenius最小化投影到目标子空间\n",
    "    projected = U_t @ U_t.T @ U_s @ U_s.T @ lora_weight\n",
    "    projected = projected @ Vh_s @ Vh_t.T @ Vh_t\n",
    "    \n",
    "    # 截断到目标形状\n",
    "    return projected[:target_shape]\n",
    "```\n",
    "\n",
    "**预期效果**: \n",
    "- 减少跳过层数，提高迁移覆盖率\n",
    "- 保留源LoRA的主要特征方向\n",
    "- 增加迁移成功的可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184f7ac",
   "metadata": {},
   "source": [
    "## 最佳LoRA模型定位\n",
    "\n",
    "**✅ 已找到最佳Qwen LoRA模型！**\n",
    "\n",
    "**模型路径**: `/root/PAW/train_lora/runs/Qwen_Qwen2.5-1.5B/arc-challenge_lora_20250724_014727/final_model`\n",
    "\n",
    "**验证信息**:\n",
    "- 训练配置: steps=600, batch_size=6, lr=1.5e-5\n",
    "- 测试准确率: **0.7457** (+1.19% vs 基础模型0.7338)\n",
    "- SwanLab Run ID: arc-challenge_lora_20250724_014727\n",
    "\n",
    "**下一步**: 使用此LoRA进行Qwen→Llama迁移测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0a254",
   "metadata": {},
   "source": [
    "## ✅ 层名映射问题修复\n",
    "\n",
    "**问题**: 所有392层被跳过，原因是\"找不到对应的基础权重\"\n",
    "\n",
    "**根本原因**: 层名映射逻辑错误\n",
    "- **LoRA层名**: `base_model.model.model.layers.0.mlp.down_proj.lora_A.weight`\n",
    "- **基础模型层名**: `model.layers.0.mlp.down_proj.weight`\n",
    "- **错误映射**: `model.model.layers.0.mlp.down_proj.weight` (多了一个`model`)\n",
    "\n",
    "**修复方案**: \n",
    "```python\n",
    "# 修正前: base_key = lora_key.replace('base_model.', '')\n",
    "# 修正后: base_key = lora_key.replace('base_model.model.', '')\n",
    "```\n",
    "\n",
    "**验证结果**: ✅ 所有层名现在都能正确映射到基础权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f217c65",
   "metadata": {},
   "source": [
    "## ⚠️ 跨架构迁移挑战\n",
    "\n",
    "### 相似性过滤结果\n",
    "- **相似度阈值**: 0.001 (已降低)\n",
    "- **结果**: 仍然大部分层相似性为0.000，说明Qwen与Llama架构差异巨大\n",
    "\n",
    "### 技术问题\n",
    "1. **设备兼容性**: 张量在GPU/CPU间不一致 ✅ 已修复\n",
    "2. **维度不匹配**: `(16x1536 和 3072x3072)` - LoRA rank与目标模型维度冲突\n",
    "\n",
    "### 下一步策略\n",
    "- 考虑使用更激进的Frobenius投影\n",
    "- 或者降低到0.0001阈值强制迁移部分层\n",
    "- 分析哪些层类型更容易迁移成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b0642",
   "metadata": {},
   "source": [
    "## 🚀 性能优化 - CUDA加速与并行化\n",
    "\n",
    "### 优化措施\n",
    "1. **CUDA加速**: 所有张量计算都在GPU上进行\n",
    "2. **并行相似度计算**: 预计算所有层的相似度，避免重复计算\n",
    "3. **批量处理**: 优化SVD分解和矩阵运算的设备管理\n",
    "\n",
    "### 技术改进\n",
    "```python\n",
    "# 并行预计算相似度\n",
    "similarities = self._precompute_similarities_parallel(...)\n",
    "\n",
    "# CUDA加速SVD\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "weight_matrix = weight_matrix.to(device)\n",
    "U, S, Vh = torch.linalg.svd(weight_matrix.float(), full_matrices=False)\n",
    "```\n",
    "\n",
    "**预期效果**: 大幅减少计算时间，特别是对于392层的大规模迁移"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fbcbf9",
   "metadata": {},
   "source": [
    "## 🔧 LoRA-X迁移初步结果\n",
    "\n",
    "### 迁移统计\n",
    "- **总层数**: 392层\n",
    "- **成功迁移**: 部分层（通过简化的Frobenius投影）\n",
    "- **迁移文件**: `/root/autodl-tmp/trained_t2l/qwen_to_llama_lora_x`\n",
    "\n",
    "### 关键发现\n",
    "1. **架构差异巨大**: Qwen与Llama相似度普遍为0.000\n",
    "2. **维度不匹配**: 需要Frobenius投影处理形状差异\n",
    "3. **评估问题**: 迁移后的LoRA需要基于Llama而非Qwen加载\n",
    "\n",
    "### 下一步\n",
    "需要修正评估脚本，确保：\n",
    "- 基础模型: Llama-3.2-3B-Instruct\n",
    "- 迁移LoRA: 基于Llama的适配器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414cd3d5",
   "metadata": {},
   "source": [
    "## 📊 评估结果与关键发现\n",
    "\n",
    "### Llama-3.2-3B-Instruct基础性能\n",
    "- **ARC-Challenge准确率**: **0.6838** (68.38%)\n",
    "- **用时**: 27秒，4.3 样本/秒\n",
    "- **结论**: 比Qwen2.5-1.5B基础模型(0.7338)低约5%\n",
    "\n",
    "### LoRA-X迁移失败原因\n",
    "1. **权重形状根本不匹配**: \n",
    "   - 迁移后: `torch.Size([1024, 3072])`\n",
    "   - Llama期望: `torch.Size([16, 3072])` 和 `torch.Size([1024, 16])`\n",
    "\n",
    "2. **维度冲突原理**:\n",
    "   - LoRA rank固定为16，但被错误扩展到1024\n",
    "   - 说明我们的Frobenius投影生成了错误的权重形状\n",
    "\n",
    "### 核心问题\n",
    "**LoRA-X算法在极大架构差异下失效**:\n",
    "- Qwen→Llama架构差异过大，子空间相似性接近0\n",
    "- 简化的Frobenius投影无法保持LoRA的低秩结构\n",
    "- 迁移实质上变成了随机权重初始化\n",
    "\n",
    "### 实验结论\n",
    "**跨架构LoRA迁移在当前实现下不可行**，需要更精密的算法设计或限制在相似架构间迁移。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ec1b6",
   "metadata": {},
   "source": [
    "## 🎯 LoRA-X实验总结\n",
    "\n",
    "### 技术成就\n",
    "1. **✅ 成功实现LoRA-X核心算法**:\n",
    "   - SVD子空间分解\n",
    "   - 子空间相似性计算  \n",
    "   - 权重迁移投影\n",
    "   - CUDA加速优化\n",
    "\n",
    "2. **✅ 工程实现完整**:\n",
    "   - 层名映射修复\n",
    "   - 设备兼容性处理\n",
    "   - 并行化优化\n",
    "   - 完整的迁移pipeline\n",
    "\n",
    "### 关键教训\n",
    "1. **架构相似性至关重要**: \n",
    "   - Qwen↔Llama差异过大，相似性≈0.000\n",
    "   - 论文中的扩散模型间迁移可能架构更相似\n",
    "\n",
    "2. **LoRA低秩约束不能忽视**:\n",
    "   - 直接投影破坏了rank=16的低秩结构\n",
    "   - 需要约束投影保持LoRA的本质特性\n",
    "\n",
    "3. **评估框架的重要性**:\n",
    "   - fallback逻辑确实无意义\n",
    "   - LoRA必须与特定基础模型匹配\n",
    "\n",
    "### 改进方向\n",
    "1. **算法优化**: 约束Frobenius投影保持低秩\n",
    "2. **相似架构**: 测试Qwen2.5-1.5B→Qwen2.5-0.5B等相似模型\n",
    "3. **部分迁移**: 只迁移高相似性层，混合使用"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
