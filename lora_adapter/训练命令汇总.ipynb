{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790cf62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "本文档禁止ai修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef718b38",
   "metadata": {},
   "source": [
    "## 📊 实验汇总\n",
    "\n",
    "### ARC-Challenge-test集 测试结果详细记录\n",
    "\n",
    "Llama-3.2-3B(source) 使用ARC-Challenge-train,valid Lora 微调，迁移至Qwen2.5 1.5B(target)\n",
    "| 模型                        | 准确率(ACC)   | 提升   | Loss   | Perplexity | 微调/迁移配置                     | Run ID          | 备注         |\n",
    "| --------------------------- | -------- | ------ | ------ | ---------- | ---------------------------- | --------------- | ------------ |\n",
    "| Llama-3.2-3B (base)         | 0.6838   | -      | -      | -          | -                            | -               | 源模型基准        | \n",
    "| Llama-3.2-3B + LoRA         | 0.7082   | +3.57% | 0.1193 | 1.1275     | steps=600, batch=6, lr=1.5e-5 | 20250724_140508 |              | \n",
    "| Qwen2.5-1.5B (base)         | 0.7338   | -      | -      | -          | -                            | -               | 目标模型基准   |\n",
    "| Qwen2.5-1.5B + 从llama迁移的7082 | 0.7372   | +0.34% | 0.7372 | 16679      | -                            | -               |              |\n",
    "| Qwen2.5-1.5B + LoRA         | 0.7457   | +1.19% | 0.1193 | 1.1275     | steps=600, batch=6, lr=1.5e-5 | 20250724_014727 |              |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7e9ff",
   "metadata": {},
   "source": [
    "## 📊 实验汇总\n",
    "\n",
    "### ARC-Challenge测试结果详细记录\n",
    "Qwen2.5 1.5B(source) 使用ARC-Challenge-train,valid Lora 微调，迁移至Llama-3.2-3B(target)\n",
    "| 模型                        | 准确率   | 提升   | Loss   | Perplexity | 训练配置                     | Run ID          | 备注         |\n",
    "| --------------------------- | -------- | ------ | ------ | ---------- | ---------------------------- | --------------- | ------------ |\n",
    "| Qwen2.5-1.5B (base)         | 0.7338   | -      | -      | -          | -                            | -               | 源模型基准   |\n",
    "| Qwen2.5-1.5B + LoRA         | 0.7457   | +1.19% | 0.1193 | 1.1275     | steps=600, batch=6, lr=1.5e-5 | 20250724_014727 |              |\n",
    "| Qwen2.5-1.5B + 从llama迁移的7082 | 0.7372   | +0.34% | 0.7372 | 16679      | -                            | -               |              |\n",
    "| Llama-3.2-3B (base)         | 0.6838   | -      | -      | -          | -                            | -               | 目标模型基准 |\n",
    "| Llama-3.2-3B + Qwen的LoRA   | 0.7065   | +2.27% | -      | -          | -                            | -               |              |\n",
    "| Llama-3.2-3B + LoRA         | 0.7082   | +3.57% | 0.1193 | 1.1275     | steps=600, batch=6, lr=1.5e-5 | 20250724_140508 |              | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c864fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "微调lora\n",
    "\n",
    "cd /root/PAW/train_lora && python train_cs_lora_lightning.py --dataset arc-challenge --base_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct --bs 4 --max_steps 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48538d36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "迁移\n",
    "\n",
    "qwen 迁移到 llama\n",
    "cd /root/PAW/lora_adapter && python scripts/transfer_lora_x.py   --source_lora /root/PAW/train_lora/runs/Qwen_Qwen2.5-1.5B/arc-challenge_lora_20250724_014727/final_model   --source_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B   --target_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct   --output /root/autodl-tmp/trained_t2l/qwen_to_llama_lora_x_fixed   --similarity_threshold 0.0001\n",
    "\n",
    "llama 迁移到 qwen\n",
    "cd /root/PAW/lora_adapter && python scripts/transfer_lora_x.py   --source_lora /root/PAW/train_lora/runs/Llama-3.2-3B-Instruct/arc-challenge_lora_20250724_140508/final_model   --source_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct   --target_model //root/autodl-tmp/models/Qwen_Qwen2.5-1.5B   --output /root/autodl-tmp/lora-Xed/llama_to_qwen   --similarity_threshold 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29f3a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "eval 迁移过的\n",
    "\n",
    "qwen 迁移到 llama\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/trained_t2l/qwen_to_llama_lora_x_fixed --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct\n",
    "\n",
    "llama 迁移到 qwen\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/lora-Xed/llama_to_qwen --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab41f98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "eval base model\n",
    "\n",
    "qwen\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/lora-Xed/llama_to_qwen --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B\n",
    "\n",
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
