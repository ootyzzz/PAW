#!/usr/bin/env python3
"""
train_commonsense_lora_enhanced.py
å¢å¼ºç‰ˆè®­ç»ƒè„šæœ¬ - æ”¯æŒindividualå’Œmixedæ•°æ®é›†è®­ç»ƒ
"""

import os
import sys
import argparse
import logging
import yaml
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

try:
    from scripts.experiment_manager_enhanced import ExperimentManager
    from scripts.model_manager import ModelManager
    from utils.data_processor import DataProcessor
    from core.train import LoRATrainer
    from utils.scheduler import TwoStageScheduler
    from lora.checkpoint_utils import CheckpointManager
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

def setup_logging(log_dir: str = "./logs") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è®¾ç½®æ ¹æ—¥å¿—å™¨
    logger = logging.getLogger('commonsense_lora_training')
    logger.setLevel(logging.INFO)
    
    # æ–‡ä»¶å¤„ç†å™¨
    log_file = os.path.join(log_dir, f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger

def load_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        raise RuntimeError(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

def validate_paths(config: Dict[str, Any]) -> bool:
    """éªŒè¯é…ç½®ä¸­çš„è·¯å¾„"""
    model_path = config['model']['local_path']
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    return True

def get_individual_datasets() -> List[str]:
    """è·å–individualæ•°æ®é›†åˆ—è¡¨"""
    return [
        'arc-challenge', 'arc-easy', 'boolq', 'hellaswag',
        'openbookqa', 'piqa', 'winogrande'
    ]

def create_individual_config(base_config: Dict[str, Any], dataset_name: str) -> Dict[str, Any]:
    """ä¸ºindividualæ•°æ®é›†åˆ›å»ºé…ç½®"""
    config = base_config.copy()
    
    # æ›´æ–°æ•°æ®è·¯å¾„
    config['data']['train_file'] = f"data_to_lora/cs/{dataset_name}/{dataset_name}_train_formatted.jsonl"
    
    # ç”Ÿæˆæ—¶é—´æˆ³ç”¨äºå®éªŒåç§°
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"{timestamp}_lora"
    
    # æ›´æ–°è¾“å‡ºç›®å½• - ä½¿ç”¨æ–°çš„ç»“æ„ experiments/cs/{dataset_name}/{timestamp_lora}/
    config['training']['output_dir'] = f"./experiments/cs/{dataset_name}/{experiment_name}/models"
    config['checkpoint']['dir'] = f"./experiments/cs/{dataset_name}/{experiment_name}/checkpoints"
    config['logging']['log_dir'] = f"./experiments/cs/{dataset_name}/{experiment_name}/logs"
    
    # æ›´æ–°å®éªŒé…ç½®
    config['experiment']['name'] = experiment_name
    config['experiment']['description'] = f"LoRA training on {dataset_name} dataset"
    config['experiment']['tags'] = ["lora", "qwen2.5", dataset_name, "two-stage"]
    
    # è®¾ç½®å®éªŒç±»å‹ä¸ºcommonsense_lora
    config['experiment_type'] = "commonsense_lora"
    config['dataset_name'] = dataset_name  # æ·»åŠ æ•°æ®é›†åç§°å­—æ®µ
    
    # ä¸ºå®éªŒç®¡ç†å™¨åˆ›å»ºæ‰å¹³åŒ–çš„é…ç½®
    flat_config = {
        "model_path": config['model']['local_path'],
        "data_path": config['data']['train_file'], 
        "lora": config['lora'],
        "training": config['training'],
        "experiment_type": "commonsense_lora"
    }
    
    # ä¿ç•™åŸå§‹é…ç½®ç”¨äºå…¶ä»–ç”¨é€”
    config['_flat_config'] = flat_config
    
    return config

def create_mixed_config(base_config: Dict[str, Any]) -> Dict[str, Any]:
    """ä¸ºmixedæ•°æ®é›†åˆ›å»ºé…ç½®"""
    config = base_config.copy()
    
    # æ›´æ–°æ•°æ®è·¯å¾„
    config['data']['train_file'] = "data_to_lora/cs/mixed/cs_mixed_formatted_train.jsonl"
    
    # ç”Ÿæˆæ—¶é—´æˆ³ç”¨äºå®éªŒåç§°
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"{timestamp}_lora"
    
    # æ›´æ–°è¾“å‡ºç›®å½• - ä½¿ç”¨æ–°çš„ç»“æ„ experiments/cs/mixed/{timestamp_lora}/
    config['training']['output_dir'] = f"./experiments/cs/mixed/{experiment_name}/models"
    config['checkpoint']['dir'] = f"./experiments/cs/mixed/{experiment_name}/checkpoints"
    config['logging']['log_dir'] = f"./experiments/cs/mixed/{experiment_name}/logs"
    
    # æ›´æ–°å®éªŒé…ç½®
    config['experiment']['name'] = experiment_name
    config['experiment']['description'] = f"LoRA training on mixed commonsense datasets"
    config['experiment']['tags'] = ["lora", "qwen2.5", "mixed", "commonsense", "two-stage"]
    
    # è®¾ç½®å®éªŒç±»å‹ä¸ºcommonsense_lora
    config['experiment_type'] = "commonsense_lora"
    config['dataset_name'] = "mixed"  # æ·»åŠ æ•°æ®é›†åç§°å­—æ®µ
    
    # ä¸ºå®éªŒç®¡ç†å™¨åˆ›å»ºæ‰å¹³åŒ–çš„é…ç½®
    flat_config = {
        "model_path": config['model']['local_path'],
        "data_path": config['data']['train_file'], 
        "lora": config['lora'],
        "training": config['training'],
        "experiment_type": "commonsense_lora"
    }
    
    # ä¿ç•™åŸå§‹é…ç½®ç”¨äºå…¶ä»–ç”¨é€”
    config['_flat_config'] = flat_config
    
    return config

def run_single_experiment(config: Dict[str, Any], dataset_name: str, logger: logging.Logger) -> Dict[str, Any]:
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\n{'=' * 60}")
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {dataset_name}")
    print(f"{'=' * 60}")
    
    try:
        # éªŒè¯æ•°æ®æ–‡ä»¶
        data_file = config['data']['train_file']
        if not os.path.exists(data_file):
            raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        
        logger.info(f"å¼€å§‹è®­ç»ƒæ•°æ®é›†: {dataset_name}")
        logger.info(f"æ•°æ®æ–‡ä»¶: {data_file}")
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        experiment_manager = ExperimentManager("./experiments")
        model_manager = ModelManager(config['model']['cache_dir'])
        
        # éªŒè¯æ¨¡å‹
        model_path = config['model']['local_path']
        compatibility = model_manager.check_model_compatibility(model_path)
        
        if not compatibility['model_valid']:
            raise RuntimeError(f"æ¨¡å‹éªŒè¯å¤±è´¥: {compatibility}")
        
        # åˆ›å»ºå®éªŒåç§°
        experiment_name = config['experiment']['name']  # ä½¿ç”¨é…ç½®ä¸­çš„å®éªŒåç§°
        dataset_name = config['dataset_name']  # è·å–æ•°æ®é›†åç§°
        
        print(f"ğŸ“‹ å®éªŒåç§°: {experiment_name}")
        print(f"ğŸ“ æ•°æ®é›†: {dataset_name}")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {data_file}")
        print(f"ğŸ¯ è¾“å‡ºç›®å½•: {config['training']['output_dir']}")
        
        # å…ˆåˆ›å»ºå®éªŒï¼ˆä½¿ç”¨æ‰å¹³åŒ–é…ç½®å’Œæ•°æ®é›†åç§°ï¼‰
        flat_config = config['_flat_config']
        experiment_dir = experiment_manager.create_experiment(
            name=experiment_name,
            config=flat_config,  # ä½¿ç”¨æ‰å¹³åŒ–é…ç½®åˆ›å»ºå®éªŒ
            description=config['experiment']['description'],
            tags=config['experiment'].get('tags', []),
            dataset_name=dataset_name  # ä¼ é€’æ•°æ®é›†åç§°
        )
        
        # æ‰§è¡Œè®­ç»ƒ
        results = experiment_manager.run_commonsense_lora_experiment(experiment_name)
        
        print(f"âœ… {dataset_name} è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š è®­ç»ƒç»“æœ:")
        print(f"  - æœ€ç»ˆæ¨¡å‹: {results.get('final_model_path', 'N/A')}")
        print(f"  - è®­ç»ƒæ­¥æ•°: {results.get('total_steps', 'N/A')}")
        print(f"  - Checkpointæ•°: {results.get('checkpoint_summary', {}).get('total_checkpoints', 'N/A')}")
        
        logger.info(f"{dataset_name} è®­ç»ƒå®Œæˆ: {results}")
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_training_report(
            experiment_manager,
            experiment_name,
            results,
            config,
            dataset_name
        )
        
        return {
            'dataset': dataset_name,
            'experiment_name': experiment_name,
            'status': 'success',
            'results': results
        }
        
    except Exception as e:
        print(f"âŒ {dataset_name} è®­ç»ƒå¤±è´¥: {e}")
        logger.error(f"{dataset_name} è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
        return {
            'dataset': dataset_name,
            'status': 'failed',
            'error': str(e)
        }

def generate_training_report(
    experiment_manager: ExperimentManager,
    experiment_name: str,
    results: Dict[str, Any],
    config: Dict[str, Any],
    dataset_name: str
):
    """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
    try:
        experiment = experiment_manager.get_experiment(experiment_name, dataset_name)
        exp_dir = Path("./experiments") / "cs" / dataset_name / experiment_name
        
        report = {
            "experiment_info": {
                "name": experiment_name,
                "dataset": dataset_name,
                "created_at": experiment.get('created_at'),
                "status": experiment.get('status'),
                "description": experiment.get('description')
            },
            "configuration": {
                "model_path": config['model']['local_path'],
                "data_path": config['data']['train_file'],
                "lora_config": config['lora'],
                "training_stages": {
                    "stage1": config['training']['stage1'],
                    "stage2": config['training']['stage2']
                }
            },
            "training_results": results,
            "file_locations": {
                "experiment_dir": str(exp_dir),
                "final_model": results.get('final_model_path'),
                "checkpoints_dir": str(exp_dir / "checkpoints"),
                "logs_dir": str(exp_dir / "logs"),
                "models_dir": str(exp_dir / "models")
            },
            "generated_at": datetime.now().isoformat()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        results_dir = exp_dir / "results"
        results_dir.mkdir(parents=True, exist_ok=True)
        report_file = results_dir / "training_report.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆCommonsense LoRAè®­ç»ƒè„šæœ¬")
    parser.add_argument("--config", type=str, default="configs/training_config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--datasets", nargs='*', 
                       help="è¦è®­ç»ƒçš„æ•°æ®é›†/æ¨¡å¼åˆ—è¡¨ã€‚é»˜è®¤è®­ç»ƒæ‰€æœ‰7ä¸ªindividualæ•°æ®é›†ã€‚å¯åŒ…å«: arc-challenge, arc-easy, boolq, hellaswag, openbookqa, piqa, winogrande, mixed")
    parser.add_argument("--dry_run", action="store_true",
                       help="å¹²è¿è¡Œï¼Œä¸å®é™…è®­ç»ƒ")
    parser.add_argument("--validate_only", action="store_true",
                       help="ä»…éªŒè¯æ•°æ®å’Œæ¨¡å‹")
    
    args = parser.parse_args()
    
    # æ‰€æœ‰å¯ç”¨çš„individualæ•°æ®é›†
    all_individual_datasets = ['arc-challenge', 'arc-easy', 'boolq', 'hellaswag', 
                              'openbookqa', 'piqa', 'winogrande']
    
    # ç¡®å®šè¦è®­ç»ƒçš„å†…å®¹
    if args.datasets is None or len(args.datasets) == 0:
        # é»˜è®¤ï¼šè®­ç»ƒæ‰€æœ‰7ä¸ªindividualæ•°æ®é›†
        individual_datasets = all_individual_datasets
        train_mixed = False
        print("ğŸš€ Enhanced Commonsense LoRA Training Script")
        print("=" * 70)
        print(f"é…ç½®æ–‡ä»¶: {args.config}")
        print(f"è®­ç»ƒæ¨¡å¼: individual (é»˜è®¤ - æ‰€æœ‰7ä¸ªæ•°æ®é›†)")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
    else:
        # è§£æç”¨æˆ·æŒ‡å®šçš„æ•°æ®é›†
        individual_datasets = [d for d in args.datasets if d in all_individual_datasets]
        train_mixed = 'mixed' in args.datasets
        
        print("ğŸš€ Enhanced Commonsense LoRA Training Script")
        print("=" * 70)
        print(f"é…ç½®æ–‡ä»¶: {args.config}")
        print(f"è®­ç»ƒå†…å®¹: Individualæ•°æ®é›†: {individual_datasets}, Mixed: {'æ˜¯' if train_mixed else 'å¦'}")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
    
    train_individual = len(individual_datasets) > 0
    
    try:
        # 1. åŠ è½½åŸºç¡€é…ç½®
        print("\nğŸ“‹ æ­¥éª¤1: åŠ è½½é…ç½®...")
        base_config = load_config(args.config)
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # 2. è®¾ç½®æ—¥å¿—
        print("\nğŸ“ æ­¥éª¤2: è®¾ç½®æ—¥å¿—ç³»ç»Ÿ...")
        log_dir = base_config.get('logging', {}).get('log_dir', './logs')
        logger = setup_logging(log_dir)
        logger.info(f"è®­ç»ƒå¼€å§‹ - Individualæ•°æ®é›†: {individual_datasets}, Mixed: {train_mixed}")
        print(f"âœ… æ—¥å¿—ç³»ç»Ÿå·²è®¾ç½®")
        
        # 3. éªŒè¯åŸºç¡€è·¯å¾„
        print("\nğŸ” æ­¥éª¤3: éªŒè¯è·¯å¾„...")
        if not validate_paths(base_config):
            logger.error("è·¯å¾„éªŒè¯å¤±è´¥")
            return False
        logger.info("è·¯å¾„éªŒè¯é€šè¿‡")
        
        if args.validate_only:
            print("\nâœ… éªŒè¯å®Œæˆï¼Œé€€å‡º")
            return True
        
        # 4. æ ¹æ®æ¨¡å¼æ‰§è¡Œè®­ç»ƒ
        all_results = []
        
        if train_individual:
            print("\nğŸ¯ æ­¥éª¤4: æ‰§è¡ŒIndividualæ•°æ®é›†è®­ç»ƒ...")
            print(f"ğŸ“Š è®­ç»ƒæ•°æ®é›†: {individual_datasets}")
            
            # é€ä¸ªè®­ç»ƒæ•°æ®é›†
            for i, dataset_name in enumerate(individual_datasets):
                print(f"\n{'ğŸ”„' * 3} è¿›åº¦: {i+1}/{len(individual_datasets)} {'ğŸ”„' * 3}")
                config = create_individual_config(base_config, dataset_name)
                
                if args.dry_run:
                    print(f"ğŸƒ Dry run: {dataset_name}")
                    print(f"  æ•°æ®æ–‡ä»¶: {config['data']['train_file']}")
                    print(f"  è¾“å‡ºç›®å½•: {config['training']['output_dir']}")
                else:
                    result = run_single_experiment(config, dataset_name, logger)
                    all_results.append(result)
        
        if train_mixed:
            print("\nğŸ¯ æ‰§è¡ŒMixedæ•°æ®é›†è®­ç»ƒ...")
            config = create_mixed_config(base_config)
            
            if args.dry_run:
                print("ğŸƒ Dry run: mixed")
                print(f"  æ•°æ®æ–‡ä»¶: {config['data']['train_file']}")
                print(f"  è¾“å‡ºç›®å½•: {config['training']['output_dir']}")
            else:
                result = run_single_experiment(config, "mixed", logger)
                all_results.append(result)
        
        if args.dry_run:
            print("\nğŸƒ Dry runå®Œæˆï¼Œæœªå®é™…è®­ç»ƒ")
            return True
        
        # 5. ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
        print("\nğŸ“‹ æ­¥éª¤5: ç”Ÿæˆæ€»ä½“è®­ç»ƒæŠ¥å‘Š...")
        
        # ç¡®å®šæ¨¡å¼å­—ç¬¦ä¸²ç”¨äºæŠ¥å‘Š
        if train_individual and train_mixed:
            mode_str = "individual_and_mixed"
        elif train_mixed:
            mode_str = "mixed"
        else:
            mode_str = "individual"
            
        generate_summary_report(all_results, mode_str)
        
        # 6. æ‰“å°æ€»ç»“
        print(f"\nğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        successful = sum(1 for r in all_results if r['status'] == 'success')
        failed = len(all_results) - successful
        print(f"  - æˆåŠŸ: {successful}")
        print(f"  - å¤±è´¥: {failed}")
        print(f"  - æ€»è®¡: {len(all_results)}")
        
        if failed > 0:
            print(f"\nâŒ å¤±è´¥çš„æ•°æ®é›†:")
            for result in all_results:
                if result['status'] == 'failed':
                    print(f"  - {result['dataset']}: {result.get('error', 'Unknown error')}")
        
        logger.info(f"æ‰€æœ‰è®­ç»ƒå®Œæˆ - æˆåŠŸ: {successful}, å¤±è´¥: {failed}")
        return failed == 0
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if 'logger' in locals():
            logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
        return False

def generate_summary_report(results: List[Dict[str, Any]], mode: str):
    """ç”Ÿæˆæ€»ä½“æŠ¥å‘Š"""
    try:
        summary = {
            "training_mode": mode,
            "total_experiments": len(results),
            "successful": sum(1 for r in results if r['status'] == 'success'),
            "failed": sum(1 for r in results if r['status'] == 'failed'),
            "results": results,
            "generated_at": datetime.now().isoformat()
        }
        
        # ä¿å­˜æ€»ä½“æŠ¥å‘Š
        report_dir = Path("./experiments/cs")
        report_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = report_dir / f"training_summary_{mode}_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ€»ä½“æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆæ€»ä½“æŠ¥å‘Šæ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
