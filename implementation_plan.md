# LoRAå¾®è°ƒQwen2.5-0.5Bå®æ–½æ–¹æ¡ˆ

## ç›®æ ‡
ä½¿ç”¨LoRAæŠ€æœ¯å¾®è°ƒQwen2.5-0.5Bæ¨¡å‹ï¼Œæ•°æ®é›†ä¸ºcommonsenseæ•°æ®ï¼Œé‡‡ç”¨åˆ†é˜¶æ®µå­¦ä¹ ç‡ç­–ç•¥ã€‚

## æ•°æ®å‡†å¤‡
- [x] æ•°æ®é›†è·¯å¾„: `C:\Users\feifa\GitHub\P2W\raw_datasets\commonsense\cs_all_unbalanced.jsonl`
- [x] æ•°æ®æ ¼å¼: {"instruction": "...", "input": "...", "output": "..."}
- [x] æ¨¡å‹è·¯å¾„: `C:\Users\feifa\GitHub\P2W\models\Qwen-Qwen2.5-0.5B`

## è®­ç»ƒç­–ç•¥
### å­¦ä¹ ç‡è°ƒåº¦
- [ ] å‰75æ­¥: lr = 1e-4, ä¸ä¿å­˜checkpoint
- [ ] å50æ­¥: lr = 1e-5, æ¯æ­¥ä¿å­˜checkpoint
- [ ] æ€»è®¡125æ­¥è®­ç»ƒ

### æŠ€æœ¯ç»„ä»¶
- [ ] ä½¿ç”¨`scripts/experiment_manager.py`ä½œä¸ºä¸»è¦æ¥å£
- [ ] ä½¿ç”¨`scripts/model_manager.py`ç®¡ç†æ¨¡å‹åŠ è½½
- [ ] å‚è€ƒ`lora/checkpoint_utils.py`å®ç°checkpointä¿å­˜é€»è¾‘
- [ ] åŸºäº`configs/training_config.yaml`é…ç½®è®­ç»ƒå‚æ•°

## å®æ–½æ­¥éª¤

### 1. æ•°æ®å¤„ç†ç»„ä»¶
- [x] åˆ›å»º`utils/data_processor.py`
  - [x] å®ç°commonsenseæ•°æ®é›†åŠ è½½
  - [x] æ•°æ®æ ¼å¼è½¬æ¢å’Œtokenization
  - [x] æ•°æ®éªŒè¯å’Œé¢„å¤„ç†

### 2. è‡ªå®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨
- [x] åœ¨`utils/scheduler.py`ä¸­æ·»åŠ `TwoStageScheduler`
  - [x] å‰75æ­¥: 1e-4å­¦ä¹ ç‡
  - [x] å50æ­¥: 1e-5å­¦ä¹ ç‡
  - [x] å¹³æ»‘è¿‡æ¸¡æœºåˆ¶

### 3. å¢å¼ºcheckpointç®¡ç†
- [x] æ‰©å±•`lora/checkpoint_utils.py`
  - [x] æ·»åŠ æ¡ä»¶ä¿å­˜é€»è¾‘
  - [x] å®ç°æ­¥éª¤è®¡æ•°å™¨
  - [x] ä¼˜åŒ–å­˜å‚¨ç®¡ç†

### 4. LoRAè®­ç»ƒå™¨é›†æˆ
- [x] æ›´æ–°`core/train.py`
  - [x] é›†æˆä¸¤é˜¶æ®µè®­ç»ƒé€»è¾‘
  - [x] æ·»åŠ è¿›åº¦ç›‘æ§
  - [x] å®ç°åŠ¨æ€checkpointç­–ç•¥

### 5. å®éªŒç®¡ç†æ¥å£
- [x] å¢å¼º`scripts/experiment_manager.py`
  - [x] æ·»åŠ commonsenseå®éªŒé…ç½®
  - [x] é›†æˆæ–°çš„è®­ç»ƒæµç¨‹
  - [x] å®ç°å®éªŒç›‘æ§å’Œæ—¥å¿—

### 6. æ¨¡å‹ç®¡ç†å¢å¼º
- [x] æ›´æ–°`scripts/model_manager.py`
  - [x] ä¼˜åŒ–Qwen2.5æ¨¡å‹åŠ è½½
  - [x] æ·»åŠ LoRAé…ç½®ç®¡ç†
  - [x] å®ç°æ¨¡å‹çŠ¶æ€æ£€æŸ¥

### 7. é…ç½®æ–‡ä»¶è°ƒæ•´
- [x] æ›´æ–°`configs/training_config.yaml`
  - [x] è®¾ç½®commonsenseæ•°æ®é›†è·¯å¾„
  - [x] é…ç½®ä¸¤é˜¶æ®µå­¦ä¹ ç‡å‚æ•°
  - [x] ä¼˜åŒ–LoRAå’Œè®­ç»ƒå‚æ•°

### 8. ä¸»è®­ç»ƒè„šæœ¬
- [x] åˆ›å»º`train_commonsense_lora.py`
  - [x] æ•´åˆæ‰€æœ‰ç»„ä»¶
  - [x] å®ç°å®Œæ•´è®­ç»ƒæµç¨‹
  - [x] æ·»åŠ é”™è¯¯å¤„ç†å’Œæ—¥å¿—

## éªŒè¯æ­¥éª¤
æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹éªŒè¯å‘½ä»¤ï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½é€šè¿‡ï¼š

### 1. ç¯å¢ƒå’Œä¾èµ–éªŒè¯
```bash
# è¿è¡Œå®Œæ•´ç¯å¢ƒéªŒè¯
python validate_setup.py
```
**æœŸæœ›ç»“æœ**: æ‰€æœ‰éªŒè¯é¡¹æ˜¾ç¤º âœ…ï¼Œç”Ÿæˆ `validation_report.json`

### 2. æ•°æ®åŠ è½½æµ‹è¯•
```bash
# ä»…éªŒè¯æ•°æ®å’Œæ¨¡å‹ï¼Œä¸è®­ç»ƒ
python train_commonsense_lora.py --validate_only
```
**æœŸæœ›ç»“æœ**: 
- æ¨¡å‹è·¯å¾„éªŒè¯é€šè¿‡
- æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡  
- LoRAå…¼å®¹æ€§æ£€æŸ¥é€šè¿‡

### 3. é…ç½®æ–‡ä»¶éªŒè¯
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•å’Œè·¯å¾„
python -c "import yaml; print('âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®' if yaml.safe_load(open('configs/training_config.yaml')) else 'âŒ')"
```
**æœŸæœ›ç»“æœ**: æ˜¾ç¤º `âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®`

### 4. Dry Runæµ‹è¯•ï¼ˆä¸å®é™…è®­ç»ƒï¼‰
```bash
# æ‰§è¡Œå®Œæ•´æµç¨‹ä½†ä¸è®­ç»ƒ
python train_commonsense_lora.py --dry_run --experiment_name "test_dry_run"
```
**æœŸæœ›ç»“æœ**: 
- å®éªŒåˆ›å»ºæˆåŠŸ
- æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–æ­£å¸¸
- æ˜¾ç¤º "ğŸƒ Dry runå®Œæˆï¼Œæœªå®é™…è®­ç»ƒ"

### 5. å°è§„æ¨¡è®­ç»ƒæµ‹è¯•ï¼ˆå¯é€‰ï¼‰
å¦‚æœå‰é¢æ­¥éª¤éƒ½é€šè¿‡ï¼Œå¯ä»¥æµ‹è¯•å®é™…è®­ç»ƒï¼š
```bash
# å¼€å§‹å®Œæ•´è®­ç»ƒ
python train_commonsense_lora.py --experiment_name "commonsense_lora_test"
```
**æœŸæœ›ç»“æœ**:
- è®­ç»ƒå¼€å§‹å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
- å‰75æ­¥ä¸ä¿å­˜checkpoint
- ç¬¬76æ­¥å¼€å§‹æ¯æ­¥ä¿å­˜checkpoint
- è®­ç»ƒå®Œæˆåæ˜¾ç¤ºç»“æœæ‘˜è¦

### æ‰‹åŠ¨éªŒè¯æ£€æŸ¥æ¸…å•

#### åœ¨è¿è¡Œè®­ç»ƒå‰ç¡®è®¤ï¼š
- [ ] GPUå¯ç”¨æ€§: `python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"` 
- [ ] ç£ç›˜ç©ºé—´: ç¡®ä¿è‡³å°‘æœ‰10GBå¯ç”¨ç©ºé—´ï¼ˆç”¨äºcheckpointsï¼‰
- [ ] å†…å­˜: ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜ï¼ˆæ¨è16GB+ï¼‰

#### åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§ï¼š
- [ ] æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `./experiments/[å®éªŒå]/logs/training_*.log`
- [ ] ç›‘æ§checkpointä¿å­˜: `./experiments/[å®éªŒå]/checkpoints/`
- [ ] æ£€æŸ¥è¿›åº¦æ˜¾ç¤º: ç¡®ä¿å­¦ä¹ ç‡åœ¨ç¬¬76æ­¥ä»1e-4å˜ä¸º1e-5

#### è®­ç»ƒå®ŒæˆåéªŒè¯ï¼š
- [ ] æ£€æŸ¥æœ€ç»ˆæ¨¡å‹: `./experiments/[å®éªŒå]/models/final_model/`
- [ ] éªŒè¯checkpointæ•°é‡: åº”è¯¥æœ‰50ä¸ªcheckpointæ–‡ä»¶ï¼ˆæ­¥éª¤75-124ï¼‰
- [ ] æŸ¥çœ‹è®­ç»ƒæŠ¥å‘Š: `./experiments/[å®éªŒå]/results/training_report.json`

## é¢„æœŸè¾“å‡º
è®­ç»ƒæˆåŠŸå®Œæˆåï¼Œä½ å°†å¾—åˆ°ä»¥ä¸‹æ–‡ä»¶å’Œç»“æœï¼š

### ğŸ“ æ–‡ä»¶ç»“æ„
```
experiments/
â””â”€â”€ [å®éªŒåç§°]/
    â”œâ”€â”€ checkpoints/           # Checkpointæ–‡ä»¶
    â”‚   â”œâ”€â”€ checkpoint_step_0075_*.pt
    â”‚   â”œâ”€â”€ checkpoint_step_0076_*.pt
    â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ checkpoint_step_0124_*.pt
    â”‚   â””â”€â”€ checkpoint_info.json
    â”œâ”€â”€ models/               # æœ€ç»ˆæ¨¡å‹
    â”‚   â””â”€â”€ final_model/
    â”‚       â”œâ”€â”€ adapter_config.json
    â”‚       â”œâ”€â”€ adapter_model.safetensors
    â”‚       â””â”€â”€ tokenizer files...
    â”œâ”€â”€ logs/                 # è®­ç»ƒæ—¥å¿—
    â”‚   â””â”€â”€ training_*.log
    â”œâ”€â”€ results/              # ç»“æœæ–‡ä»¶
    â”‚   â”œâ”€â”€ training_results.json
    â”‚   â”œâ”€â”€ training_report.json
    â”‚   â””â”€â”€ data_validation.json
    â”œâ”€â”€ config.yaml           # å®éªŒé…ç½®
    â””â”€â”€ metadata.json         # å®éªŒå…ƒæ•°æ®
```

### ğŸ“Š å…³é”®æŒ‡æ ‡
- **è®­ç»ƒæ­¥æ•°**: 125æ­¥ (75æ­¥ + 50æ­¥)
- **Checkpointæ–‡ä»¶**: 50ä¸ª (æ­¥éª¤75-124)
- **æœ€ç»ˆLoRAæƒé‡**: ä¿å­˜åœ¨ `final_model/` ç›®å½•
- **è®­ç»ƒæ—¥å¿—**: è¯¦ç»†è®°å½•æ¯æ­¥çš„æŸå¤±å’Œå­¦ä¹ ç‡å˜åŒ–

### ğŸ“‹ éªŒè¯æˆåŠŸçš„æ ‡å¿—
- [x] å­¦ä¹ ç‡åœ¨ç¬¬76æ­¥ä»1e-4åˆ‡æ¢åˆ°1e-5
- [x] å‰75æ­¥æ²¡æœ‰ä¿å­˜checkpoint
- [x] å50æ­¥æ¯æ­¥éƒ½ä¿å­˜checkpoint  
- [x] è®­ç»ƒè¿‡ç¨‹æ— é”™è¯¯ä¸­æ–­
- [x] æœ€ç»ˆæ¨¡å‹æ–‡ä»¶å®Œæ•´ç”Ÿæˆ

---
*åˆ›å»ºæ—¶é—´: 2025-07-18*
*çŠ¶æ€: âœ… å®æ–½å®Œæˆï¼Œç­‰å¾…éªŒè¯*

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒéªŒè¯
```bash
python validate_setup.py
```

### ç¬¬äºŒæ­¥ï¼šæµ‹è¯•è¿è¡Œ
```bash
python train_commonsense_lora.py --validate_only
```

### ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹è®­ç»ƒ
```bash
python train_commonsense_lora.py --experiment_name "my_commonsense_lora"
```

### ç¬¬å››æ­¥ï¼šç›‘æ§è¿›åº¦
- æŸ¥çœ‹å®æ—¶æ—¥å¿—: `tail -f ./experiments/[å®éªŒå]/logs/training_*.log`
- æ£€æŸ¥checkpoint: `ls -la ./experiments/[å®éªŒå]/checkpoints/`

**é¢„è®¡è®­ç»ƒæ—¶é—´**: çº¦30-60åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
**æ‰€éœ€ç£ç›˜ç©ºé—´**: çº¦5-10GBï¼ˆåŒ…æ‹¬checkpointsï¼‰
