{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790cf62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "本文档禁止ai修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef718b38",
   "metadata": {},
   "source": [
    "## 📊 实验汇总\n",
    "\n",
    "### ARC-Challenge-test集 测试结果详细记录\n",
    "\n",
    "### 表格 1：Llama-3.2-3B (source) 使用 ARC-Challenge-train 微调后迁移至 Qwen2.5-1.5B (target)\n",
    "\n",
    "| 模型                           | 准确率(ACC) | 提升     | 微调/迁移配置                                                 |\n",
    "| ---------------------------- | -------- | ------ | ------------------------------------------------------- |\n",
    "| Llama-3.2-3B                 | 0.6838   | -      | -                                                       |\n",
    "| Llama-3.2-3B + LoRA          | 0.7082   | +2.44% | steps=600, batch=6, lr=1.5e-5                           |\n",
    "| Qwen2.5-1.5B (baseline)      | 0.7338   | -      | -                                                       |\n",
    "| Qwen2.5-1.5B + 从llama迁移的LoRA | 0.7372   | +0.34% | target: q, k, v, o, gate, up, down，共396层，max\\_sim=0.002 |\n",
    "| Qwen2.5-1.5B + LoRA          | 0.7457   | +1.19% | steps=600, batch=6, lr=1.5e-5                           |\n",
    "\n",
    "---\n",
    "\n",
    "### 表格 2：Qwen2.5-1.5B (source) 使用 ARC-Challenge-train 微调后迁移至 Llama-3.2-3B (target)\n",
    "\n",
    "| 模型                          | 准确率(ACC) | 提升     | 微调/迁移配置                                                 |\n",
    "| --------------------------- | -------- | ------ | ------------------------------------------------------- |\n",
    "| Qwen2.5-1.5B                | 0.7338   | -      | -                                                       |\n",
    "| Qwen2.5-1.5B + LoRA         | 0.7457   | +1.19% | steps=600, batch=6, lr=1.5e-5                           |\n",
    "| Llama-3.2-3B (baseline)     | 0.6838   | -      | -                                                       |\n",
    "| Llama-3.2-3B + 从Qwen迁移的LoRA | 0.7065   | +2.27% | target: q, k, v, o, gate, up, down，共396层，max\\_sim=0.002 |\n",
    "| Llama-3.2-3B + LoRA         | 0.7082   | +2.44% | steps=600, batch=6, lr=1.5e-5                           |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c864fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "微调lora\n",
    "有早停 动态学习率 每个epoch后用valid选best model\n",
    "\n",
    "cd /root/PAW/train_lora && python train_cs_lora_lightning.py --dataset arc-challenge --base_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct --bs 4 --max_steps 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48538d36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "迁移\n",
    "\n",
    "qwen 迁移到 llama\n",
    "cd /root/PAW/lora_adapter && python scripts/transfer_lora_x.py   --source_lora /root/PAW/train_lora/runs/Qwen_Qwen2.5-1.5B/arc-challenge_lora_20250724_014727/final_model   --source_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B   --target_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct   --output /root/autodl-tmp/adapted_lora/qwen_to_llama_lora_x_fixed   --similarity_threshold 0.0001\n",
    "\n",
    "llama 迁移到 qwen\n",
    "cd /root/PAW/lora_adapter && python scripts/transfer_lora_x.py   --source_lora /root/PAW/train_lora/runs/Llama-3.2-3B-Instruct/arc-challenge_lora_20250724_140508/final_model   --source_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct   --target_model //root/autodl-tmp/models/Qwen_Qwen2.5-1.5B   --output /root/autodl-tmp/adapted_lora/llama_to_qwen   --similarity_threshold 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29f3a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "eval 迁移过的\n",
    "\n",
    "qwen 迁移到 llama\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/adapted_lora/qwen_to_llama_lora_x_fixed --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct\n",
    "\n",
    "llama 迁移到 qwen\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/adapted_lora/llama_to_qwen --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab41f98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "eval base model\n",
    "\n",
    "qwen\n",
    "python eval/lightning_eval.py --models_list /root/autodl-tmp/adapted_lora/llama_to_qwen --dataset arc-challenge --sample_ratio 0.1 --base_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B\n",
    "\n",
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python pipeline/experiments/run_single_experiment.py --base_model /root/autodl-tmp/models/Qwen_Qwen2.5-1.5B --target_model /root/autodl-tmp/models/Llama-3.2-3B-Instruct --dataset arc-challenge --eval_only"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
